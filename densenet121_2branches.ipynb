{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a6086d",
   "metadata": {
    "id": "modular-forth"
   },
   "source": [
    "# Implementación de DenseNet para las dos vistas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe13a0c",
   "metadata": {
    "id": "younger-sentence"
   },
   "source": [
    "Ajustamos el notebook según estemos trabajando en local o en un entorno de Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f8cde9",
   "metadata": {
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1621188710580,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "flying-consciousness"
   },
   "outputs": [],
   "source": [
    "google_colab = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1193ca84",
   "metadata": {},
   "source": [
    "Importamos todas las librerías necesarias para la implementación del entrenamiento de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d25f417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 21:48:09.609776: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-21 21:48:09.612497: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 21:48:09.654679: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 21:48:09.656098: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 21:48:10.366073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "\n",
    "# if google_colab:\n",
    "#     from google.colab import drive\n",
    "#     !pip install pickle5\n",
    "#     import pickle5 as pickle\n",
    "#     drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d36bab",
   "metadata": {
    "id": "engaging-persian"
   },
   "source": [
    "##  Carga del dataset y preparación de los dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71844e5e",
   "metadata": {
    "id": "beautiful-monthly"
   },
   "source": [
    "Definimos una función auxiliar para ayudar con el preprocesamiento de los datos (ajuste de entrada para la DenseNet en el caso de las imágenes y conversión a one-hot encoding para las etiquetas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5f35fd",
   "metadata": {
    "executionInfo": {
     "elapsed": 22216,
     "status": "ok",
     "timestamp": 1621188731832,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "traditional-islam"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X_cc, X_mlo, Y):\n",
    "    \"\"\"\n",
    "    Pre-processes the data for the model\n",
    "        - X_cc is a numpy.ndarray of shape (m, 1024, 1024, 3) containing\n",
    "         the CC view mammography, where m is the number of data points\n",
    "        - X_mlo is a numpy.ndarray of shape (m, 1024, 1024, 3) containing\n",
    "         the MLO view mammography, where m is the number of data points\n",
    "        - Y is a numpy.ndarray of shape (m,) containing\n",
    "         the Bi-Rads labels for X\n",
    "    Returns:\n",
    "        - X_cc_p is a numpy.ndarray containing the preprocessed X_cc\n",
    "        - X_mlo_p is a numpy.ndarray containing the preprocessed X_mlo\n",
    "        - Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    X_cc_p = K.applications.densenet.preprocess_input(X_cc)\n",
    "    X_mlo_p = K.applications.densenet.preprocess_input(X_mlo)\n",
    "\n",
    "    Y_p = K.utils.to_categorical(Y, 3)\n",
    "\n",
    "    return X_cc_p, X_mlo_p, Y_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664432f2",
   "metadata": {
    "id": "mobile-monroe"
   },
   "source": [
    "Cargamos los ficheros de entrada, tanto el de entrenamiento-test como el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd05d656",
   "metadata": {
    "executionInfo": {
     "elapsed": 39717,
     "status": "ok",
     "timestamp": 1621188749334,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "frequent-homework"
   },
   "outputs": [],
   "source": [
    "# if google_colab:\n",
    "#     with open('/content/gdrive/MyDrive/Colab Notebooks/df_INbreast_train.pkl', 'rb') as pickle_file:\n",
    "#         df_INbreast_train = pickle.load(pickle_file)\n",
    "#     with open('/content/gdrive/MyDrive/Colab Notebooks/df_INbreast_val.pkl', 'rb') as pickle_file:\n",
    "#         df_INbreast_val = pickle.load(pickle_file)\n",
    "# else:\n",
    "df_INbreast_train = pd.read_pickle('/workspace/container_0/andres/data/df_INbreast_train.pkl')\n",
    "df_INbreast_val = pd.read_pickle('/workspace/container_0/andres/data/df_INbreast_val.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35619a6d",
   "metadata": {
    "id": "contained-franchise"
   },
   "source": [
    "Cargamos los datos, convertimos las etiquetas a enteros y liberamos espacio de los ficheros que contenían el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1c53c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 41835,
     "status": "ok",
     "timestamp": 1621188751455,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "fatty-forwarding"
   },
   "outputs": [],
   "source": [
    "dict_valores = {'benigno': 0, 'seguimiento': 1, 'maligno': 2}\n",
    "Y_traintest = np.array(df_INbreast_train['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_traintest_cc = np.array(df_INbreast_train['CC Image'].tolist())\n",
    "X_traintest_mlo = np.array(df_INbreast_train['MLO Image'].tolist())\n",
    "Y_val = np.array(df_INbreast_val['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_val_cc = np.array(df_INbreast_val['CC Image'].tolist())\n",
    "X_val_mlo = np.array(df_INbreast_val['MLO Image'].tolist())\n",
    "X_val_cc, X_val_mlo, Y_val = preprocess_data(X_val_cc, X_val_mlo, Y_val)\n",
    "del df_INbreast_train\n",
    "del df_INbreast_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a116bb",
   "metadata": {
    "id": "W4IVXDMAOplr"
   },
   "source": [
    "## Definición de la arquitectura de red neuronal de dos ramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaf408",
   "metadata": {
    "id": "5moG-NYZcICz"
   },
   "source": [
    "Cargamos los modelos individuales de cada rama y definimos el nuevo modelo a partir de ellos, junto con el inicializador de los pesos de la capa conectada y el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b90db674",
   "metadata": {
    "executionInfo": {
     "elapsed": 95117,
     "status": "ok",
     "timestamp": 1621188804739,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "8Yka6jqyOtSx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 21:48:13.765055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 21:48:13.765862: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model_cc = K.models.load_model('/workspace/container_0/andres/densenet_2ramas/model_best_CC')\n",
    "model_mlo = K.models.load_model('/workspace/container_0/andres/densenet_2ramas/model_best_DN121_ft_MLO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb29976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_34_cc\n"
     ]
    }
   ],
   "source": [
    "model_cc.layers[0]._name = model_cc.layers[0].name + str('_cc')\n",
    "print(model_cc.layers[0]._name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511a7a5e",
   "metadata": {
    "executionInfo": {
     "elapsed": 95116,
     "status": "ok",
     "timestamp": 1621188804740,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "7UvQIbcNPxqL"
   },
   "outputs": [],
   "source": [
    "def DenseNet_2Ramas(model_cc, model_mlo, rand_seed = 2021, learning_rate = 0.0001, momentum = 0.9):\n",
    "    \"\"\"\n",
    "    Define the DenseNet architecture and compile the model\n",
    "        - model_cc is the pretrained CC-view DenseNet model\n",
    "        - model_mlo is the pretrained MLO-view DenseNet model\n",
    "        - rand_seed is a random seed number used during the fc layer initialization\n",
    "        - learning_rate is the learning rate used during the training\n",
    "        - momentum is the parameters that defines the momentun for the SGD optimizer\n",
    "    Returns:\n",
    "        - model_2ramas is the output compiled DenseNet 2-branch model\n",
    "    \"\"\"\n",
    "    # Define the model architecture\n",
    "    model_cc = K.Sequential(model_cc.layers[:-1]) # \n",
    "    model_mlo = K.Sequential(model_mlo.layers[:-1])\n",
    "\n",
    "    model_cc.layers[-1]._name = model_cc.layers[-1].name + '_cc'\n",
    "    model_mlo.layers[-1]._name = model_mlo.layers[-1].name + '_mlo'\n",
    "\n",
    "\n",
    "    model_cc.trainable = False\n",
    "    model_mlo.trainable = False\n",
    "\n",
    "\n",
    "    combined = K.layers.Concatenate()([model_cc.output, model_mlo.output])\n",
    "    \n",
    "    initializer = K.initializers.he_normal(seed = rand_seed)\n",
    "    \n",
    "    # pasar de todas las neuronas a las tres (añadir alguna capa)\n",
    "    fc_layer = K.layers.Dense(units = 3,\n",
    "                              activation = 'softmax',\n",
    "                              kernel_initializer = initializer\n",
    "                              )(combined)\n",
    "\n",
    "    model_2ramas = K.models.Model(inputs = [model_cc.input, model_mlo.input], outputs = fc_layer)\n",
    "#     model_2ramas.layers[0]._name = model_cc.layers[0].name + '_cc'\n",
    "\n",
    "    # Compile the model\n",
    "    opt = K.optimizers.SGD(learning_rate = learning_rate, momentum = momentum)\n",
    "    \n",
    "    model_2ramas.compile(loss = 'categorical_crossentropy',\n",
    "                         optimizer = opt,\n",
    "                         metrics = [\n",
    "                             'accuracy',\n",
    "                         Precision(name='precision'),\n",
    "                         Recall(name='recall'),\n",
    "                         AUC(name='auc')\n",
    "                         ]\n",
    "                        )\n",
    "    \n",
    "    return model_2ramas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d097c8c",
   "metadata": {
    "id": "LNizgVEZ5ENX"
   },
   "source": [
    "Mostramos por pantalla la arquitectura de la red definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ecd15cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96767,
     "status": "ok",
     "timestamp": 1621188806394,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "M_Sbv12gckjn",
    "outputId": "1f397139-8bec-41b2-ecac-e96c8c3fd8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_34_cc (InputLayer)    [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)       [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " resize_CC (Lambda)          (None, 256, 256, 3)          0         ['input_34_cc[0][0]']         \n",
      "                                                                                                  \n",
      " resize_MLO (Lambda)         (None, 256, 256, 3)          0         ['input_36[0][0]']            \n",
      "                                                                                                  \n",
      " densenet121_cc (Functional  (None, 1024)                 7037504   ['resize_CC[1][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " densenet121_mlo (Functiona  (None, 1024)                 7037504   ['resize_MLO[1][0]']          \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 2048)                 0         ['densenet121_cc[1][0]',      \n",
      "                                                                     'densenet121_mlo[1][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 3)                    6147      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14081155 (53.72 MB)\n",
      "Trainable params: 6147 (24.01 KB)\n",
      "Non-trainable params: 14075008 (53.69 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DenseNet_2Ramas(model_cc, model_mlo).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd3d66",
   "metadata": {
    "id": "daily-secretariat"
   },
   "source": [
    "## Entrenamiento de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f709ab1c",
   "metadata": {
    "id": "AVvOsz7p5ptL"
   },
   "source": [
    "Definimos una función auxiliar que particiona el conjunto de entrenamiento/test en los dos subconjuntos correspondientes (entrenamiento y test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241a7294",
   "metadata": {
    "executionInfo": {
     "elapsed": 96766,
     "status": "ok",
     "timestamp": 1621188806394,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "MfoWhBMq5plj"
   },
   "outputs": [],
   "source": [
    "def part_traintest(X_traintest_cc, X_traintest_mlo, Y_traintest, rand_seed = 2021, frac_test = .2/.8):\n",
    "    \"\"\"\n",
    "    Function that makes a partition for training and testing from the original dataset\n",
    "        - X_traintest_cc is the array of CC-view images from the original dataset\n",
    "        - X_traintest_mlo is the array of MLO-view images from the original dataset\n",
    "        - Y_traintest is the array of labels from the original dataset\n",
    "        - rand_seed is a random seed number used during the sampling\n",
    "        - frac_test is the fraction of cases used in the test subset\n",
    "    Returns:\n",
    "        - X_train_cc is the train array of CC-images\n",
    "        - X_train_mlo is the train array of MLO-images\n",
    "        - Y_train is the train array of labels\n",
    "        - X_test_cc is the test array of CC-images\n",
    "        - X_test_mlo is the test array of MLO-images\n",
    "        - Y_test is the test array of labels\n",
    "    \"\"\"\n",
    "    np.random.seed(rand_seed)\n",
    "    index_test = np.array([], dtype = 'int64')\n",
    "    for i in np.unique(Y_traintest):\n",
    "        index_test = np.append(index_test, \n",
    "                               np.random.choice(list(np.where(Y_traintest == i)[0]), size = int(np.where(Y_traintest == i)[0].shape[0]*frac_test), replace = False))\n",
    "    X_train_cc = np.delete(X_traintest_cc, index_test, axis = 0)\n",
    "    X_train_mlo = np.delete(X_traintest_mlo, index_test, axis = 0)\n",
    "    Y_train = np.delete(Y_traintest, index_test)\n",
    "    X_test_cc = np.take(X_traintest_cc, index_test, axis = 0)\n",
    "    X_test_mlo = np.take(X_traintest_mlo, index_test, axis = 0)\n",
    "    Y_test = np.take(Y_traintest, index_test)\n",
    "    X_train_cc, X_train_mlo, Y_train = preprocess_data(X_train_cc, X_train_mlo, Y_train)\n",
    "    X_test_cc, X_test_mlo, Y_test = preprocess_data(X_test_cc, X_test_mlo, Y_test)\n",
    "\n",
    "    return X_train_cc, X_train_mlo, Y_train, X_test_cc, X_test_mlo, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8bdf48",
   "metadata": {
    "id": "korean-press"
   },
   "source": [
    "Definimos los parámetros básicos para el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f01f5ca",
   "metadata": {
    "executionInfo": {
     "elapsed": 96766,
     "status": "ok",
     "timestamp": 1621188806395,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "incident-sender"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "no_epochs = 200\n",
    "rand_seed = 2021\n",
    "learning_rate = 0.001\n",
    "momentum = 0.8\n",
    "n_folds = 2\n",
    "frac_test = .2/.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fa216",
   "metadata": {
    "id": "0j95AaVx5bCa"
   },
   "source": [
    "Dado el desbalance que sufren las categorías de la muestra de entrenamiento, forzamos el balanceo calculando las proporciones respecto a la clase más representada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c902d3dd",
   "metadata": {
    "executionInfo": {
     "elapsed": 96765,
     "status": "ok",
     "timestamp": 1621188806396,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "pb5VnDmd5bCe"
   },
   "outputs": [],
   "source": [
    "label, counts = np.unique(Y_traintest, return_counts = True)\n",
    "class_weight = {}\n",
    "for lab, con in zip(label, counts):\n",
    "  class_weight.update({lab: round(max(counts)/con, 2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997bd79",
   "metadata": {
    "id": "GKOHQP5Q5e47"
   },
   "source": [
    "Definimos un callback para el entrenamiento de la red, de tal manera que nos aseguramos que el entrenamiento disminuye el learning rate cuando la pérdida sobre el conjutno de test ya no disminuye y detenemos el entrenamiento cuando dich pérdida tampoco disminuye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b71e7842",
   "metadata": {
    "executionInfo": {
     "elapsed": 96764,
     "status": "ok",
     "timestamp": 1621188806397,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "s_zS0yCB5gZ0"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(factor = 0.5, patience = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d63f00",
   "metadata": {
    "id": "yVvCVm45MlNh"
   },
   "source": [
    "Iteramos la definición y el entrenamiento de la red para no sesgar los resultados según el conjunto de entrenamiento y de test escogido en cada caso. Almacenamos el output de cada iteración para poder representarlos más adelante, evaluando cada red obtenida mediante el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "860ec570",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1433256,
     "status": "ok",
     "timestamp": 1621190142892,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "studied-billy",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d8f46312-b88f-4cc0-a97e-cbdb91bbf7d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for combination 1/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 20s 2s/step - loss: 0.3781 - accuracy: 0.9684 - precision: 0.9740 - recall: 0.9494 - auc: 0.9950 - val_loss: 0.6678 - val_accuracy: 0.8077 - val_precision: 0.8333 - val_recall: 0.6731 - val_auc: 0.8853 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3320 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9976 - val_loss: 0.6445 - val_accuracy: 0.8077 - val_precision: 0.8409 - val_recall: 0.7115 - val_auc: 0.8969 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3160 - accuracy: 0.9810 - precision: 0.9808 - recall: 0.9684 - auc: 0.9980 - val_loss: 0.6274 - val_accuracy: 0.8269 - val_precision: 0.8333 - val_recall: 0.6731 - val_auc: 0.9039 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3073 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9983 - val_loss: 0.6182 - val_accuracy: 0.8269 - val_precision: 0.8261 - val_recall: 0.7308 - val_auc: 0.9078 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2958 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9991 - val_loss: 0.6167 - val_accuracy: 0.8269 - val_precision: 0.8298 - val_recall: 0.7500 - val_auc: 0.9075 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2889 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9988 - val_loss: 0.6053 - val_accuracy: 0.8269 - val_precision: 0.8298 - val_recall: 0.7500 - val_auc: 0.9121 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2780 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.6009 - val_accuracy: 0.8269 - val_precision: 0.8333 - val_recall: 0.7692 - val_auc: 0.9127 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2689 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.6048 - val_accuracy: 0.8269 - val_precision: 0.8298 - val_recall: 0.7500 - val_auc: 0.9102 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2614 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.5917 - val_accuracy: 0.8269 - val_precision: 0.8333 - val_recall: 0.7692 - val_auc: 0.9151 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2557 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5872 - val_accuracy: 0.8269 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9165 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2488 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5838 - val_accuracy: 0.8269 - val_precision: 0.8511 - val_recall: 0.7692 - val_auc: 0.9172 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2433 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5822 - val_accuracy: 0.8269 - val_precision: 0.8367 - val_recall: 0.7885 - val_auc: 0.9174 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2390 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5779 - val_accuracy: 0.8269 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9190 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2316 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5717 - val_accuracy: 0.8269 - val_precision: 0.8542 - val_recall: 0.7885 - val_auc: 0.9203 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2283 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5714 - val_accuracy: 0.8269 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9199 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2212 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5658 - val_accuracy: 0.8462 - val_precision: 0.8571 - val_recall: 0.8077 - val_auc: 0.9212 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2160 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5677 - val_accuracy: 0.8269 - val_precision: 0.8200 - val_recall: 0.7885 - val_auc: 0.9209 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2123 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5637 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9214 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2088 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5632 - val_accuracy: 0.8269 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9221 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2055 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5604 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1997 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5528 - val_accuracy: 0.8269 - val_precision: 0.8571 - val_recall: 0.8077 - val_auc: 0.9253 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1962 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9251 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1932 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9252 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1907 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9254 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1869 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.8269 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9248 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1845 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9240 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1805 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5444 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9249 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1779 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9266 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1756 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9270 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1729 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9268 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1702 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5361 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9264 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1669 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9264 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1646 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9264 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1630 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5332 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9262 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1610 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9257 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 998ms/step - loss: 0.1589 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9259 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1572 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9270 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1544 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5287 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9271 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1528 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9275 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1503 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5241 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9277 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1483 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5235 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1461 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1453 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5214 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1437 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1416 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9274 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1395 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1385 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9264 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1377 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1350 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1335 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5157 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1324 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1315 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1294 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1280 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1272 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9268 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1256 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1252 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1231 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1223 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1207 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1198 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1186 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1176 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1162 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9288 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1166 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1142 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9291 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1132 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1131 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1112 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1105 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1093 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9289 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1089 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1079 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1065 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1049 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9288 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1032 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1025 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1019 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1008 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1003 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0991 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0985 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9289 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0978 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0978 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0961 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0956 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0950 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9301 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0944 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9301 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 8s 990ms/step - loss: 0.0938 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0931 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0927 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0917 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9306 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0910 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0914 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0900 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9306 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0895 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9298 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0886 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0880 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0869 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0863 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0858 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0855 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0851 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0849 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0848 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0845 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0843 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0838 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0836 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0834 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9306 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0831 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0828 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0827 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0824 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0822 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9306 - lr: 5.0000e-04\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0819 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 5.0000e-04\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0817 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 5.0000e-04\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0813 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0810 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0809 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0808 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0807 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0805 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0804 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 1.2500e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0804 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 1.2500e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0803 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 1.2500e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0803 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 1.2500e-04\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0802 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 1.2500e-04\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 3.1250e-05\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 3.1250e-05\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.5625e-05\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.5625e-05\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.5625e-05\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.5625e-05\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.5625e-05\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 7.8125e-06\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 7.8125e-06\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 7.8125e-06\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 7.8125e-06\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 7.8125e-06\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.9063e-06\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.9063e-06\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.9063e-06\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.9063e-06\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.9063e-06\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.9531e-06\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.9531e-06\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.9531e-06\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.9531e-06\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.9531e-06\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 9.7656e-07\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 9.7656e-07\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 9.7656e-07\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 9.7656e-07\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 9.7656e-07\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 4.8828e-07\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 4.8828e-07\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 4.8828e-07\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 4.8828e-07\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 4.8828e-07\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 2.4414e-07\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 2.4414e-07\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 2.4414e-07\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 2.4414e-07\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 2.4414e-07\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.2207e-07\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.2207e-07\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.2207e-07\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.2207e-07\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.2207e-07\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 6.1035e-08\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 6.1035e-08\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 6.1035e-08\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 6.1035e-08\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 6.1035e-08\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.0518e-08\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.0518e-08\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.0518e-08\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.0518e-08\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 3.0518e-08\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.5259e-08\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.5259e-08\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.5259e-08\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.5259e-08\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 1.5259e-08\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 7.6294e-09\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.63; accuracy of 75.0%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 1s/step - loss: 0.5233 - accuracy: 0.8861 - precision: 0.9291 - recall: 0.8291 - auc: 0.9704 - val_loss: 0.3721 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4724 - accuracy: 0.9494 - precision: 0.9470 - recall: 0.9051 - auc: 0.9827 - val_loss: 0.3670 - val_accuracy: 0.9231 - val_precision: 0.9583 - val_recall: 0.8846 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4615 - accuracy: 0.9367 - precision: 0.9527 - recall: 0.8924 - auc: 0.9845 - val_loss: 0.3529 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4388 - accuracy: 0.9494 - precision: 0.9539 - recall: 0.9177 - auc: 0.9868 - val_loss: 0.3506 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4300 - accuracy: 0.9494 - precision: 0.9481 - recall: 0.9241 - auc: 0.9866 - val_loss: 0.3464 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4156 - accuracy: 0.9494 - precision: 0.9484 - recall: 0.9304 - auc: 0.9884 - val_loss: 0.3473 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4059 - accuracy: 0.9494 - precision: 0.9484 - recall: 0.9304 - auc: 0.9889 - val_loss: 0.3367 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3916 - accuracy: 0.9557 - precision: 0.9548 - recall: 0.9367 - auc: 0.9900 - val_loss: 0.3331 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3824 - accuracy: 0.9557 - precision: 0.9548 - recall: 0.9367 - auc: 0.9899 - val_loss: 0.3265 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3742 - accuracy: 0.9620 - precision: 0.9677 - recall: 0.9494 - auc: 0.9917 - val_loss: 0.3257 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3614 - accuracy: 0.9557 - precision: 0.9551 - recall: 0.9430 - auc: 0.9916 - val_loss: 0.3212 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3571 - accuracy: 0.9557 - precision: 0.9554 - recall: 0.9494 - auc: 0.9917 - val_loss: 0.3171 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3444 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9926 - val_loss: 0.3168 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3375 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9923 - val_loss: 0.3132 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3357 - accuracy: 0.9620 - precision: 0.9740 - recall: 0.9494 - auc: 0.9934 - val_loss: 0.3138 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3226 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9939 - val_loss: 0.3095 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3178 - accuracy: 0.9620 - precision: 0.9682 - recall: 0.9620 - auc: 0.9939 - val_loss: 0.3076 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3112 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9940 - val_loss: 0.3068 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3060 - accuracy: 0.9620 - precision: 0.9618 - recall: 0.9557 - auc: 0.9942 - val_loss: 0.3038 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2994 - accuracy: 0.9620 - precision: 0.9682 - recall: 0.9620 - auc: 0.9950 - val_loss: 0.3019 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2960 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9955 - val_loss: 0.3010 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2891 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9951 - val_loss: 0.2995 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2848 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9953 - val_loss: 0.2993 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2803 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9952 - val_loss: 0.2973 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2747 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9956 - val_loss: 0.2965 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2712 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9964 - val_loss: 0.2948 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2677 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9962 - val_loss: 0.2941 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2644 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9960 - val_loss: 0.2931 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2579 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9964 - val_loss: 0.2927 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2547 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9963 - val_loss: 0.2914 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2502 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9967 - val_loss: 0.2906 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2479 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9967 - val_loss: 0.2896 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2446 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9970 - val_loss: 0.2891 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2410 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9967 - val_loss: 0.2883 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2369 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9970 - val_loss: 0.2879 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2339 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9971 - val_loss: 0.2889 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2316 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9974 - val_loss: 0.2869 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2287 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9971 - val_loss: 0.2867 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2268 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9973 - val_loss: 0.2862 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2232 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9975 - val_loss: 0.2859 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2206 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9973 - val_loss: 0.2856 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2181 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9977 - val_loss: 0.2841 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2159 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9976 - val_loss: 0.2839 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2137 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9978 - val_loss: 0.2835 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2129 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9975 - val_loss: 0.2832 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2090 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9980 - val_loss: 0.2836 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2059 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9982 - val_loss: 0.2828 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2031 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9982 - val_loss: 0.2826 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2032 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9981 - val_loss: 0.2825 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1991 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9983 - val_loss: 0.2820 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1977 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9983 - val_loss: 0.2816 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 995ms/step - loss: 0.1947 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9983 - val_loss: 0.2818 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1934 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9984 - val_loss: 0.2810 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1920 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9984 - val_loss: 0.2813 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1903 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9985 - val_loss: 0.2808 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1866 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9986 - val_loss: 0.2805 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1866 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9984 - val_loss: 0.2803 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1841 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9987 - val_loss: 0.2801 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1835 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9984 - val_loss: 0.2802 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1807 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9987 - val_loss: 0.2800 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1788 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9987 - val_loss: 0.2810 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1778 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2798 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1751 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2796 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1753 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9991 - val_loss: 0.2794 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1727 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2792 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1708 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2791 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1705 - accuracy: 0.9810 - precision: 0.9873 - recall: 0.9810 - auc: 0.9989 - val_loss: 0.2799 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1686 - accuracy: 0.9747 - precision: 0.9872 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1662 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9992 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1659 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2797 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9763 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1645 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9993 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9764 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1631 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9992 - val_loss: 0.2792 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1621 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9993 - val_loss: 0.2792 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9767 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1622 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9992 - val_loss: 0.2791 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9767 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1610 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2790 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9767 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1609 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9992 - val_loss: 0.2791 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1597 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2789 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1595 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2789 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1584 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2789 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1582 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2789 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9764 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1578 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2789 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9775 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1570 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2788 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9764 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1559 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2788 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9763 - lr: 2.5000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1554 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2788 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9763 - lr: 2.5000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1551 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2788 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9761 - lr: 2.5000e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1547 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2788 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9761 - lr: 2.5000e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1546 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2788 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9762 - lr: 2.5000e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1544 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9400 - val_recall: 0.9038 - val_auc: 0.9763 - lr: 2.5000e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1541 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9765 - lr: 2.5000e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1535 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9763 - lr: 1.2500e-04\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1534 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 1.2500e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1532 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9765 - lr: 1.2500e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1531 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9765 - lr: 1.2500e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1530 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9765 - lr: 1.2500e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 8s 988ms/step - loss: 0.1528 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9765 - lr: 6.2500e-05\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1527 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9765 - lr: 6.2500e-05\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1526 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9765 - lr: 6.2500e-05\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1525 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9765 - lr: 6.2500e-05\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1525 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9765 - lr: 6.2500e-05\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1524 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 3.1250e-05\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1523 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 3.1250e-05\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1522 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 3.1250e-05\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1522 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 3.1250e-05\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1522 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9763 - lr: 3.1250e-05\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1521 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2789 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9763 - lr: 1.5625e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.62; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.63 - Accuracy: 0.75%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.62 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0):\n",
      "> Accuracy: 0.76 (+- 0.01)\n",
      "> Loss: 0.63 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 2/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 18s 2s/step - loss: 0.3688 - accuracy: 0.9747 - precision: 0.9742 - recall: 0.9557 - auc: 0.9946 - val_loss: 0.6357 - val_accuracy: 0.8269 - val_precision: 0.8372 - val_recall: 0.6923 - val_auc: 0.9005 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3170 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9986 - val_loss: 0.6278 - val_accuracy: 0.8462 - val_precision: 0.8261 - val_recall: 0.7308 - val_auc: 0.9020 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1667 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1596 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5356 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9247 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1346 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5173 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1319 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.8269 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9277 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1284 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1265 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1237 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1220 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5122 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9274 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1189 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1163 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1158 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9295 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1138 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.8269 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9275 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1035 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1023 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9298 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1005 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0994 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9289 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0971 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9292 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0959 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0943 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0940 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0921 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9292 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0905 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0894 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0884 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9298 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0877 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0865 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0851 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0840 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9306 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0787 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9313 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0784 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0779 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9313 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0772 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9312 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0769 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9315 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0764 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9318 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0762 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0762 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0754 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9318 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0750 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9315 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0745 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9314 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0740 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9314 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0739 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9320 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0731 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0729 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9320 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0725 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9319 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0720 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9322 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0717 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9322 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0715 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9323 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0707 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9320 - lr: 2.5000e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0707 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9320 - lr: 2.5000e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0706 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9325 - lr: 2.5000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0704 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9324 - lr: 2.5000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0701 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9323 - lr: 2.5000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0700 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9322 - lr: 2.5000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0698 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9324 - lr: 1.2500e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0697 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9325 - lr: 1.2500e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0696 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9324 - lr: 1.2500e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0695 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9325 - lr: 1.2500e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0694 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9325 - lr: 1.2500e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0693 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9323 - lr: 6.2500e-05\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0693 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 6.2500e-05\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0692 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 6.2500e-05\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0691 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9327 - lr: 6.2500e-05\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0691 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 6.2500e-05\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0691 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 3.1250e-05\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0691 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 3.1250e-05\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0690 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9327 - lr: 3.1250e-05\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0690 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9327 - lr: 3.1250e-05\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0690 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9327 - lr: 3.1250e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.63; accuracy of 75.0%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 1s/step - loss: 0.5294 - accuracy: 0.9177 - precision: 0.9315 - recall: 0.8608 - auc: 0.9745 - val_loss: 0.3738 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4590 - accuracy: 0.9367 - precision: 0.9470 - recall: 0.9051 - auc: 0.9818 - val_loss: 0.3479 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4321 - accuracy: 0.9430 - precision: 0.9548 - recall: 0.9367 - auc: 0.9854 - val_loss: 0.3428 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4070 - accuracy: 0.9494 - precision: 0.9545 - recall: 0.9304 - auc: 0.9913 - val_loss: 0.3557 - val_accuracy: 0.9423 - val_precision: 0.9388 - val_recall: 0.8846 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3937 - accuracy: 0.9557 - precision: 0.9613 - recall: 0.9430 - auc: 0.9891 - val_loss: 0.3320 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3600 - accuracy: 0.9620 - precision: 0.9677 - recall: 0.9494 - auc: 0.9920 - val_loss: 0.3186 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3445 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9924 - val_loss: 0.3142 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3353 - accuracy: 0.9620 - precision: 0.9682 - recall: 0.9620 - auc: 0.9927 - val_loss: 0.3131 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3225 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9938 - val_loss: 0.3067 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3087 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9946 - val_loss: 0.3034 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2950 - accuracy: 0.9684 - precision: 0.9808 - recall: 0.9684 - auc: 0.9948 - val_loss: 0.3005 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2841 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9959 - val_loss: 0.2974 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2762 - accuracy: 0.9810 - precision: 0.9808 - recall: 0.9684 - auc: 0.9953 - val_loss: 0.2968 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2704 - accuracy: 0.9747 - precision: 0.9745 - recall: 0.9684 - auc: 0.9958 - val_loss: 0.2950 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2588 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9963 - val_loss: 0.2911 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2510 - accuracy: 0.9810 - precision: 0.9808 - recall: 0.9684 - auc: 0.9968 - val_loss: 0.2966 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2492 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9963 - val_loss: 0.2884 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2375 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9970 - val_loss: 0.2877 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2296 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9972 - val_loss: 0.2878 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2269 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9973 - val_loss: 0.2852 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2196 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9975 - val_loss: 0.2842 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2139 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9978 - val_loss: 0.2836 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2098 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9979 - val_loss: 0.2836 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2047 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9980 - val_loss: 0.2830 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2030 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9980 - val_loss: 0.2822 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1982 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9981 - val_loss: 0.2811 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1927 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9982 - val_loss: 0.2819 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1874 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9985 - val_loss: 0.2810 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1868 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9986 - val_loss: 0.2809 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1817 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9986 - val_loss: 0.2810 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1813 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9983 - val_loss: 0.2801 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1752 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9987 - val_loss: 0.2799 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1731 - accuracy: 0.9747 - precision: 0.9872 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2806 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1688 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9991 - val_loss: 0.2802 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1672 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2794 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1649 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1385 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 2.5000e-04\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1380 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 2.5000e-04\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1378 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9759 - lr: 2.5000e-04\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1370 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 2.5000e-04\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1369 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9756 - lr: 2.5000e-04\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1361 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9756 - lr: 1.2500e-04\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1359 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9756 - lr: 1.2500e-04\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1358 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 1.2500e-04\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1355 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 1.2500e-04\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1353 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 1.2500e-04\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1348 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2800 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 6.2500e-05\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1348 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2800 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 6.2500e-05\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1346 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2800 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 6.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.62; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.63 - Accuracy: 0.75%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.62 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0.5):\n",
      "> Accuracy: 0.76 (+- 0.01)\n",
      "> Loss: 0.63 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 3/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 18s 1s/step - loss: 0.3677 - accuracy: 0.9684 - precision: 0.9805 - recall: 0.9557 - auc: 0.9968 - val_loss: 0.6007 - val_accuracy: 0.7885 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9112 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3290 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9970 - val_loss: 0.6177 - val_accuracy: 0.7308 - val_precision: 0.7347 - val_recall: 0.6923 - val_auc: 0.8988 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2159 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5789 - val_accuracy: 0.7500 - val_precision: 0.8125 - val_recall: 0.7500 - val_auc: 0.9092 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1874 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5238 - val_accuracy: 0.8077 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9248 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 994ms/step - loss: 0.1525 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9261 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1327 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8077 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9314 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1177 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.8462 - val_precision: 0.8600 - val_recall: 0.8269 - val_auc: 0.9252 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 974ms/step - loss: 0.1025 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8077 - val_precision: 0.8077 - val_recall: 0.8077 - val_auc: 0.9316 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0941 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.8654 - val_precision: 0.8627 - val_recall: 0.8462 - val_auc: 0.9274 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0871 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.8269 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9334 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9343 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9328 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0712 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9339 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0666 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9340 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0638 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9342 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0607 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9349 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0582 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9341 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0554 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9344 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0536 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4801 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9357 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 7s 949ms/step - loss: 0.0519 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9350 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0493 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4827 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9348 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0485 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9342 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0484 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.8077 - val_precision: 0.8077 - val_recall: 0.8077 - val_auc: 0.9352 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 7s 908ms/step - loss: 0.0344 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9360 - lr: 2.5000e-04\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0342 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9359 - lr: 1.2500e-04\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0340 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9358 - lr: 1.2500e-04\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0339 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9356 - lr: 1.2500e-04\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0338 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9356 - lr: 1.2500e-04\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0336 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9356 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.65; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 1s/step - loss: 0.5420 - accuracy: 0.8861 - precision: 0.9379 - recall: 0.8608 - auc: 0.9725 - val_loss: 0.3939 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9656 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.5132 - accuracy: 0.8861 - precision: 0.9122 - recall: 0.8544 - auc: 0.9726 - val_loss: 0.3399 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9765 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3635 - accuracy: 0.9241 - precision: 0.9359 - recall: 0.9241 - auc: 0.9849 - val_loss: 0.3028 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9759 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3013 - accuracy: 0.9557 - precision: 0.9615 - recall: 0.9494 - auc: 0.9929 - val_loss: 0.3243 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9734 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2405 - accuracy: 0.9620 - precision: 0.9615 - recall: 0.9494 - auc: 0.9932 - val_loss: 0.2822 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1859 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9988 - val_loss: 0.2827 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9749 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1646 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2745 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 7s 954ms/step - loss: 0.1537 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9989 - val_loss: 0.2756 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1384 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9735 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1313 - accuracy: 0.9810 - precision: 0.9873 - recall: 0.9810 - auc: 0.9996 - val_loss: 0.2887 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9742 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1023 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.2877 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9734 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1007 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.2873 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9736 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0976 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.2885 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9731 - lr: 5.0000e-04\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0947 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2878 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9729 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0927 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2868 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9731 - lr: 2.5000e-04\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0909 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2870 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9728 - lr: 2.5000e-04\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 7s 967ms/step - loss: 0.0899 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2877 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9730 - lr: 2.5000e-04\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 986ms/step - loss: 0.0887 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2886 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9727 - lr: 2.5000e-04\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0887 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2891 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9726 - lr: 2.5000e-04\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 7s 834ms/step - loss: 0.0867 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2892 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9727 - lr: 1.2500e-04\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0865 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2899 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9727 - lr: 1.2500e-04\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0858 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2900 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9726 - lr: 1.2500e-04\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0853 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2903 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9727 - lr: 1.2500e-04\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0847 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2904 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9727 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.64; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.65 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.64 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0.9):\n",
      "> Accuracy: 0.77 (+- 0.0)\n",
      "> Loss: 0.64 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 4/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 1s/step - loss: 0.3764 - accuracy: 0.9620 - precision: 0.9799 - recall: 0.9241 - auc: 0.9958 - val_loss: 0.6649 - val_accuracy: 0.8077 - val_precision: 0.8372 - val_recall: 0.6923 - val_auc: 0.8860 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3291 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9975 - val_loss: 0.6410 - val_accuracy: 0.8462 - val_precision: 0.8182 - val_recall: 0.6923 - val_auc: 0.8988 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3199 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9977 - val_loss: 0.6257 - val_accuracy: 0.8077 - val_precision: 0.8571 - val_recall: 0.6923 - val_auc: 0.9058 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3046 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9986 - val_loss: 0.6153 - val_accuracy: 0.8269 - val_precision: 0.8478 - val_recall: 0.7500 - val_auc: 0.9089 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2958 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9991 - val_loss: 0.6132 - val_accuracy: 0.8269 - val_precision: 0.8261 - val_recall: 0.7308 - val_auc: 0.9086 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 998ms/step - loss: 0.2854 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.6069 - val_accuracy: 0.8269 - val_precision: 0.8298 - val_recall: 0.7500 - val_auc: 0.9106 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2806 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.6010 - val_accuracy: 0.8269 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9131 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2710 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9996 - val_loss: 0.5953 - val_accuracy: 0.8269 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9140 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 991ms/step - loss: 0.2629 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.5938 - val_accuracy: 0.8269 - val_precision: 0.8200 - val_recall: 0.7885 - val_auc: 0.9145 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2580 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9996 - val_loss: 0.5932 - val_accuracy: 0.8269 - val_precision: 0.8200 - val_recall: 0.7885 - val_auc: 0.9137 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2489 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5866 - val_accuracy: 0.8269 - val_precision: 0.8200 - val_recall: 0.7885 - val_auc: 0.9154 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2429 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5816 - val_accuracy: 0.8269 - val_precision: 0.8367 - val_recall: 0.7885 - val_auc: 0.9181 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2371 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5749 - val_accuracy: 0.8269 - val_precision: 0.8542 - val_recall: 0.7885 - val_auc: 0.9191 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2323 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5699 - val_accuracy: 0.8269 - val_precision: 0.8542 - val_recall: 0.7885 - val_auc: 0.9210 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2267 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5703 - val_accuracy: 0.8269 - val_precision: 0.8200 - val_recall: 0.7885 - val_auc: 0.9201 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2208 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5657 - val_accuracy: 0.8462 - val_precision: 0.8367 - val_recall: 0.7885 - val_auc: 0.9216 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2169 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5651 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9220 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2134 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5646 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9210 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2087 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5621 - val_accuracy: 0.8269 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9213 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2067 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5613 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9216 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2021 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5598 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9220 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1970 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5509 - val_accuracy: 0.8269 - val_precision: 0.8571 - val_recall: 0.8077 - val_auc: 0.9253 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 7s 932ms/step - loss: 0.1933 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9254 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1894 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.8269 - val_precision: 0.8600 - val_recall: 0.8269 - val_auc: 0.9253 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1873 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5481 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1839 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5434 - val_accuracy: 0.8269 - val_precision: 0.8600 - val_recall: 0.8269 - val_auc: 0.9256 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1807 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9252 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1779 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9259 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 7s 966ms/step - loss: 0.1749 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9265 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1727 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9267 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 7s 902ms/step - loss: 0.1716 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9257 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1687 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5338 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9264 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1652 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9265 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1627 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9273 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1607 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5290 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 965ms/step - loss: 0.1582 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9275 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1572 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5290 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9270 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1539 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5271 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9275 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1529 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1504 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5265 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9275 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1487 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5244 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1461 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1445 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5209 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1426 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1418 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1398 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1386 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1367 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1354 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1337 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1328 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1313 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 7s 923ms/step - loss: 0.1299 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1285 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1268 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1257 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1241 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1233 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9285 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1218 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1204 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1193 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1195 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1175 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9277 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1164 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 8s 976ms/step - loss: 0.1160 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1145 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 7s 959ms/step - loss: 0.1137 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 7s 884ms/step - loss: 0.1124 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 8s 996ms/step - loss: 0.1113 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9285 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1100 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1094 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1091 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1074 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1068 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9275 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1060 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9275 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9285 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1041 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1033 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1028 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 8s 991ms/step - loss: 0.1023 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9291 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 7s 899ms/step - loss: 0.1012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9291 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1008 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9290 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1003 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0996 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0992 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0988 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0987 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0982 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0977 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0974 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0973 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9298 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 8s 981ms/step - loss: 0.0967 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0964 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9301 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0960 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 7s 939ms/step - loss: 0.0956 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0952 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0950 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0946 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0943 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0940 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9301 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 8s 989ms/step - loss: 0.0936 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9301 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 8s 993ms/step - loss: 0.0932 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 7s 966ms/step - loss: 0.0930 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0926 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0922 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0920 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9301 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 8s 998ms/step - loss: 0.0917 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0914 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0912 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 7s 917ms/step - loss: 0.0907 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0904 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0900 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0899 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0894 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0893 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9298 - lr: 5.0000e-04\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0891 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9297 - lr: 5.0000e-04\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0887 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 5.0000e-04\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0885 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9301 - lr: 5.0000e-04\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0881 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9301 - lr: 5.0000e-04\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0877 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9302 - lr: 5.0000e-04\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0876 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9298 - lr: 5.0000e-04\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 7s 945ms/step - loss: 0.0870 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 5.0000e-04\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0869 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0864 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0862 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9302 - lr: 5.0000e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 5.0000e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0857 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 5.0000e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0854 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 5.0000e-04\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 8s 979ms/step - loss: 0.0853 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 5.0000e-04\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0849 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9302 - lr: 5.0000e-04\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0847 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 5.0000e-04\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0845 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9302 - lr: 5.0000e-04\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 8s 979ms/step - loss: 0.0841 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 5.0000e-04\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 7s 887ms/step - loss: 0.0839 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 5.0000e-04\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 7s 850ms/step - loss: 0.0836 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9302 - lr: 5.0000e-04\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 7s 868ms/step - loss: 0.0834 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 5.0000e-04\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 7s 979ms/step - loss: 0.0832 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 5.0000e-04\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0828 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 5.0000e-04\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0825 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 7s 914ms/step - loss: 0.0824 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0823 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 5.0000e-04\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0818 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 5.0000e-04\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0815 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0813 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 8s 985ms/step - loss: 0.0812 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0811 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0810 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0808 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0806 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 1.2500e-04\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0806 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 1.2500e-04\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0806 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 1.2500e-04\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0804 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 1.2500e-04\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0805 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 1.2500e-04\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0803 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 7s 938ms/step - loss: 0.0803 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0803 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0802 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0802 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0802 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 6.2500e-05\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 8s 976ms/step - loss: 0.0802 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 3.1250e-05\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 3.1250e-05\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 8s 969ms/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.1250e-05\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 7s 910ms/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.5625e-05\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.5625e-05\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.5625e-05\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.5625e-05\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.5625e-05\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 8s 995ms/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 7.8125e-06\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 7s 946ms/step - loss: 0.0800 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 7.8125e-06\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 7.8125e-06\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 7.8125e-06\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 7.8125e-06\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.9063e-06\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.9063e-06\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 7s 905ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.9063e-06\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.9063e-06\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 3.9063e-06\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 7s 915ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.9531e-06\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.9531e-06\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.9531e-06\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.9531e-06\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 1.9531e-06\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 8s 983ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 9.7656e-07\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 9.7656e-07\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 9.7656e-07\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 9.7656e-07\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 8s 995ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 9.7656e-07\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 4.8828e-07\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 4.8828e-07\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 8s 988ms/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 4.8828e-07\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.63; accuracy of 75.0%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 1s/step - loss: 0.5182 - accuracy: 0.9114 - precision: 0.9241 - recall: 0.8481 - auc: 0.9712 - val_loss: 0.3791 - val_accuracy: 0.9423 - val_precision: 0.9592 - val_recall: 0.9038 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4761 - accuracy: 0.9430 - precision: 0.9467 - recall: 0.8987 - auc: 0.9813 - val_loss: 0.3651 - val_accuracy: 0.9423 - val_precision: 0.9400 - val_recall: 0.9038 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4594 - accuracy: 0.9430 - precision: 0.9539 - recall: 0.9177 - auc: 0.9844 - val_loss: 0.3561 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4425 - accuracy: 0.9430 - precision: 0.9412 - recall: 0.9114 - auc: 0.9852 - val_loss: 0.3447 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4272 - accuracy: 0.9430 - precision: 0.9467 - recall: 0.8987 - auc: 0.9872 - val_loss: 0.3395 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4144 - accuracy: 0.9494 - precision: 0.9490 - recall: 0.9430 - auc: 0.9893 - val_loss: 0.3419 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4025 - accuracy: 0.9494 - precision: 0.9484 - recall: 0.9304 - auc: 0.9881 - val_loss: 0.3317 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3957 - accuracy: 0.9367 - precision: 0.9539 - recall: 0.9177 - auc: 0.9895 - val_loss: 0.3297 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3855 - accuracy: 0.9494 - precision: 0.9551 - recall: 0.9430 - auc: 0.9897 - val_loss: 0.3269 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3743 - accuracy: 0.9557 - precision: 0.9615 - recall: 0.9494 - auc: 0.9907 - val_loss: 0.3273 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3636 - accuracy: 0.9557 - precision: 0.9615 - recall: 0.9494 - auc: 0.9915 - val_loss: 0.3222 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3532 - accuracy: 0.9620 - precision: 0.9682 - recall: 0.9620 - auc: 0.9925 - val_loss: 0.3218 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 985ms/step - loss: 0.3456 - accuracy: 0.9557 - precision: 0.9615 - recall: 0.9494 - auc: 0.9919 - val_loss: 0.3160 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 976ms/step - loss: 0.3383 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9931 - val_loss: 0.3140 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3310 - accuracy: 0.9620 - precision: 0.9682 - recall: 0.9620 - auc: 0.9936 - val_loss: 0.3122 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 7s 899ms/step - loss: 0.3229 - accuracy: 0.9620 - precision: 0.9682 - recall: 0.9620 - auc: 0.9935 - val_loss: 0.3107 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3186 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9940 - val_loss: 0.3073 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3096 - accuracy: 0.9620 - precision: 0.9682 - recall: 0.9620 - auc: 0.9944 - val_loss: 0.3051 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3061 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9944 - val_loss: 0.3042 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2999 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9947 - val_loss: 0.3033 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2941 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9951 - val_loss: 0.3022 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2890 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9954 - val_loss: 0.3004 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2865 - accuracy: 0.9620 - precision: 0.9682 - recall: 0.9620 - auc: 0.9945 - val_loss: 0.2984 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2799 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9954 - val_loss: 0.2973 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2753 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9958 - val_loss: 0.2970 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2714 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9956 - val_loss: 0.2950 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2682 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9963 - val_loss: 0.2940 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2643 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9962 - val_loss: 0.2929 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2576 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9967 - val_loss: 0.2925 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2539 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9966 - val_loss: 0.2913 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2520 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9964 - val_loss: 0.2914 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2470 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9968 - val_loss: 0.2902 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2444 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9966 - val_loss: 0.2896 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2413 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9968 - val_loss: 0.2885 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2402 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9969 - val_loss: 0.2883 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2374 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9968 - val_loss: 0.2879 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2317 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9973 - val_loss: 0.2874 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2281 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9971 - val_loss: 0.2872 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2279 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9972 - val_loss: 0.2869 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2236 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9975 - val_loss: 0.2856 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2203 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9975 - val_loss: 0.2864 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2179 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9977 - val_loss: 0.2857 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2157 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9978 - val_loss: 0.2859 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2135 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9981 - val_loss: 0.2846 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 7s 926ms/step - loss: 0.2142 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9977 - val_loss: 0.2836 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2091 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9977 - val_loss: 0.2838 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2064 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9983 - val_loss: 0.2827 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2052 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9981 - val_loss: 0.2824 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2034 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9980 - val_loss: 0.2821 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2026 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9981 - val_loss: 0.2824 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 7s 933ms/step - loss: 0.1965 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9983 - val_loss: 0.2817 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1982 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9983 - val_loss: 0.2843 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 7s 920ms/step - loss: 0.1931 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9983 - val_loss: 0.2811 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1913 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9985 - val_loss: 0.2814 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1885 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9986 - val_loss: 0.2813 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1873 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9985 - val_loss: 0.2807 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 8s 995ms/step - loss: 0.1869 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9984 - val_loss: 0.2809 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1852 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9985 - val_loss: 0.2805 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1835 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9986 - val_loss: 0.2805 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 7s 930ms/step - loss: 0.1807 - accuracy: 0.9810 - precision: 0.9873 - recall: 0.9810 - auc: 0.9987 - val_loss: 0.2802 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1785 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9988 - val_loss: 0.2801 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1766 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9988 - val_loss: 0.2803 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1758 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2803 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1744 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 8s 982ms/step - loss: 0.1725 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2798 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1706 - accuracy: 0.9810 - precision: 0.9873 - recall: 0.9810 - auc: 0.9990 - val_loss: 0.2803 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9765 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1691 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9992 - val_loss: 0.2797 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1692 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2800 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1683 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2803 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9761 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1652 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9992 - val_loss: 0.2797 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9766 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1643 - accuracy: 0.9747 - precision: 0.9872 - recall: 0.9747 - auc: 0.9992 - val_loss: 0.2795 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9784 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.1636 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9992 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1631 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9993 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1619 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9992 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 7s 960ms/step - loss: 0.1617 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1612 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9993 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1603 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1606 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9992 - val_loss: 0.2795 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1590 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2795 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 2.5000e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 8s 996ms/step - loss: 0.1583 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 2.5000e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1580 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 2.5000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1579 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 2.5000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1574 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9768 - lr: 2.5000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1570 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 1.2500e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1567 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9764 - lr: 1.2500e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1566 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 1.2500e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1565 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 1.2500e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 7s 914ms/step - loss: 0.1564 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 1.2500e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 8s 1000ms/step - loss: 0.1561 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 6.2500e-05\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 6s 831ms/step - loss: 0.1561 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 6.2500e-05\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1560 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 6.2500e-05\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1559 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9423 - val_precision: 0.9400 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 6.2500e-05\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1559 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9400 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 6.2500e-05\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1557 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 3.1250e-05\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1556 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 3.1250e-05\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1556 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 3.1250e-05\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1556 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 3.1250e-05\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1556 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 3.1250e-05\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1555 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 1.5625e-05\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1555 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 1.5625e-05\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1555 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 1.5625e-05\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 7s 962ms/step - loss: 0.1554 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 1.5625e-05\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1554 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 1.5625e-05\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1554 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 7.8125e-06\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 8s 999ms/step - loss: 0.1554 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9766 - lr: 7.8125e-06\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.62; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.63 - Accuracy: 0.75%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.62 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0):\n",
      "> Accuracy: 0.76 (+- 0.01)\n",
      "> Loss: 0.62 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 5/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 21s 1s/step - loss: 0.3759 - accuracy: 0.9557 - precision: 0.9733 - recall: 0.9241 - auc: 0.9950 - val_loss: 0.6365 - val_accuracy: 0.8269 - val_precision: 0.8372 - val_recall: 0.6923 - val_auc: 0.9006 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3195 - accuracy: 0.9810 - precision: 0.9808 - recall: 0.9684 - auc: 0.9978 - val_loss: 0.6184 - val_accuracy: 0.8269 - val_precision: 0.8636 - val_recall: 0.7308 - val_auc: 0.9076 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2953 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.6194 - val_accuracy: 0.8269 - val_precision: 0.8333 - val_recall: 0.7692 - val_auc: 0.9050 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2767 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.5975 - val_accuracy: 0.8269 - val_precision: 0.8298 - val_recall: 0.7500 - val_auc: 0.9136 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2624 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.5863 - val_accuracy: 0.8269 - val_precision: 0.8298 - val_recall: 0.7500 - val_auc: 0.9177 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2460 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5827 - val_accuracy: 0.8269 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9173 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2352 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5734 - val_accuracy: 0.8269 - val_precision: 0.8200 - val_recall: 0.7885 - val_auc: 0.9195 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2258 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5653 - val_accuracy: 0.8269 - val_precision: 0.8367 - val_recall: 0.7885 - val_auc: 0.9207 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2167 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.8269 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9189 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 957ms/step - loss: 0.2104 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5586 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9223 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1984 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5536 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9248 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 996ms/step - loss: 0.1927 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5481 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9249 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1854 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5434 - val_accuracy: 0.8462 - val_precision: 0.8333 - val_recall: 0.7692 - val_auc: 0.9259 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1805 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.8077 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9251 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1750 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9243 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1707 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1664 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5305 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9271 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1598 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9260 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1548 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.8269 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9277 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 7s 931ms/step - loss: 0.1511 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5297 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9257 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1484 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1444 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5185 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1412 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1399 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1349 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5200 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9271 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1323 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 988ms/step - loss: 0.1294 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5152 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1255 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1240 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1221 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9271 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1192 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 986ms/step - loss: 0.1162 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1148 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1126 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1104 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1088 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1069 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9285 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1052 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 8s 981ms/step - loss: 0.1037 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5026 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9275 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9290 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1004 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 7s 932ms/step - loss: 0.0994 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0973 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0956 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0946 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0936 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0916 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0906 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0896 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0888 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9301 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0880 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0858 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0848 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0841 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9311 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0828 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0816 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 7s 861ms/step - loss: 0.0809 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9306 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 8s 999ms/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0786 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0780 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9313 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0773 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9312 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0767 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9319 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0755 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9315 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0735 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9320 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0727 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9321 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0722 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9320 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0713 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9323 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0706 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9322 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0700 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0693 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 8s 976ms/step - loss: 0.0688 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9324 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0686 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4887 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0681 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0678 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9326 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0675 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9325 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0671 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9324 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0669 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9325 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0664 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9327 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0661 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9330 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0657 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9325 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0657 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9328 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0653 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9324 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 7s 895ms/step - loss: 0.0651 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9329 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0649 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9329 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0643 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9328 - lr: 2.5000e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 7s 933ms/step - loss: 0.0641 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9329 - lr: 2.5000e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0639 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9331 - lr: 2.5000e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0638 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 2.5000e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0636 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 2.5000e-04\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0635 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9331 - lr: 1.2500e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 1.2500e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 7s 922ms/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 1.2500e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9331 - lr: 1.2500e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 7s 942ms/step - loss: 0.0632 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 1.2500e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.0631 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 6.2500e-05\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0631 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 6.2500e-05\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0630 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 6.2500e-05\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 7s 930ms/step - loss: 0.0630 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9333 - lr: 6.2500e-05\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0629 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 6.2500e-05\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0629 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 3.1250e-05\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 7s 912ms/step - loss: 0.0629 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 3.1250e-05\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0629 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 3.1250e-05\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 8s 983ms/step - loss: 0.0629 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 3.1250e-05\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0628 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 3.1250e-05\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0628 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 1.5625e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.63; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 1s/step - loss: 0.5027 - accuracy: 0.9304 - precision: 0.9463 - recall: 0.8924 - auc: 0.9748 - val_loss: 0.3592 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4560 - accuracy: 0.9367 - precision: 0.9539 - recall: 0.9177 - auc: 0.9845 - val_loss: 0.3449 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4267 - accuracy: 0.9494 - precision: 0.9477 - recall: 0.9177 - auc: 0.9880 - val_loss: 0.3390 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4083 - accuracy: 0.9494 - precision: 0.9484 - recall: 0.9304 - auc: 0.9888 - val_loss: 0.3382 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4049 - accuracy: 0.9241 - precision: 0.9463 - recall: 0.8924 - auc: 0.9867 - val_loss: 0.3265 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3632 - accuracy: 0.9557 - precision: 0.9551 - recall: 0.9430 - auc: 0.9915 - val_loss: 0.3198 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3567 - accuracy: 0.9494 - precision: 0.9490 - recall: 0.9430 - auc: 0.9906 - val_loss: 0.3123 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3346 - accuracy: 0.9557 - precision: 0.9618 - recall: 0.9557 - auc: 0.9933 - val_loss: 0.3097 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 7s 964ms/step - loss: 0.3146 - accuracy: 0.9620 - precision: 0.9677 - recall: 0.9494 - auc: 0.9938 - val_loss: 0.3045 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3043 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9951 - val_loss: 0.3025 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2941 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9947 - val_loss: 0.2988 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2803 - accuracy: 0.9747 - precision: 0.9808 - recall: 0.9684 - auc: 0.9958 - val_loss: 0.2964 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2788 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9961 - val_loss: 0.2991 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2681 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9955 - val_loss: 0.2929 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2591 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9964 - val_loss: 0.2921 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2484 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9965 - val_loss: 0.2895 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2425 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9970 - val_loss: 0.2881 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2383 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9971 - val_loss: 0.2909 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2360 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9969 - val_loss: 0.2858 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2251 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9974 - val_loss: 0.2850 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 7s 962ms/step - loss: 0.2183 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9974 - val_loss: 0.2858 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2150 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9978 - val_loss: 0.2839 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2094 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9980 - val_loss: 0.2840 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 7s 877ms/step - loss: 0.2064 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9977 - val_loss: 0.2827 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2002 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9981 - val_loss: 0.2818 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1996 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9981 - val_loss: 0.2820 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1923 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9986 - val_loss: 0.2809 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1877 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9984 - val_loss: 0.2806 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1850 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9985 - val_loss: 0.2806 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1812 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9987 - val_loss: 0.2800 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1779 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9987 - val_loss: 0.2799 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1759 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2796 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1751 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9984 - val_loss: 0.2800 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1708 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2797 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1657 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9991 - val_loss: 0.2799 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 977ms/step - loss: 0.1631 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9992 - val_loss: 0.2797 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9764 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1600 - accuracy: 0.9810 - precision: 0.9873 - recall: 0.9810 - auc: 0.9992 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9758 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1578 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9763 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1553 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9994 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9762 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1536 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2796 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9756 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1535 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2797 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1482 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2802 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9760 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1457 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2795 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1452 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9760 - lr: 5.0000e-04\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1452 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2795 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 5.0000e-04\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1430 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2795 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9760 - lr: 5.0000e-04\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1436 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2800 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9763 - lr: 5.0000e-04\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1417 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9762 - lr: 5.0000e-04\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1402 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1390 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2795 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9761 - lr: 2.5000e-04\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 7s 960ms/step - loss: 0.1384 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2796 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9761 - lr: 2.5000e-04\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1383 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 2.5000e-04\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 8s 971ms/step - loss: 0.1374 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2797 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 2.5000e-04\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1369 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9758 - lr: 2.5000e-04\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1362 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 1.2500e-04\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1361 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9760 - lr: 1.2500e-04\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1359 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9759 - lr: 1.2500e-04\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 8s 996ms/step - loss: 0.1356 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9758 - lr: 1.2500e-04\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 8s 994ms/step - loss: 0.1357 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 1.2500e-04\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 8s 970ms/step - loss: 0.1352 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9758 - lr: 6.2500e-05\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 7s 964ms/step - loss: 0.1351 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9757 - lr: 6.2500e-05\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1349 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2798 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9758 - lr: 6.2500e-05\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1348 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9758 - lr: 6.2500e-05\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1346 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2799 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9758 - lr: 6.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.62; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.63 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.62 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.5):\n",
      "> Accuracy: 0.75 (+- 0.02)\n",
      "> Loss: 0.63 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 6/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.3886 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9957 - val_loss: 0.6410 - val_accuracy: 0.7500 - val_precision: 0.8085 - val_recall: 0.7308 - val_auc: 0.8923 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2719 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9986 - val_loss: 0.5753 - val_accuracy: 0.8077 - val_precision: 0.8125 - val_recall: 0.7500 - val_auc: 0.9140 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2155 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.8077 - val_precision: 0.8125 - val_recall: 0.7500 - val_auc: 0.9215 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1743 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.8269 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9265 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1474 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1282 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.8077 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9302 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1193 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.8077 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9311 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1024 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0961 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9290 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0879 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9322 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0826 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.8269 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9329 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0772 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9333 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0722 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 999ms/step - loss: 0.0684 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9332 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0656 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9334 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0618 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9340 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 7s 923ms/step - loss: 0.0593 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9342 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0573 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9339 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0547 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0536 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9342 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0525 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9346 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0512 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9347 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0502 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9358 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0495 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9344 - lr: 2.5000e-04\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0487 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9348 - lr: 2.5000e-04\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0484 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9346 - lr: 2.5000e-04\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0477 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9350 - lr: 2.5000e-04\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0476 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9343 - lr: 2.5000e-04\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0472 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9350 - lr: 1.2500e-04\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.0466 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9349 - lr: 1.2500e-04\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0465 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9353 - lr: 1.2500e-04\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 7s 876ms/step - loss: 0.0462 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9350 - lr: 1.2500e-04\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 7s 966ms/step - loss: 0.0460 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9346 - lr: 1.2500e-04\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0458 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9345 - lr: 6.2500e-05\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0457 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9344 - lr: 6.2500e-05\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0456 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9346 - lr: 6.2500e-05\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 8s 997ms/step - loss: 0.0455 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9344 - lr: 6.2500e-05\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0454 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9347 - lr: 6.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.64; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 21s 1s/step - loss: 0.5110 - accuracy: 0.9114 - precision: 0.9521 - recall: 0.8797 - auc: 0.9779 - val_loss: 0.3677 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9724 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4357 - accuracy: 0.9367 - precision: 0.9412 - recall: 0.9114 - auc: 0.9882 - val_loss: 0.3504 - val_accuracy: 0.9231 - val_precision: 0.9592 - val_recall: 0.9038 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3357 - accuracy: 0.9430 - precision: 0.9490 - recall: 0.9430 - auc: 0.9908 - val_loss: 0.3280 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9720 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 983ms/step - loss: 0.2810 - accuracy: 0.9430 - precision: 0.9551 - recall: 0.9430 - auc: 0.9964 - val_loss: 0.3442 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9683 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2423 - accuracy: 0.9494 - precision: 0.9494 - recall: 0.9494 - auc: 0.9958 - val_loss: 0.2945 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9747 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1915 - accuracy: 0.9747 - precision: 0.9744 - recall: 0.9620 - auc: 0.9982 - val_loss: 0.2943 - val_accuracy: 0.9038 - val_precision: 0.9200 - val_recall: 0.8846 - val_auc: 0.9742 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1836 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9974 - val_loss: 0.2851 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1568 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9987 - val_loss: 0.3017 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9713 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1581 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9987 - val_loss: 0.2889 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9748 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1403 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2811 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9753 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1241 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.2831 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9730 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1191 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2842 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9722 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1183 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2879 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9732 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1027 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2894 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9749 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0985 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.2873 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9728 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0918 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2901 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9726 - lr: 5.0000e-04\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0889 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2905 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9726 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0864 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2906 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9726 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 7s 952ms/step - loss: 0.0848 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2904 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0845 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2923 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 969ms/step - loss: 0.0837 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2919 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9728 - lr: 2.5000e-04\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0800 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2917 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9721 - lr: 2.5000e-04\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0787 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2926 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9726 - lr: 2.5000e-04\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0781 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2927 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9724 - lr: 2.5000e-04\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0777 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2935 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9725 - lr: 2.5000e-04\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0765 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9727 - lr: 1.2500e-04\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0760 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9728 - lr: 1.2500e-04\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0756 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9726 - lr: 1.2500e-04\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 7s 945ms/step - loss: 0.0753 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9728 - lr: 1.2500e-04\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0749 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9727 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.63; accuracy of 75.0%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.64 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.63 - Accuracy: 0.75%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.9):\n",
      "> Accuracy: 0.76 (+- 0.01)\n",
      "> Loss: 0.64 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 7/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.3759 - accuracy: 0.9747 - precision: 0.9803 - recall: 0.9430 - auc: 0.9950 - val_loss: 0.6680 - val_accuracy: 0.8077 - val_precision: 0.8372 - val_recall: 0.6923 - val_auc: 0.8858 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 982ms/step - loss: 0.3318 - accuracy: 0.9810 - precision: 0.9808 - recall: 0.9684 - auc: 0.9977 - val_loss: 0.6402 - val_accuracy: 0.7885 - val_precision: 0.8571 - val_recall: 0.6923 - val_auc: 0.8992 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3185 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9983 - val_loss: 0.6282 - val_accuracy: 0.8269 - val_precision: 0.8372 - val_recall: 0.6923 - val_auc: 0.9040 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3061 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9988 - val_loss: 0.6224 - val_accuracy: 0.8269 - val_precision: 0.8261 - val_recall: 0.7308 - val_auc: 0.9038 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2942 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9988 - val_loss: 0.6087 - val_accuracy: 0.8269 - val_precision: 0.8261 - val_recall: 0.7308 - val_auc: 0.9112 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2886 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.6067 - val_accuracy: 0.8269 - val_precision: 0.8298 - val_recall: 0.7500 - val_auc: 0.9111 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2768 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.6034 - val_accuracy: 0.8269 - val_precision: 0.8333 - val_recall: 0.7692 - val_auc: 0.9116 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2726 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.5940 - val_accuracy: 0.8269 - val_precision: 0.8333 - val_recall: 0.7692 - val_auc: 0.9142 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2619 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.5948 - val_accuracy: 0.8269 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9136 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2562 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5895 - val_accuracy: 0.8269 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9154 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2493 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5825 - val_accuracy: 0.8269 - val_precision: 0.8333 - val_recall: 0.7692 - val_auc: 0.9184 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2437 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5785 - val_accuracy: 0.8269 - val_precision: 0.8333 - val_recall: 0.7692 - val_auc: 0.9178 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2368 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5752 - val_accuracy: 0.8462 - val_precision: 0.8723 - val_recall: 0.7885 - val_auc: 0.9197 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2321 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5730 - val_accuracy: 0.8462 - val_precision: 0.8571 - val_recall: 0.8077 - val_auc: 0.9208 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2268 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5740 - val_accuracy: 0.8269 - val_precision: 0.8200 - val_recall: 0.7885 - val_auc: 0.9192 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2225 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5669 - val_accuracy: 0.8462 - val_precision: 0.8571 - val_recall: 0.8077 - val_auc: 0.9215 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2163 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5656 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9217 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2146 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5608 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9233 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 7s 923ms/step - loss: 0.2079 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5571 - val_accuracy: 0.8462 - val_precision: 0.8542 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2038 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5562 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2007 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8462 - val_precision: 0.8367 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1958 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9253 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1942 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.8269 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9251 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 7s 951ms/step - loss: 0.1897 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5473 - val_accuracy: 0.8269 - val_precision: 0.8600 - val_recall: 0.8269 - val_auc: 0.9259 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1873 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9261 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1830 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5442 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9255 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1818 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5436 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9254 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 7s 889ms/step - loss: 0.1779 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9256 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 7s 854ms/step - loss: 0.1750 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9261 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 7s 854ms/step - loss: 0.1719 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9257 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1700 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9265 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1684 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9263 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 8s 995ms/step - loss: 0.1660 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9271 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1627 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5328 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9270 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 7s 915ms/step - loss: 0.1607 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9268 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1581 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1560 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1536 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9270 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1524 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9274 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1509 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1488 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1476 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9271 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1446 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1432 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1424 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9277 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1399 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1381 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1363 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1354 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1335 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5164 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1321 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1311 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1295 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 8s 994ms/step - loss: 0.1281 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1268 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1259 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1245 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1231 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1224 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1212 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 8s 993ms/step - loss: 0.1195 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1186 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1174 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9279 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 7s 959ms/step - loss: 0.1165 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9277 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1154 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1141 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1135 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1131 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 8s 999ms/step - loss: 0.1127 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 7s 936ms/step - loss: 0.1120 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9285 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1116 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 7s 909ms/step - loss: 0.1113 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9285 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 7s 952ms/step - loss: 0.1107 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1102 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9289 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1097 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1095 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9288 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 7s 939ms/step - loss: 0.1087 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1083 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9285 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 8s 998ms/step - loss: 0.1081 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1075 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1073 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1066 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1063 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1057 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1053 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1048 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9288 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1045 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1040 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1036 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1032 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9291 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1028 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9292 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1025 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9287 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1020 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9289 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 7s 970ms/step - loss: 0.1015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9291 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1007 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9292 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1003 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4996 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1001 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 8s 987ms/step - loss: 0.0997 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0994 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0990 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0987 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0982 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9291 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0978 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 2.5000e-04\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0976 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 2.5000e-04\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0974 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 2.5000e-04\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0972 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 2.5000e-04\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 7s 956ms/step - loss: 0.0971 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 2.5000e-04\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 8s 965ms/step - loss: 0.0969 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9289 - lr: 1.2500e-04\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 7s 933ms/step - loss: 0.0967 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0966 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0966 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9290 - lr: 1.2500e-04\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0965 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9290 - lr: 1.2500e-04\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0964 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9290 - lr: 1.2500e-04\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0963 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9289 - lr: 1.2500e-04\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0962 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9291 - lr: 1.2500e-04\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0961 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9291 - lr: 1.2500e-04\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0960 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9291 - lr: 1.2500e-04\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0959 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9290 - lr: 1.2500e-04\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0958 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9292 - lr: 1.2500e-04\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0958 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9293 - lr: 1.2500e-04\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0957 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 1.2500e-04\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0956 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 8s 966ms/step - loss: 0.0955 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0954 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0953 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0952 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0952 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 1.2500e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0951 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 1.2500e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0951 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9297 - lr: 1.2500e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0949 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 1.2500e-04\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0948 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9296 - lr: 1.2500e-04\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0947 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9297 - lr: 1.2500e-04\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0947 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9297 - lr: 1.2500e-04\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0945 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9297 - lr: 1.2500e-04\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 8s 1000ms/step - loss: 0.0945 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 1.2500e-04\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0944 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 1.2500e-04\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0943 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 1.2500e-04\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 8s 975ms/step - loss: 0.0942 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 1.2500e-04\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0941 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 1.2500e-04\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0941 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 1.2500e-04\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0940 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 1.2500e-04\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0939 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 1.2500e-04\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0938 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 1.2500e-04\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 7s 981ms/step - loss: 0.0937 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9302 - lr: 1.2500e-04\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0936 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 1.2500e-04\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 8s 979ms/step - loss: 0.0936 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9302 - lr: 1.2500e-04\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0935 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 1.2500e-04\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0934 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 1.2500e-04\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0933 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 1.2500e-04\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 8s 991ms/step - loss: 0.0932 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 1.2500e-04\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0932 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 1.2500e-04\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0930 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 1.2500e-04\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 7s 942ms/step - loss: 0.0930 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0929 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0928 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0927 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0926 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0926 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0925 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0924 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0923 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 1.2500e-04\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0922 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 1.2500e-04\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0922 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 1.2500e-04\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0921 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 7s 952ms/step - loss: 0.0920 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 1.2500e-04\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0919 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 1.2500e-04\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0919 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 1.2500e-04\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0918 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0917 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0916 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0915 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0915 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0913 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0913 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0912 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0912 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0911 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0910 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0909 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0908 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 8s 987ms/step - loss: 0.0907 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 8s 980ms/step - loss: 0.0907 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 7s 921ms/step - loss: 0.0906 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 6.2500e-05\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0905 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 6.2500e-05\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0905 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 6.2500e-05\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0905 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 6.2500e-05\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0904 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 6.2500e-05\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0904 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 6.2500e-05\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0903 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 3.1250e-05\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0903 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 3.1250e-05\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0903 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 3.1250e-05\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0903 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 3.1250e-05\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0903 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 3.1250e-05\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0902 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 3.1250e-05\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0902 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 3.1250e-05\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0902 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 3.1250e-05\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 7s 960ms/step - loss: 0.0902 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 3.1250e-05\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0902 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.5625e-05\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0902 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 1.5625e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.63; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.5203 - accuracy: 0.9051 - precision: 0.9324 - recall: 0.8734 - auc: 0.9712 - val_loss: 0.3858 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4815 - accuracy: 0.9367 - precision: 0.9463 - recall: 0.8924 - auc: 0.9803 - val_loss: 0.3734 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4565 - accuracy: 0.9430 - precision: 0.9470 - recall: 0.9051 - auc: 0.9831 - val_loss: 0.3632 - val_accuracy: 0.9231 - val_precision: 0.9400 - val_recall: 0.9038 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4519 - accuracy: 0.9430 - precision: 0.9474 - recall: 0.9114 - auc: 0.9834 - val_loss: 0.3492 - val_accuracy: 0.9423 - val_precision: 0.9388 - val_recall: 0.8846 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4314 - accuracy: 0.9494 - precision: 0.9542 - recall: 0.9241 - auc: 0.9869 - val_loss: 0.3413 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4306 - accuracy: 0.9494 - precision: 0.9605 - recall: 0.9241 - auc: 0.9876 - val_loss: 0.3429 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.4045 - accuracy: 0.9494 - precision: 0.9548 - recall: 0.9367 - auc: 0.9871 - val_loss: 0.3329 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3917 - accuracy: 0.9494 - precision: 0.9554 - recall: 0.9494 - auc: 0.9904 - val_loss: 0.3359 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3852 - accuracy: 0.9557 - precision: 0.9610 - recall: 0.9367 - auc: 0.9895 - val_loss: 0.3276 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3674 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - auc: 0.9918 - val_loss: 0.3266 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 960ms/step - loss: 0.3613 - accuracy: 0.9494 - precision: 0.9551 - recall: 0.9430 - auc: 0.9917 - val_loss: 0.3253 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3561 - accuracy: 0.9557 - precision: 0.9615 - recall: 0.9494 - auc: 0.9911 - val_loss: 0.3226 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3448 - accuracy: 0.9557 - precision: 0.9554 - recall: 0.9494 - auc: 0.9925 - val_loss: 0.3173 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3410 - accuracy: 0.9557 - precision: 0.9618 - recall: 0.9557 - auc: 0.9924 - val_loss: 0.3138 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3295 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9935 - val_loss: 0.3116 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3245 - accuracy: 0.9620 - precision: 0.9682 - recall: 0.9620 - auc: 0.9941 - val_loss: 0.3107 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 7s 979ms/step - loss: 0.3168 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9936 - val_loss: 0.3084 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3132 - accuracy: 0.9684 - precision: 0.9682 - recall: 0.9620 - auc: 0.9945 - val_loss: 0.3046 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 7s 843ms/step - loss: 0.3055 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9944 - val_loss: 0.3035 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3027 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9947 - val_loss: 0.3025 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2926 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9952 - val_loss: 0.3014 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2878 - accuracy: 0.9747 - precision: 0.9745 - recall: 0.9684 - auc: 0.9953 - val_loss: 0.3011 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 982ms/step - loss: 0.2869 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9949 - val_loss: 0.3009 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2794 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9955 - val_loss: 0.2972 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2751 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9958 - val_loss: 0.2969 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 7s 960ms/step - loss: 0.2706 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9957 - val_loss: 0.2957 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2672 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9962 - val_loss: 0.2969 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2634 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9958 - val_loss: 0.2927 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2600 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9963 - val_loss: 0.2930 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2553 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9966 - val_loss: 0.2930 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2494 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9966 - val_loss: 0.2906 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2463 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9966 - val_loss: 0.2896 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2447 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9968 - val_loss: 0.2893 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2396 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9969 - val_loss: 0.2889 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2378 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9969 - val_loss: 0.2884 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2331 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9971 - val_loss: 0.2878 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2336 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9973 - val_loss: 0.2876 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 7s 942ms/step - loss: 0.2300 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9975 - val_loss: 0.2861 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2268 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9973 - val_loss: 0.2859 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2235 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9975 - val_loss: 0.2852 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 7s 972ms/step - loss: 0.2214 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9974 - val_loss: 0.2847 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2168 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9977 - val_loss: 0.2854 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2149 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9978 - val_loss: 0.2841 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2116 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9980 - val_loss: 0.2839 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2102 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9978 - val_loss: 0.2839 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2077 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9979 - val_loss: 0.2830 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2081 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9979 - val_loss: 0.2826 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2041 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9979 - val_loss: 0.2823 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2017 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9981 - val_loss: 0.2825 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1995 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9982 - val_loss: 0.2820 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1983 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9981 - val_loss: 0.2816 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1945 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9984 - val_loss: 0.2812 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 8s 964ms/step - loss: 0.1954 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9983 - val_loss: 0.2814 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 7s 951ms/step - loss: 0.1917 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9983 - val_loss: 0.2809 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1914 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9983 - val_loss: 0.2813 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 7s 887ms/step - loss: 0.1871 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9985 - val_loss: 0.2806 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1871 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9984 - val_loss: 0.2804 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1843 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9986 - val_loss: 0.2805 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1828 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9987 - val_loss: 0.2802 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1817 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9988 - val_loss: 0.2801 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1780 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9988 - val_loss: 0.2800 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1773 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9988 - val_loss: 0.2799 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1755 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9988 - val_loss: 0.2798 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1743 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1725 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9988 - val_loss: 0.2801 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1721 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9989 - val_loss: 0.2796 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1705 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2798 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 8s 996ms/step - loss: 0.1681 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9991 - val_loss: 0.2796 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1669 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9991 - val_loss: 0.2798 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1657 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9991 - val_loss: 0.2795 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1633 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9993 - val_loss: 0.2794 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1632 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9993 - val_loss: 0.2796 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1612 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2792 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9765 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1604 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2799 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9761 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1587 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2789 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1577 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2789 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1570 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2788 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1554 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9756 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1540 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1523 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9995 - val_loss: 0.2795 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9757 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1513 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9760 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1502 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9756 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1491 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2792 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1482 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2792 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 7s 952ms/step - loss: 0.1478 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1484 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9995 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1469 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9763 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1462 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9761 - lr: 2.5000e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1456 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9764 - lr: 2.5000e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 8s 991ms/step - loss: 0.1456 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9763 - lr: 2.5000e-04\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 7s 956ms/step - loss: 0.1453 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9763 - lr: 2.5000e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1450 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 2.5000e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 7s 920ms/step - loss: 0.1446 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 1.2500e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1444 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 1.2500e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 8s 995ms/step - loss: 0.1443 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 1.2500e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1441 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9761 - lr: 1.2500e-04\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1441 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9760 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.62; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.63 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.62 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0):\n",
      "> Accuracy: 0.75 (+- 0.02)\n",
      "> Loss: 0.63 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 8/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 22s 2s/step - loss: 0.3622 - accuracy: 0.9684 - precision: 0.9742 - recall: 0.9557 - auc: 0.9951 - val_loss: 0.6329 - val_accuracy: 0.8269 - val_precision: 0.8182 - val_recall: 0.6923 - val_auc: 0.9013 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3175 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9984 - val_loss: 0.6112 - val_accuracy: 0.8269 - val_precision: 0.8222 - val_recall: 0.7115 - val_auc: 0.9113 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2989 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9986 - val_loss: 0.5995 - val_accuracy: 0.8269 - val_precision: 0.8409 - val_recall: 0.7115 - val_auc: 0.9135 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2805 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9992 - val_loss: 0.5948 - val_accuracy: 0.8269 - val_precision: 0.8333 - val_recall: 0.7692 - val_auc: 0.9137 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2625 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9996 - val_loss: 0.5980 - val_accuracy: 0.8269 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9138 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2479 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9996 - val_loss: 0.5826 - val_accuracy: 0.8269 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9168 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2365 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5700 - val_accuracy: 0.8462 - val_precision: 0.8511 - val_recall: 0.7692 - val_auc: 0.9204 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2303 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5651 - val_accuracy: 0.8462 - val_precision: 0.8542 - val_recall: 0.7885 - val_auc: 0.9207 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2153 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5637 - val_accuracy: 0.8462 - val_precision: 0.8571 - val_recall: 0.8077 - val_auc: 0.9219 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2067 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.8269 - val_precision: 0.8571 - val_recall: 0.8077 - val_auc: 0.9243 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1986 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1964 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5520 - val_accuracy: 0.8462 - val_precision: 0.8367 - val_recall: 0.7885 - val_auc: 0.9229 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1867 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9246 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1792 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5400 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9254 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5390 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9256 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 7s 953ms/step - loss: 0.1689 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9261 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1647 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1611 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9273 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1551 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5277 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9270 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1519 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5273 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9264 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1487 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9271 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1447 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1412 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5179 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9277 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1373 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5179 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1349 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1319 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1285 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 998ms/step - loss: 0.1272 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 8s 995ms/step - loss: 0.1237 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1225 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 7s 856ms/step - loss: 0.1200 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1172 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1152 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1126 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1114 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 982ms/step - loss: 0.1091 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9288 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1069 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9271 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1038 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9285 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1022 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.1006 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9292 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0990 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9286 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 8s 989ms/step - loss: 0.0973 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9274 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0960 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0944 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9305 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 7s 921ms/step - loss: 0.0936 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.8462 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9315 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0918 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9294 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0905 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9300 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0902 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0884 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0876 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9295 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9299 - lr: 5.0000e-04\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0856 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0849 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 5.0000e-04\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0844 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 5.0000e-04\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0836 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9302 - lr: 5.0000e-04\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0831 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9306 - lr: 2.5000e-04\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 8s 964ms/step - loss: 0.0828 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 2.5000e-04\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0825 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9304 - lr: 2.5000e-04\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0824 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9306 - lr: 2.5000e-04\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 8s 997ms/step - loss: 0.0822 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9303 - lr: 2.5000e-04\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0819 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 2.5000e-04\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0816 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 2.5000e-04\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0814 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0813 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9306 - lr: 2.5000e-04\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0810 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9307 - lr: 2.5000e-04\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 8s 997ms/step - loss: 0.0807 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9309 - lr: 2.5000e-04\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 7s 964ms/step - loss: 0.0804 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 7s 970ms/step - loss: 0.0802 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0799 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9308 - lr: 2.5000e-04\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0795 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9313 - lr: 2.5000e-04\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0794 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9312 - lr: 2.5000e-04\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 8s 982ms/step - loss: 0.0791 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9311 - lr: 2.5000e-04\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0789 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9311 - lr: 2.5000e-04\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0788 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9314 - lr: 2.5000e-04\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 7s 966ms/step - loss: 0.0785 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9315 - lr: 2.5000e-04\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0783 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9312 - lr: 2.5000e-04\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0780 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9312 - lr: 2.5000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0778 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9311 - lr: 2.5000e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0776 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9312 - lr: 2.5000e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0775 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9315 - lr: 2.5000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0773 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9314 - lr: 2.5000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0768 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9314 - lr: 2.5000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0767 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9315 - lr: 2.5000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0765 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 2.5000e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0763 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 2.5000e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0760 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 2.5000e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 8s 977ms/step - loss: 0.0759 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9314 - lr: 2.5000e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0757 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 2.5000e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0755 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9312 - lr: 2.5000e-04\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 7s 960ms/step - loss: 0.0753 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 2.5000e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0751 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 2.5000e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0750 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9319 - lr: 2.5000e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9312 - lr: 2.5000e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0745 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9312 - lr: 2.5000e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0743 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9314 - lr: 2.5000e-04\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0739 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 2.5000e-04\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0738 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9315 - lr: 2.5000e-04\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0736 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 1.2500e-04\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0735 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9315 - lr: 1.2500e-04\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0735 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 1.2500e-04\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0734 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9314 - lr: 1.2500e-04\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 8s 965ms/step - loss: 0.0732 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 1.2500e-04\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 7s 954ms/step - loss: 0.0731 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9318 - lr: 1.2500e-04\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0730 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 1.2500e-04\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 7s 902ms/step - loss: 0.0729 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9319 - lr: 1.2500e-04\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0728 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 6.2500e-05\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0727 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 6.2500e-05\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0727 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 6.2500e-05\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0726 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 6.2500e-05\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0726 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 6.2500e-05\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0725 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9316 - lr: 3.1250e-05\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0725 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 3.1250e-05\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0725 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9318 - lr: 3.1250e-05\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0724 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9318 - lr: 3.1250e-05\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0724 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 3.1250e-05\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0724 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9317 - lr: 1.5625e-05\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 8s 982ms/step - loss: 0.0724 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9318 - lr: 1.5625e-05\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0724 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9318 - lr: 1.5625e-05\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.0724 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9318 - lr: 1.5625e-05\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0724 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9318 - lr: 1.5625e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.63; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 1s/step - loss: 0.5195 - accuracy: 0.9177 - precision: 0.9459 - recall: 0.8861 - auc: 0.9743 - val_loss: 0.4106 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9668 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4743 - accuracy: 0.9241 - precision: 0.9404 - recall: 0.8987 - auc: 0.9824 - val_loss: 0.3554 - val_accuracy: 0.9231 - val_precision: 0.9600 - val_recall: 0.9231 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4072 - accuracy: 0.9557 - precision: 0.9613 - recall: 0.9430 - auc: 0.9893 - val_loss: 0.3340 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3809 - accuracy: 0.9494 - precision: 0.9548 - recall: 0.9367 - auc: 0.9898 - val_loss: 0.3222 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3601 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9916 - val_loss: 0.3201 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3435 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9930 - val_loss: 0.3167 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3292 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - auc: 0.9924 - val_loss: 0.3117 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3195 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9938 - val_loss: 0.3083 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.3067 - accuracy: 0.9684 - precision: 0.9682 - recall: 0.9620 - auc: 0.9936 - val_loss: 0.3048 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.2943 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9951 - val_loss: 0.3003 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 7s 962ms/step - loss: 0.2856 - accuracy: 0.9620 - precision: 0.9620 - recall: 0.9620 - auc: 0.9951 - val_loss: 0.2966 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2723 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9960 - val_loss: 0.2947 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2639 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9961 - val_loss: 0.2931 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2604 - accuracy: 0.9684 - precision: 0.9745 - recall: 0.9684 - auc: 0.9969 - val_loss: 0.2916 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2498 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9962 - val_loss: 0.2902 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2437 - accuracy: 0.9747 - precision: 0.9808 - recall: 0.9684 - auc: 0.9969 - val_loss: 0.2890 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 7s 969ms/step - loss: 0.2379 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9969 - val_loss: 0.2870 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2315 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9971 - val_loss: 0.2859 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 7s 967ms/step - loss: 0.2248 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9973 - val_loss: 0.2850 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2280 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9967 - val_loss: 0.2849 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2182 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9969 - val_loss: 0.2832 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2111 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9980 - val_loss: 0.2826 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 976ms/step - loss: 0.2052 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9979 - val_loss: 0.2828 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2009 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9980 - val_loss: 0.2831 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1959 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9982 - val_loss: 0.2822 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 964ms/step - loss: 0.1921 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9983 - val_loss: 0.2814 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1890 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9984 - val_loss: 0.2807 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1852 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9986 - val_loss: 0.2811 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1818 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9985 - val_loss: 0.2801 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1788 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9985 - val_loss: 0.2798 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1762 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9988 - val_loss: 0.2811 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9764 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1709 - accuracy: 0.9747 - precision: 0.9809 - recall: 0.9747 - auc: 0.9989 - val_loss: 0.2794 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1682 - accuracy: 0.9747 - precision: 0.9872 - recall: 0.9747 - auc: 0.9990 - val_loss: 0.2795 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1660 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9992 - val_loss: 0.2799 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1658 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9989 - val_loss: 0.2800 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9760 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1602 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9992 - val_loss: 0.2787 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1595 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9993 - val_loss: 0.2787 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 7s 962ms/step - loss: 0.1566 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9992 - val_loss: 0.2791 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9759 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1543 - accuracy: 0.9810 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2791 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9761 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1529 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9993 - val_loss: 0.2791 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9755 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 7s 899ms/step - loss: 0.1494 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9756 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1476 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9995 - val_loss: 0.2795 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9763 - lr: 5.0000e-04\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1456 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2793 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9762 - lr: 5.0000e-04\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1443 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2791 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9759 - lr: 5.0000e-04\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 8s 998ms/step - loss: 0.1434 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2795 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9763 - lr: 5.0000e-04\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 7s 938ms/step - loss: 0.1424 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2795 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1409 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2794 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9758 - lr: 2.5000e-04\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1402 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2794 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9763 - lr: 2.5000e-04\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 8s 988ms/step - loss: 0.1403 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.2794 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9762 - lr: 2.5000e-04\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 7s 868ms/step - loss: 0.1393 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2795 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9760 - lr: 2.5000e-04\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 6s 829ms/step - loss: 0.1386 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2796 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9759 - lr: 2.5000e-04\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 7s 839ms/step - loss: 0.1384 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2796 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9759 - lr: 1.2500e-04\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 7s 949ms/step - loss: 0.1380 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2797 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9761 - lr: 1.2500e-04\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 7s 943ms/step - loss: 0.1376 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2796 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9759 - lr: 1.2500e-04\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 7s 929ms/step - loss: 0.1375 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2796 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9759 - lr: 1.2500e-04\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1373 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2796 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9758 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.62; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.63 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.62 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.5):\n",
      "> Accuracy: 0.75 (+- 0.02)\n",
      "> Loss: 0.63 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 9/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 1s/step - loss: 0.3537 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9953 - val_loss: 0.6017 - val_accuracy: 0.6923 - val_precision: 0.7500 - val_recall: 0.6923 - val_auc: 0.9038 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2964 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9996 - val_loss: 0.6497 - val_accuracy: 0.7500 - val_precision: 0.8000 - val_recall: 0.6923 - val_auc: 0.8910 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2237 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5390 - val_accuracy: 0.8077 - val_precision: 0.8163 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 974ms/step - loss: 0.1870 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9239 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1521 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9250 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1303 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.8077 - val_precision: 0.8200 - val_recall: 0.7885 - val_auc: 0.9281 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1187 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.8269 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9292 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1023 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8077 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9292 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0949 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.8462 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9301 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0893 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8269 - val_precision: 0.8400 - val_recall: 0.8077 - val_auc: 0.9300 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0885 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9330 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0785 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5026 - val_accuracy: 0.8462 - val_precision: 0.8627 - val_recall: 0.8462 - val_auc: 0.9304 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0755 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.8077 - val_precision: 0.8077 - val_recall: 0.8077 - val_auc: 0.9343 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 981ms/step - loss: 0.0668 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.8269 - val_precision: 0.8431 - val_recall: 0.8269 - val_auc: 0.9310 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0666 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9339 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0661 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.8077 - val_precision: 0.8077 - val_recall: 0.8077 - val_auc: 0.9339 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0593 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.8462 - val_precision: 0.8627 - val_recall: 0.8462 - val_auc: 0.9276 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0579 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4806 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9355 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0549 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8269 - val_precision: 0.8235 - val_recall: 0.8077 - val_auc: 0.9344 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0519 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8462 - val_precision: 0.8462 - val_recall: 0.8462 - val_auc: 0.9335 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0492 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9354 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0478 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9353 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0467 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9350 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0453 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9360 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0445 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0439 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9346 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0431 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9348 - lr: 2.5000e-04\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 7s 948ms/step - loss: 0.0426 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9348 - lr: 2.5000e-04\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0423 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9358 - lr: 2.5000e-04\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0419 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9355 - lr: 2.5000e-04\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0416 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9346 - lr: 2.5000e-04\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0414 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9349 - lr: 1.2500e-04\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0410 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9347 - lr: 1.2500e-04\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0408 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9348 - lr: 1.2500e-04\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 8s 995ms/step - loss: 0.0407 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9349 - lr: 1.2500e-04\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 7s 954ms/step - loss: 0.0406 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.8269 - val_precision: 0.8269 - val_recall: 0.8269 - val_auc: 0.9348 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.64; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.5194 - accuracy: 0.9114 - precision: 0.9262 - recall: 0.8734 - auc: 0.9730 - val_loss: 0.3477 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4035 - accuracy: 0.9430 - precision: 0.9419 - recall: 0.9241 - auc: 0.9902 - val_loss: 0.3320 - val_accuracy: 0.9423 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9807 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 7s 935ms/step - loss: 0.3478 - accuracy: 0.9494 - precision: 0.9603 - recall: 0.9177 - auc: 0.9881 - val_loss: 0.3027 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2710 - accuracy: 0.9684 - precision: 0.9684 - recall: 0.9684 - auc: 0.9963 - val_loss: 0.2938 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9765 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2340 - accuracy: 0.9684 - precision: 0.9679 - recall: 0.9557 - auc: 0.9958 - val_loss: 0.2795 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2044 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9971 - val_loss: 0.2783 - val_accuracy: 0.9231 - val_precision: 0.9412 - val_recall: 0.9231 - val_auc: 0.9764 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.1710 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9988 - val_loss: 0.2798 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1626 - accuracy: 0.9747 - precision: 0.9747 - recall: 0.9747 - auc: 0.9985 - val_loss: 0.2774 - val_accuracy: 0.9038 - val_precision: 0.9216 - val_recall: 0.9038 - val_auc: 0.9753 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1542 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9987 - val_loss: 0.2840 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9757 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 8s 988ms/step - loss: 0.1382 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9992 - val_loss: 0.2846 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9733 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1350 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2811 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9745 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1247 - accuracy: 0.9810 - precision: 0.9810 - recall: 0.9810 - auc: 0.9994 - val_loss: 0.2865 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9729 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1087 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.2886 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9727 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1091 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9996 - val_loss: 0.2891 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9744 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1071 - accuracy: 0.9810 - precision: 0.9873 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.2889 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9716 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0973 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.2878 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9724 - lr: 5.0000e-04\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0943 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2891 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9724 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 7s 955ms/step - loss: 0.0932 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2888 - val_accuracy: 0.9038 - val_precision: 0.9038 - val_recall: 0.9038 - val_auc: 0.9725 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.0879 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2897 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9723 - lr: 2.5000e-04\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 8s 979ms/step - loss: 0.0896 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2928 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9727 - lr: 2.5000e-04\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0885 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2900 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9727 - lr: 2.5000e-04\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0860 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2904 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9721 - lr: 2.5000e-04\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0843 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2912 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9725 - lr: 2.5000e-04\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0839 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2920 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9723 - lr: 1.2500e-04\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0836 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2924 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9724 - lr: 1.2500e-04\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0825 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2917 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9725 - lr: 1.2500e-04\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0822 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2916 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9720 - lr: 1.2500e-04\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0819 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2920 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9722 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.63; accuracy of 75.0%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.64 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.63 - Accuracy: 0.75%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.9):\n",
      "> Accuracy: 0.76 (+- 0.01)\n",
      "> Loss: 0.64 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Average Training Time: 751.89 seconds\n",
      "Average Inference Time: 2.14 seconds\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "learn_rate = [0.01, 0.001, 0.0001]\n",
    "momentum = [0, 0.5, 0.9]\n",
    "\n",
    "tot_comb = len(learn_rate) * len(momentum)\n",
    "glob_param = np.empty([tot_comb, 2])\n",
    "\n",
    "history_list = []\n",
    "scores_glob_array = np.empty([tot_comb, n_folds, 5])\n",
    "training_times = []  # Initialize list to store training times\n",
    "inference_times = []  # Initialize list to store inference times\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "auc_list = []\n",
    "\n",
    "for idx, x in enumerate(itertools.product(learn_rate, momentum)):\n",
    "    learn_rate = x[0]\n",
    "    momentum = x[1]\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for combination {idx + 1}/{tot_comb} ...')\n",
    "    print(f'Learning rate = {learn_rate}')\n",
    "    print(f'Momentum = {momentum}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    history_array = np.array([])\n",
    "    scores_array = np.empty([n_folds, 5])\n",
    "\n",
    "    glob_param[idx, 0] = learn_rate\n",
    "    glob_param[idx, 1] = momentum\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold + 1}/{n_folds} ...')\n",
    "        print('------------------------------------------------------------------------')\n",
    "\n",
    "        # Generate the fold sample for train-test\n",
    "        X_train_cc, X_train_mlo, Y_train, X_test_cc, X_test_mlo, Y_test = part_traintest(X_traintest_cc, X_traintest_mlo, Y_traintest, rand_seed + fold, frac_test)\n",
    "\n",
    "        # Define the model architecture\n",
    "        model_2ramas = DenseNet_2Ramas(model_cc, model_mlo, rand_seed, learning_rate, momentum)\n",
    "        \n",
    "        # Measure training time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Fit data to model -> entrenamos con los distintos parametros \n",
    "        history = model_2ramas.fit([X_train_cc, X_train_mlo], Y_train,\n",
    "                                   batch_size = batch_size,\n",
    "                                   epochs = no_epochs,\n",
    "                                   validation_data = ([X_test_cc, X_test_mlo], Y_test),\n",
    "                                   class_weight = class_weight,\n",
    "                                   verbose = 1,\n",
    "                                   callbacks = [early_stopping, reduce_lr])\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        training_times.append(training_time)\n",
    "        \n",
    "        # Generate generalization metrics\n",
    "        start_time = time.time()\n",
    "        scores = model_2ramas.evaluate([X_val_cc, X_val_mlo], Y_val, verbose=0)\n",
    "        inference_time = time.time() - start_time\n",
    "        inference_times.append(inference_time)\n",
    "        \n",
    "        # Append scores\n",
    "        scores_array[fold, :] = scores\n",
    "        accuracy_list.append(scores[1])  # Accuracy is the second metric\n",
    "        precision_list.append(scores[2])  # Precision is the third metric\n",
    "        recall_list.append(scores[3])  # Recall is the fourth metric\n",
    "        auc_list.append(scores[4])  # AUC is the fifth metric\n",
    "        \n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Score for fold {fold + 1}: {model_2ramas.metrics_names[0]} of {round(scores_array[fold, 0], 2)}; {model_2ramas.metrics_names[1]} of {round(scores_array[fold, 1]*100, 2)}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('')\n",
    "\n",
    "        # Append history callback into array\n",
    "        history_array = np.append(history_array, [history])\n",
    "\n",
    "        \n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, scores_array.shape[0]):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i + 1} - Loss: {round(scores_array[i, 0], 2)} - Accuracy: {round(scores_array[i, 1], 2)}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Average scores for all folds (LR = {learn_rate}, mtm = {momentum}):')\n",
    "    print(f'> Accuracy: {round(np.mean(scores_array[:, 1]), 2)} (+- {round(np.std(scores_array[:, 1]), 2)})')\n",
    "    print(f'> Loss: {round(np.mean(scores_array[:, 0]), 2)} (+- {round(np.std(scores_array[:, 0]), 2)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "    idx_best_hist = np.argmax(scores_array[:, 1])\n",
    "    history_list.append(history_array[idx_best_hist])\n",
    "    \n",
    "    scores_glob_array[idx, :, :] = scores_array\n",
    "\n",
    "# Print the average training and inference times\n",
    "print(f'Average Training Time: {np.mean(training_times):.2f} seconds')\n",
    "print(f'Average Inference Time: {np.mean(inference_times):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73492217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados promedios del entrenamiento DenseNet121:\n",
      "- LR=0.01 / mom=0.0:\tAcc=0.76 (+- 0.01) - Loss=0.63 (+- 0.0)\n",
      "- LR=0.01 / mom=0.5:\tAcc=0.76 (+- 0.01) - Loss=0.63 (+- 0.0)\n",
      "- LR=0.01 / mom=0.9:\tAcc=0.77 (+- 0.0) - Loss=0.64 (+- 0.01)\n",
      "- LR=0.001 / mom=0.0:\tAcc=0.76 (+- 0.01) - Loss=0.62 (+- 0.0)\n",
      "- LR=0.001 / mom=0.5:\tAcc=0.75 (+- 0.02) - Loss=0.63 (+- 0.0)\n",
      "- LR=0.001 / mom=0.9:\tAcc=0.76 (+- 0.01) - Loss=0.64 (+- 0.0)\n",
      "- LR=0.0001 / mom=0.0:\tAcc=0.75 (+- 0.02) - Loss=0.63 (+- 0.0)\n",
      "- LR=0.0001 / mom=0.5:\tAcc=0.75 (+- 0.02) - Loss=0.63 (+- 0.0)\n",
      "- LR=0.0001 / mom=0.9:\tAcc=0.76 (+- 0.01) - Loss=0.64 (+- 0.0)\n",
      "\n",
      "El mejor resultado para la DenseNet121 se obtiene para LR = 0.01 y momentum = 0.9.\n"
     ]
    }
   ],
   "source": [
    "print(f'Resultados promedios del entrenamiento DenseNet121:')\n",
    "for i in range(len(glob_param)):\n",
    "    print(f'- LR={glob_param[i, 0]} / mom={glob_param[i, 1]}:\\tAcc={round(np.mean(scores_glob_array[i, :, 1]), 2)} (+- {round(np.std(scores_glob_array[i, :, 1]), 2)}) - Loss={round(np.mean(scores_glob_array[i, :, 0]), 2)} (+- {round(np.std(scores_glob_array[i, :, 0]), 2)})')\n",
    "\n",
    "idx_best = np.argmax(np.mean(scores_glob_array, 1)[:, 1])\n",
    "history_best = history_list[idx_best]\n",
    "model_best = history_best.model\n",
    "print(f'\\nEl mejor resultado para la DenseNet121 se obtiene para LR = {glob_param[idx_best, 0]} y momentum = {glob_param[idx_best, 1]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8531a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_best = np.argmax(scores_array[:, 1])\n",
    "model_best = history_array[idx_best].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc856174",
   "metadata": {},
   "outputs": [],
   "source": [
    "if google_colab:\n",
    "    file_path = '/content/gdrive/MyDrive/Colab Notebooks/model_CC-MLO'\n",
    "else:\n",
    "    file_path = './DN169_model_CC-MLO'\n",
    "K.models.save_model(model_best, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0dac00",
   "metadata": {
    "id": "super-progressive"
   },
   "source": [
    "## Representación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd8701",
   "metadata": {
    "id": "streaming-recruitment"
   },
   "source": [
    "Definimos una serie de funciones auxiliares para facilitar la visualización de resultados (representación de la evolución de las métricas durante el proceso de entrenamiento y resultados de la matriz de confusión finalmente obtenida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ccefae",
   "metadata": {
    "executionInfo": {
     "elapsed": 1434193,
     "status": "ok",
     "timestamp": 1621190143830,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "published-lingerie"
   },
   "outputs": [],
   "source": [
    "def get_metrics(history_array, no_epochs):\n",
    "    \"\"\"\n",
    "    Function that extracts the metrics from the k-fold history from the training process\n",
    "        - history_array is the array of histories generated during the training process\n",
    "        - no_epochs is number of epochs fixed for the training process\n",
    "    Returns:\n",
    "        - accuracy is the output array of accuracies\n",
    "        - val_accuracy is the output array of validation accuracies\n",
    "        - loss is the output array of losses\n",
    "        - val_loss is the output array of validation losses\n",
    "    \"\"\"\n",
    "    accuracy = np.empty([no_epochs, len(history_array)])\n",
    "    accuracy[:, :] = np.nan\n",
    "    val_accuracy = np.empty([no_epochs, len(history_array)])\n",
    "    val_accuracy[:, :] = np.nan\n",
    "    loss = np.empty([no_epochs, len(history_array)])\n",
    "    loss[:, :] = np.nan\n",
    "    val_loss = np.empty([no_epochs, len(history_array)])\n",
    "    val_loss[:, :] = np.nan\n",
    "\n",
    "    for idx, fold in enumerate(history_array):\n",
    "        max_epochs = max(fold.epoch)\n",
    "        accuracy[:max_epochs + 1, idx] = fold.history['accuracy']\n",
    "        val_accuracy[:max_epochs + 1, idx] = fold.history['val_accuracy']\n",
    "        loss[:max_epochs + 1, idx] = fold.history['loss']\n",
    "        val_loss[:max_epochs + 1, idx] = fold.history['val_loss']\n",
    "\n",
    "    return accuracy, val_accuracy, loss, val_loss\n",
    "\n",
    "def plot_metrics(history_array, no_epochs):\n",
    "    \"\"\"\n",
    "    Function that plots the metrics from the training process\n",
    "        - history_array is the array of histories generated during the training process\n",
    "        - no_epochs is number of epochs fixed for the training process\n",
    "    Returns:\n",
    "        - accuracy is the output array of accuracies\n",
    "        - val_accuracy is the output array of validation accuracies\n",
    "        - loss is the output array of losses\n",
    "        - val_loss is the output array of validation losses\n",
    "    \"\"\"\n",
    "    accuracy, val_accuracy, loss, val_loss = get_metrics(history_array, no_epochs)\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(np.mean(accuracy, axis = 1))\n",
    "    plt.plot(np.mean(val_accuracy, axis = 1))\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(np.mean(loss, axis = 1))\n",
    "    plt.plot(np.mean(val_loss, axis = 1))\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"\n",
    "    Credit to:\n",
    "    https://gist.github.com/zachguo/10296432\n",
    "    \n",
    "    Function that makes a pretty print for confusion matrixes\n",
    "        - cm is the array of histories generated during the training process\n",
    "        - labels is number of epochs fixed for the training process\n",
    "        - hide_zeroes is a boolean that allows the user to hide the zeroes in the matrix\n",
    "        - hide_diagonal is a boolean that allows the user to hide the diagonal in the matrix\n",
    "        - hide_threshold is a number that allows the user to hide results in the matrix below that value\n",
    "    \"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b952db",
   "metadata": {
    "executionInfo": {
     "elapsed": 2276,
     "status": "ok",
     "timestamp": 1620075964551,
     "user": {
      "displayName": "Duun V",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GipsnLzW9bWFJbKNrxY-F-xi7XKh0HhowJGi0hF9A=s64",
      "userId": "10921869077997462696"
     },
     "user_tz": -120
    },
    "id": "marked-decimal"
   },
   "source": [
    "Visualizamos la evolución de las métricas durante el proceso de entrenamiento de las redes, haciendo la media por época de las distintas iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa720a92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 1434738,
     "status": "ok",
     "timestamp": 1621190144383,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "racial-tribute",
    "outputId": "a5234e36-de66-4044-d2d5-2e0943b85ff3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history_array, no_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a8ea3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 739ms/step\n",
      "                    benigno seguimiento     maligno \n",
      "        benigno        25.0         2.0         1.0 \n",
      "    seguimiento         2.0         2.0         0.0 \n",
      "        maligno         6.0         1.0        13.0 \n"
     ]
    }
   ],
   "source": [
    "conf_matrix = metrics.confusion_matrix(Y_val.argmax(axis = 1), model_best.predict([X_val_cc, X_val_mlo]).argmax(axis = 1))\n",
    "print_cm(conf_matrix, list(dict_valores.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdbd6471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 806ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     benigno       0.76      0.89      0.82        28\n",
      " seguimiento       0.40      0.50      0.44         4\n",
      "     maligno       0.93      0.65      0.76        20\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.70      0.68      0.68        52\n",
      "weighted avg       0.80      0.77      0.77        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classif_report = metrics.classification_report(Y_val.argmax(axis = 1), model_best.predict([X_val_cc, X_val_mlo]).argmax(axis = 1),\n",
    "                                               target_names = list(dict_valores.keys()))\n",
    "print(classif_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a699029",
   "metadata": {},
   "source": [
    "# Guardamos las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92ec550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# Function to convert numpy types to native Python types\n",
    "def convert_to_native_types(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_native_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native_types(v) for v in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(convert_to_native_types(v) for v in obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Assuming history_list contains History objects\n",
    "# Extract the history dictionaries\n",
    "history_dicts = [convert_to_native_types(hist.history) for hist in history_list]\n",
    "\n",
    "# Save the history dictionaries using pickle\n",
    "with open('history_DN121.pkl', 'wb') as file:\n",
    "    pickle.dump(history_dicts, file)\n",
    "\n",
    "# Save the history dictionaries using JSON\n",
    "with open('history_DN121.json', 'w') as file:\n",
    "    json.dump(history_dicts, file)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Entrenamiento_DenseNet_2Ramas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
