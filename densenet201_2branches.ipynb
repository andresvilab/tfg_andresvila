{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38259443",
   "metadata": {
    "id": "modular-forth"
   },
   "source": [
    "# Implementación de DenseNet para las dos vistas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260c559",
   "metadata": {
    "id": "younger-sentence"
   },
   "source": [
    "Ajustamos el notebook según estemos trabajando en local o en un entorno de Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60043be6",
   "metadata": {
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1621188710580,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "flying-consciousness"
   },
   "outputs": [],
   "source": [
    "google_colab = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac61e1da",
   "metadata": {},
   "source": [
    "Importamos todas las librerías necesarias para la implementación del entrenamiento de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d831a740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 22:56:39.329887: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-21 22:56:39.332504: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 22:56:39.375366: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 22:56:39.376892: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 22:56:40.178626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa231a75",
   "metadata": {
    "id": "engaging-persian"
   },
   "source": [
    "##  Carga del dataset y preparación de los dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea77ac",
   "metadata": {
    "id": "beautiful-monthly"
   },
   "source": [
    "Definimos una función auxiliar para ayudar con el preprocesamiento de los datos (ajuste de entrada para la DenseNet en el caso de las imágenes y conversión a one-hot encoding para las etiquetas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3eed8ff",
   "metadata": {
    "executionInfo": {
     "elapsed": 22216,
     "status": "ok",
     "timestamp": 1621188731832,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "traditional-islam"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X_cc, X_mlo, Y):\n",
    "    \"\"\"\n",
    "    Pre-processes the data for the model\n",
    "        - X_cc is a numpy.ndarray of shape (m, 1024, 1024, 3) containing\n",
    "         the CC view mammography, where m is the number of data points\n",
    "        - X_mlo is a numpy.ndarray of shape (m, 1024, 1024, 3) containing\n",
    "         the MLO view mammography, where m is the number of data points\n",
    "        - Y is a numpy.ndarray of shape (m,) containing\n",
    "         the Bi-Rads labels for X\n",
    "    Returns:\n",
    "        - X_cc_p is a numpy.ndarray containing the preprocessed X_cc\n",
    "        - X_mlo_p is a numpy.ndarray containing the preprocessed X_mlo\n",
    "        - Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    X_cc_p = K.applications.densenet.preprocess_input(X_cc)\n",
    "    X_mlo_p = K.applications.densenet.preprocess_input(X_mlo)\n",
    "\n",
    "    Y_p = K.utils.to_categorical(Y, 3)\n",
    "\n",
    "    return X_cc_p, X_mlo_p, Y_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29196e9",
   "metadata": {
    "id": "mobile-monroe"
   },
   "source": [
    "Cargamos los ficheros de entrada, tanto el de entrenamiento-test como el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1e266d",
   "metadata": {
    "executionInfo": {
     "elapsed": 39717,
     "status": "ok",
     "timestamp": 1621188749334,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "frequent-homework"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_INbreast_train = pd.read_pickle('/workspace/container_0/andres/data/df_INbreast_train.pkl')\n",
    "df_INbreast_val = pd.read_pickle('/workspace/container_0/andres/data/df_INbreast_val.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8495d",
   "metadata": {
    "id": "contained-franchise"
   },
   "source": [
    "Cargamos los datos, convertimos las etiquetas a enteros y liberamos espacio de los ficheros que contenían el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3be12f8",
   "metadata": {
    "executionInfo": {
     "elapsed": 41835,
     "status": "ok",
     "timestamp": 1621188751455,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "fatty-forwarding"
   },
   "outputs": [],
   "source": [
    "dict_valores = {'benigno': 0, 'seguimiento': 1, 'maligno': 2}\n",
    "Y_traintest = np.array(df_INbreast_train['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_traintest_cc = np.array(df_INbreast_train['CC Image'].tolist())\n",
    "X_traintest_mlo = np.array(df_INbreast_train['MLO Image'].tolist())\n",
    "Y_val = np.array(df_INbreast_val['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_val_cc = np.array(df_INbreast_val['CC Image'].tolist())\n",
    "X_val_mlo = np.array(df_INbreast_val['MLO Image'].tolist())\n",
    "X_val_cc, X_val_mlo, Y_val = preprocess_data(X_val_cc, X_val_mlo, Y_val)\n",
    "del df_INbreast_train\n",
    "del df_INbreast_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f4787",
   "metadata": {
    "id": "W4IVXDMAOplr"
   },
   "source": [
    "## Definición de la arquitectura de red neuronal de dos ramas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b6691",
   "metadata": {
    "id": "5moG-NYZcICz"
   },
   "source": [
    "Cargamos los modelos individuales de cada rama y definimos el nuevo modelo a partir de ellos, junto con el inicializador de los pesos de la capa conectada y el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545ce439",
   "metadata": {
    "executionInfo": {
     "elapsed": 95117,
     "status": "ok",
     "timestamp": 1621188804739,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "8Yka6jqyOtSx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 22:56:43.748563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 22:56:43.749425: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Load the densenet 169 best models fo\n",
    "model_cc = K.models.load_model('/workspace/container_0/andres/densenet_1rama/model_best_DN201_CC')\n",
    "model_mlo = K.models.load_model('/workspace/container_0/andres/densenet_2ramas/model_best_DN201_MLO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabb1f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_6_cc\n"
     ]
    }
   ],
   "source": [
    "model_cc.layers[0]._name = model_cc.layers[0].name + str('_cc')\n",
    "print(model_cc.layers[0]._name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fddd07ea",
   "metadata": {
    "executionInfo": {
     "elapsed": 95116,
     "status": "ok",
     "timestamp": 1621188804740,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "7UvQIbcNPxqL"
   },
   "outputs": [],
   "source": [
    "def DenseNet_2Ramas(model_cc, model_mlo, rand_seed = 2021, learning_rate = 0.0001, momentum = 0.9):\n",
    "    \"\"\"\n",
    "    Define the DenseNet architecture and compile the model\n",
    "        - model_cc is the pretrained CC-view DenseNet model\n",
    "        - model_mlo is the pretrained MLO-view DenseNet model\n",
    "        - rand_seed is a random seed number used during the fc layer initialization\n",
    "        - learning_rate is the learning rate used during the training\n",
    "        - momentum is the parameters that defines the momentun for the SGD optimizer\n",
    "    Returns:\n",
    "        - model_2ramas is the output compiled DenseNet 2-branch model\n",
    "    \"\"\"\n",
    "    # Define the model architecture\n",
    "    model_cc = K.Sequential(model_cc.layers[:-1]) # \n",
    "    model_mlo = K.Sequential(model_mlo.layers[:-1])\n",
    "\n",
    "    model_cc.layers[-1]._name = model_cc.layers[-1].name + '_cc'\n",
    "    model_mlo.layers[-1]._name = model_mlo.layers[-1].name + '_mlo'\n",
    "\n",
    "\n",
    "    model_cc.trainable = False\n",
    "    model_mlo.trainable = False\n",
    "\n",
    "\n",
    "    combined = K.layers.Concatenate()([model_cc.output, model_mlo.output])\n",
    "    \n",
    "    initializer = K.initializers.he_normal(seed = rand_seed)\n",
    "    \n",
    "    # pasar de todas las neuronas a las tres (añadir alguna capa)\n",
    "    fc_layer = K.layers.Dense(units = 3,\n",
    "                              activation = 'softmax',\n",
    "                              kernel_initializer = initializer\n",
    "                              )(combined)\n",
    "\n",
    "    model_2ramas = K.models.Model(inputs = [model_cc.input, model_mlo.input], outputs = fc_layer)\n",
    "#     model_2ramas.layers[0]._name = model_cc.layers[0].name + '_cc'\n",
    "\n",
    "    # Compile the model\n",
    "    opt = K.optimizers.SGD(learning_rate = learning_rate, momentum = momentum)\n",
    "    \n",
    "    model_2ramas.compile(loss = 'categorical_crossentropy',\n",
    "                         optimizer = opt,\n",
    "                         metrics = [\n",
    "                             'accuracy',\n",
    "                         Precision(name='precision'),\n",
    "                         Recall(name='recall'),\n",
    "                         AUC(name='auc')\n",
    "                         ]\n",
    "                        )\n",
    "    \n",
    "    return model_2ramas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187c571e",
   "metadata": {
    "id": "LNizgVEZ5ENX"
   },
   "source": [
    "Mostramos por pantalla la arquitectura de la red definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee65e067",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96767,
     "status": "ok",
     "timestamp": 1621188806394,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "M_Sbv12gckjn",
    "outputId": "1f397139-8bec-41b2-ecac-e96c8c3fd8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6_cc (InputLayer)     [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " resize_CC (Lambda)          (None, 256, 256, 3)          0         ['input_6_cc[0][0]']          \n",
      "                                                                                                  \n",
      " resize_MLO (Lambda)         (None, 256, 256, 3)          0         ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " densenet201_cc (Functional  (None, 1920)                 1832198   ['resize_CC[1][0]']           \n",
      " )                                                        4                                       \n",
      "                                                                                                  \n",
      " densenet201_mlo (Functiona  (None, 1920)                 1832198   ['resize_MLO[1][0]']          \n",
      " l)                                                       4                                       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 3840)                 0         ['densenet201_cc[1][0]',      \n",
      "                                                                     'densenet201_mlo[1][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 3)                    11523     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36655491 (139.83 MB)\n",
      "Trainable params: 11523 (45.01 KB)\n",
      "Non-trainable params: 36643968 (139.79 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DenseNet_2Ramas(model_cc, model_mlo).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ff97b",
   "metadata": {
    "id": "daily-secretariat"
   },
   "source": [
    "## Entrenamiento de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89499bf0",
   "metadata": {
    "id": "AVvOsz7p5ptL"
   },
   "source": [
    "Definimos una función auxiliar que particiona el conjunto de entrenamiento/test en los dos subconjuntos correspondientes (entrenamiento y test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c7acd7",
   "metadata": {
    "executionInfo": {
     "elapsed": 96766,
     "status": "ok",
     "timestamp": 1621188806394,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "MfoWhBMq5plj"
   },
   "outputs": [],
   "source": [
    "def part_traintest(X_traintest_cc, X_traintest_mlo, Y_traintest, rand_seed = 2021, frac_test = .2/.8):\n",
    "    \"\"\"\n",
    "    Function that makes a partition for training and testing from the original dataset\n",
    "        - X_traintest_cc is the array of CC-view images from the original dataset\n",
    "        - X_traintest_mlo is the array of MLO-view images from the original dataset\n",
    "        - Y_traintest is the array of labels from the original dataset\n",
    "        - rand_seed is a random seed number used during the sampling\n",
    "        - frac_test is the fraction of cases used in the test subset\n",
    "    Returns:\n",
    "        - X_train_cc is the train array of CC-images\n",
    "        - X_train_mlo is the train array of MLO-images\n",
    "        - Y_train is the train array of labels\n",
    "        - X_test_cc is the test array of CC-images\n",
    "        - X_test_mlo is the test array of MLO-images\n",
    "        - Y_test is the test array of labels\n",
    "    \"\"\"\n",
    "    np.random.seed(rand_seed)\n",
    "    index_test = np.array([], dtype = 'int64')\n",
    "    for i in np.unique(Y_traintest):\n",
    "        index_test = np.append(index_test, \n",
    "                               np.random.choice(list(np.where(Y_traintest == i)[0]), size = int(np.where(Y_traintest == i)[0].shape[0]*frac_test), replace = False))\n",
    "    X_train_cc = np.delete(X_traintest_cc, index_test, axis = 0)\n",
    "    X_train_mlo = np.delete(X_traintest_mlo, index_test, axis = 0)\n",
    "    Y_train = np.delete(Y_traintest, index_test)\n",
    "    X_test_cc = np.take(X_traintest_cc, index_test, axis = 0)\n",
    "    X_test_mlo = np.take(X_traintest_mlo, index_test, axis = 0)\n",
    "    Y_test = np.take(Y_traintest, index_test)\n",
    "    X_train_cc, X_train_mlo, Y_train = preprocess_data(X_train_cc, X_train_mlo, Y_train)\n",
    "    X_test_cc, X_test_mlo, Y_test = preprocess_data(X_test_cc, X_test_mlo, Y_test)\n",
    "\n",
    "    return X_train_cc, X_train_mlo, Y_train, X_test_cc, X_test_mlo, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc65ae4",
   "metadata": {
    "id": "korean-press"
   },
   "source": [
    "Definimos los parámetros básicos para el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef95793",
   "metadata": {
    "executionInfo": {
     "elapsed": 96766,
     "status": "ok",
     "timestamp": 1621188806395,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "incident-sender"
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "no_epochs = 200\n",
    "rand_seed = 2021\n",
    "learning_rate = 0.001\n",
    "momentum = 0.8\n",
    "n_folds = 2\n",
    "frac_test = .2/.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ea038",
   "metadata": {
    "id": "0j95AaVx5bCa"
   },
   "source": [
    "Dado el desbalance que sufren las categorías de la muestra de entrenamiento, forzamos el balanceo calculando las proporciones respecto a la clase más representada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f47d0ca",
   "metadata": {
    "executionInfo": {
     "elapsed": 96765,
     "status": "ok",
     "timestamp": 1621188806396,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "pb5VnDmd5bCe"
   },
   "outputs": [],
   "source": [
    "label, counts = np.unique(Y_traintest, return_counts = True)\n",
    "class_weight = {}\n",
    "for lab, con in zip(label, counts):\n",
    "  class_weight.update({lab: round(max(counts)/con, 2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5416ab33",
   "metadata": {
    "id": "GKOHQP5Q5e47"
   },
   "source": [
    "Definimos un callback para el entrenamiento de la red, de tal manera que nos aseguramos que el entrenamiento disminuye el learning rate cuando la pérdida sobre el conjutno de test ya no disminuye y detenemos el entrenamiento cuando dich pérdida tampoco disminuye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac6f462",
   "metadata": {
    "executionInfo": {
     "elapsed": 96764,
     "status": "ok",
     "timestamp": 1621188806397,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "s_zS0yCB5gZ0"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(factor = 0.5, patience = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37113b27",
   "metadata": {
    "id": "yVvCVm45MlNh"
   },
   "source": [
    "Iteramos la definición y el entrenamiento de la red para no sesgar los resultados según el conjunto de entrenamiento y de test escogido en cada caso. Almacenamos el output de cada iteración para poder representarlos más adelante, evaluando cada red obtenida mediante el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb6f282f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1433256,
     "status": "ok",
     "timestamp": 1621190142892,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "studied-billy",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d8f46312-b88f-4cc0-a97e-cbdb91bbf7d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for combination 1/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 32s 2s/step - loss: 0.8222 - accuracy: 0.8544 - precision: 0.9440 - recall: 0.7468 - auc: 0.9689 - val_loss: 0.5374 - val_accuracy: 0.9038 - val_precision: 0.9286 - val_recall: 0.7500 - val_auc: 0.9676 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.7634 - accuracy: 0.8481 - precision: 0.9365 - recall: 0.7468 - auc: 0.9722 - val_loss: 0.4880 - val_accuracy: 0.9231 - val_precision: 0.9130 - val_recall: 0.8077 - val_auc: 0.9706 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.7264 - accuracy: 0.8481 - precision: 0.9474 - recall: 0.7975 - auc: 0.9796 - val_loss: 0.4902 - val_accuracy: 0.8846 - val_precision: 0.9130 - val_recall: 0.8077 - val_auc: 0.9731 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6820 - accuracy: 0.8734 - precision: 0.9416 - recall: 0.8165 - auc: 0.9830 - val_loss: 0.4784 - val_accuracy: 0.8846 - val_precision: 0.9130 - val_recall: 0.8077 - val_auc: 0.9725 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6566 - accuracy: 0.9051 - precision: 0.9416 - recall: 0.8165 - auc: 0.9836 - val_loss: 0.4754 - val_accuracy: 0.8846 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9731 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6084 - accuracy: 0.9177 - precision: 0.9643 - recall: 0.8544 - auc: 0.9865 - val_loss: 0.4599 - val_accuracy: 0.8654 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9737 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5824 - accuracy: 0.9114 - precision: 0.9510 - recall: 0.8608 - auc: 0.9881 - val_loss: 0.4505 - val_accuracy: 0.8654 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9740 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5530 - accuracy: 0.9114 - precision: 0.9577 - recall: 0.8608 - auc: 0.9888 - val_loss: 0.4426 - val_accuracy: 0.8654 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9738 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5339 - accuracy: 0.9367 - precision: 0.9648 - recall: 0.8671 - auc: 0.9910 - val_loss: 0.4253 - val_accuracy: 0.8846 - val_precision: 0.9362 - val_recall: 0.8462 - val_auc: 0.9750 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5153 - accuracy: 0.9241 - precision: 0.9577 - recall: 0.8608 - auc: 0.9905 - val_loss: 0.4126 - val_accuracy: 0.8846 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9752 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.5028 - accuracy: 0.9304 - precision: 0.9653 - recall: 0.8797 - auc: 0.9918 - val_loss: 0.4160 - val_accuracy: 0.8846 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9762 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4728 - accuracy: 0.9367 - precision: 0.9589 - recall: 0.8861 - auc: 0.9926 - val_loss: 0.4057 - val_accuracy: 0.8846 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9764 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3681 - accuracy: 0.9557 - precision: 0.9733 - recall: 0.9241 - auc: 0.9961 - val_loss: 0.3724 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3588 - accuracy: 0.9557 - precision: 0.9669 - recall: 0.9241 - auc: 0.9962 - val_loss: 0.3692 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3529 - accuracy: 0.9557 - precision: 0.9737 - recall: 0.9367 - auc: 0.9964 - val_loss: 0.3676 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3455 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9965 - val_loss: 0.3652 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3362 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9970 - val_loss: 0.3676 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3306 - accuracy: 0.9494 - precision: 0.9675 - recall: 0.9430 - auc: 0.9968 - val_loss: 0.3604 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3254 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9969 - val_loss: 0.3609 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3178 - accuracy: 0.9557 - precision: 0.9675 - recall: 0.9430 - auc: 0.9971 - val_loss: 0.3588 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3113 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9974 - val_loss: 0.3590 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3058 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9973 - val_loss: 0.3551 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2993 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9976 - val_loss: 0.3557 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2959 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9976 - val_loss: 0.3529 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2722 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9982 - val_loss: 0.3435 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2660 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9983 - val_loss: 0.3433 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2635 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9984 - val_loss: 0.3411 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2582 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9985 - val_loss: 0.3396 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.2546 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9983 - val_loss: 0.3378 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2517 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9985 - val_loss: 0.3369 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2489 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9984 - val_loss: 0.3361 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2455 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9986 - val_loss: 0.3346 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2412 - accuracy: 0.9620 - precision: 0.9740 - recall: 0.9494 - auc: 0.9988 - val_loss: 0.3338 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2380 - accuracy: 0.9557 - precision: 0.9742 - recall: 0.9557 - auc: 0.9988 - val_loss: 0.3321 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2346 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9989 - val_loss: 0.3325 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2321 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9988 - val_loss: 0.3288 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2293 - accuracy: 0.9684 - precision: 0.9682 - recall: 0.9620 - auc: 0.9990 - val_loss: 0.3277 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2283 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9987 - val_loss: 0.3275 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2231 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3293 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2205 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9991 - val_loss: 0.3288 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2173 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9991 - val_loss: 0.3283 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2165 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9991 - val_loss: 0.3267 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2139 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3251 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2106 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3239 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2084 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3254 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.2053 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3241 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2033 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3233 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2008 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3216 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2003 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3228 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1968 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3209 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1954 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3197 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1943 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3196 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1916 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3182 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1911 - accuracy: 0.9684 - precision: 0.9679 - recall: 0.9557 - auc: 0.9992 - val_loss: 0.3206 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9763 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1869 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3189 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1857 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3185 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1839 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3175 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1820 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3165 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1806 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3158 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1782 - accuracy: 0.9747 - precision: 0.9871 - recall: 0.9684 - auc: 0.9994 - val_loss: 0.3140 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1764 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3146 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1762 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3136 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1731 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3139 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1718 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3123 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1706 - accuracy: 0.9747 - precision: 0.9808 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3133 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1696 - accuracy: 0.9747 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3117 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1677 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3111 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1666 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3111 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1655 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3114 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1635 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3117 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1620 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3115 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1603 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9997 - val_loss: 0.3109 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1590 - accuracy: 0.9873 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3094 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1579 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3091 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1572 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3080 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1568 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3071 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1549 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3077 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1529 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3086 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1524 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3082 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1511 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3076 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1496 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3071 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1481 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3069 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1474 - accuracy: 0.9937 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3068 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1467 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3064 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1463 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3062 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1457 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3057 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1453 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3058 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1449 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3059 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1446 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3053 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1435 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3052 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1434 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3052 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1426 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3049 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1423 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3048 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1415 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.3048 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1413 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3044 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1406 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3044 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1404 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3042 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1400 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3042 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1392 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3041 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1386 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3040 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1380 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3037 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1377 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3037 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1372 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3032 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1367 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3028 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1362 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3029 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1360 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3030 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1353 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3028 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1347 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3028 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1344 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3027 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1343 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3025 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1336 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3024 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1335 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3022 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1326 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3019 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1322 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3016 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1317 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3015 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1314 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3015 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1308 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3013 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1306 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3008 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1299 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3006 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1296 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3005 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1291 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1290 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3007 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1281 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3005 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1280 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3003 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1275 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3000 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1270 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1266 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1262 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1257 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1255 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2996 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1251 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1250 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1244 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2993 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1238 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2991 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1234 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1234 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2987 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1228 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1224 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1221 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1216 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1213 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1213 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1206 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1202 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1200 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1195 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1190 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1188 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1186 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1179 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1177 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1175 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1168 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1166 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1163 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1160 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1156 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1152 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1153 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1147 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1142 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1142 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1140 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1133 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1130 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1127 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1125 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1122 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1117 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1114 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1111 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1109 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1104 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1102 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1098 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1096 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1092 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1090 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1089 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1085 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1081 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1078 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1076 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1072 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1071 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1068 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1064 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1061 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.7; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 31s 2s/step - loss: 0.6652 - accuracy: 0.9494 - precision: 0.9928 - recall: 0.8671 - auc: 0.9949 - val_loss: 0.8080 - val_accuracy: 0.6346 - val_precision: 0.7419 - val_recall: 0.4423 - val_auc: 0.8399 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6163 - accuracy: 0.9304 - precision: 0.9786 - recall: 0.8671 - auc: 0.9939 - val_loss: 0.7692 - val_accuracy: 0.6731 - val_precision: 0.7742 - val_recall: 0.4615 - val_auc: 0.8599 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5807 - accuracy: 0.9177 - precision: 0.9650 - recall: 0.8734 - auc: 0.9950 - val_loss: 0.7476 - val_accuracy: 0.6923 - val_precision: 0.7812 - val_recall: 0.4808 - val_auc: 0.8697 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.5441 - accuracy: 0.9430 - precision: 0.9724 - recall: 0.8924 - auc: 0.9959 - val_loss: 0.7459 - val_accuracy: 0.6731 - val_precision: 0.7105 - val_recall: 0.5192 - val_auc: 0.8688 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.5109 - accuracy: 0.9430 - precision: 0.9722 - recall: 0.8861 - auc: 0.9961 - val_loss: 0.7179 - val_accuracy: 0.6923 - val_precision: 0.7568 - val_recall: 0.5385 - val_auc: 0.8738 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4914 - accuracy: 0.9620 - precision: 0.9865 - recall: 0.9241 - auc: 0.9974 - val_loss: 0.7122 - val_accuracy: 0.6923 - val_precision: 0.7500 - val_recall: 0.5192 - val_auc: 0.8791 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4677 - accuracy: 0.9557 - precision: 0.9797 - recall: 0.9177 - auc: 0.9973 - val_loss: 0.6950 - val_accuracy: 0.6923 - val_precision: 0.7632 - val_recall: 0.5577 - val_auc: 0.8839 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4493 - accuracy: 0.9557 - precision: 0.9799 - recall: 0.9241 - auc: 0.9975 - val_loss: 0.6829 - val_accuracy: 0.7115 - val_precision: 0.7692 - val_recall: 0.5769 - val_auc: 0.8875 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4292 - accuracy: 0.9684 - precision: 0.9867 - recall: 0.9367 - auc: 0.9981 - val_loss: 0.6689 - val_accuracy: 0.7308 - val_precision: 0.7500 - val_recall: 0.5769 - val_auc: 0.8930 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4134 - accuracy: 0.9620 - precision: 0.9801 - recall: 0.9367 - auc: 0.9978 - val_loss: 0.6723 - val_accuracy: 0.6923 - val_precision: 0.7561 - val_recall: 0.5962 - val_auc: 0.8920 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3988 - accuracy: 0.9810 - precision: 0.9867 - recall: 0.9367 - auc: 0.9985 - val_loss: 0.6544 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.5769 - val_auc: 0.8977 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3848 - accuracy: 0.9747 - precision: 0.9804 - recall: 0.9494 - auc: 0.9984 - val_loss: 0.6545 - val_accuracy: 0.7308 - val_precision: 0.7838 - val_recall: 0.5577 - val_auc: 0.8980 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3722 - accuracy: 0.9620 - precision: 0.9867 - recall: 0.9367 - auc: 0.9986 - val_loss: 0.6365 - val_accuracy: 0.7885 - val_precision: 0.7692 - val_recall: 0.5769 - val_auc: 0.9032 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3617 - accuracy: 0.9620 - precision: 0.9803 - recall: 0.9430 - auc: 0.9983 - val_loss: 0.6353 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9013 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3488 - accuracy: 0.9747 - precision: 0.9868 - recall: 0.9430 - auc: 0.9989 - val_loss: 0.6279 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9043 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3371 - accuracy: 0.9620 - precision: 0.9868 - recall: 0.9430 - auc: 0.9987 - val_loss: 0.6238 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9030 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3298 - accuracy: 0.9747 - precision: 0.9868 - recall: 0.9430 - auc: 0.9992 - val_loss: 0.6161 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9060 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3190 - accuracy: 0.9747 - precision: 0.9934 - recall: 0.9557 - auc: 0.9991 - val_loss: 0.6078 - val_accuracy: 0.7308 - val_precision: 0.7907 - val_recall: 0.6538 - val_auc: 0.9075 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3132 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9684 - auc: 0.9994 - val_loss: 0.6027 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9083 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3038 - accuracy: 0.9747 - precision: 0.9934 - recall: 0.9494 - auc: 0.9993 - val_loss: 0.6003 - val_accuracy: 0.7500 - val_precision: 0.7857 - val_recall: 0.6346 - val_auc: 0.9111 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2944 - accuracy: 0.9684 - precision: 0.9805 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.6010 - val_accuracy: 0.7308 - val_precision: 0.7556 - val_recall: 0.6538 - val_auc: 0.9082 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2885 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.5930 - val_accuracy: 0.7308 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9102 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2821 - accuracy: 0.9684 - precision: 0.9935 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.5865 - val_accuracy: 0.7500 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9114 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2758 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.5887 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9108 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2691 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.5876 - val_accuracy: 0.7308 - val_precision: 0.7609 - val_recall: 0.6731 - val_auc: 0.9107 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2637 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.5842 - val_accuracy: 0.7308 - val_precision: 0.7660 - val_recall: 0.6923 - val_auc: 0.9126 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2573 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.5804 - val_accuracy: 0.7308 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9122 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2525 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.5774 - val_accuracy: 0.7500 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9131 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.2490 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5712 - val_accuracy: 0.7308 - val_precision: 0.7660 - val_recall: 0.6923 - val_auc: 0.9144 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2428 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.5715 - val_accuracy: 0.7308 - val_precision: 0.7872 - val_recall: 0.7115 - val_auc: 0.9147 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2392 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.5676 - val_accuracy: 0.7308 - val_precision: 0.7660 - val_recall: 0.6923 - val_auc: 0.9160 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2337 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5656 - val_accuracy: 0.7308 - val_precision: 0.7660 - val_recall: 0.6923 - val_auc: 0.9163 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2311 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.5657 - val_accuracy: 0.7308 - val_precision: 0.7872 - val_recall: 0.7115 - val_auc: 0.9163 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2268 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5628 - val_accuracy: 0.7308 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9167 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2235 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5599 - val_accuracy: 0.7308 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9181 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2188 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5578 - val_accuracy: 0.7500 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9177 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2161 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5566 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9173 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2117 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5540 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9179 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2088 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5476 - val_accuracy: 0.7692 - val_precision: 0.8043 - val_recall: 0.7115 - val_auc: 0.9203 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2054 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5487 - val_accuracy: 0.7500 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9197 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2025 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5438 - val_accuracy: 0.7500 - val_precision: 0.8085 - val_recall: 0.7308 - val_auc: 0.9211 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2001 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5440 - val_accuracy: 0.7500 - val_precision: 0.7917 - val_recall: 0.7308 - val_auc: 0.9213 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1962 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5474 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9177 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1942 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5435 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9204 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1907 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5427 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9213 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1878 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5442 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9191 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1854 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5412 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9211 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1829 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5417 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9198 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1807 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 1.0000 - val_loss: 0.5385 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9209 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1786 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5387 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9213 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1756 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5383 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9211 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1742 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 1.0000 - val_loss: 0.5368 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9210 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1725 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9216 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1700 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1679 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5328 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9219 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1658 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.7692 - val_precision: 0.7959 - val_recall: 0.7500 - val_auc: 0.9226 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1646 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5277 - val_accuracy: 0.7885 - val_precision: 0.8000 - val_recall: 0.7692 - val_auc: 0.9235 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1622 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5303 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9219 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1602 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1580 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5285 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9226 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1565 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5270 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9226 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1549 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9232 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1530 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5255 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9229 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1516 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1504 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1483 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9223 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1472 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9226 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1457 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5229 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9228 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1452 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5211 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9233 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1429 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.7692 - val_precision: 0.8000 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1416 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9225 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1404 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9217 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1384 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.7692 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9223 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1372 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5185 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9237 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1366 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1347 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1335 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1326 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5162 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1310 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1299 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9234 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1289 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9245 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1281 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1269 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9234 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1255 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9234 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1247 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1234 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5138 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1227 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9229 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1215 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1205 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1194 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1189 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9247 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1180 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1168 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1159 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9249 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1153 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9246 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1152 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1135 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1127 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1118 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9246 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1107 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1105 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1100 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1093 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1092 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9239 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1085 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1083 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1077 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1077 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1075 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1073 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1070 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1069 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1067 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9239 - lr: 2.5000e-04\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1065 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1063 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1061 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9246 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1059 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1057 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9246 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1056 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9246 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1053 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9246 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1052 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1050 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1048 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1047 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1044 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1043 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1041 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1040 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1039 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9246 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1036 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1034 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1032 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1031 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1029 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1027 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1026 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1023 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9245 - lr: 1.2500e-04\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1023 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 1.2500e-04\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1022 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 1.2500e-04\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 1.2500e-04\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1020 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 1.2500e-04\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1019 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 1.2500e-04\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1018 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 1.2500e-04\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 1.2500e-04\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 6.2500e-05\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1016 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 6.2500e-05\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 6.2500e-05\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 6.2500e-05\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 6.2500e-05\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1014 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 6.2500e-05\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1014 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 6.2500e-05\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 6.2500e-05\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 6.2500e-05\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 6.2500e-05\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 3.1250e-05\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 3.1250e-05\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 3.1250e-05\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 3.1250e-05\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 3.1250e-05\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 3.1250e-05\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 3.1250e-05\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 3.1250e-05\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.5625e-05\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.5625e-05\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.5625e-05\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.5625e-05\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.5625e-05\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 7.8125e-06\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 7.8125e-06\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 7.8125e-06\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 7.8125e-06\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 7.8125e-06\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 3.9063e-06\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 3.9063e-06\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 3.9063e-06\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 3.9063e-06\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 3.9063e-06\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.9531e-06\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.9531e-06\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.9531e-06\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.9531e-06\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.9531e-06\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 9.7656e-07\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 9.7656e-07\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 9.7656e-07\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 9.7656e-07\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 9.7656e-07\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 4.8828e-07\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 4.8828e-07\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 4.8828e-07\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 4.8828e-07\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 4.8828e-07\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.4414e-07\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.4414e-07\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.4414e-07\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.4414e-07\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.4414e-07\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2207e-07\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2207e-07\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2207e-07\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.73; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.7 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.73 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0):\n",
      "> Accuracy: 0.71 (+- 0.06)\n",
      "> Loss: 0.72 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 2/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 31s 2s/step - loss: 0.8253 - accuracy: 0.8481 - precision: 0.9206 - recall: 0.7342 - auc: 0.9673 - val_loss: 0.5042 - val_accuracy: 0.8846 - val_precision: 0.9286 - val_recall: 0.7500 - val_auc: 0.9694 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.7097 - accuracy: 0.8861 - precision: 0.9407 - recall: 0.8038 - auc: 0.9810 - val_loss: 0.4799 - val_accuracy: 0.8846 - val_precision: 0.9111 - val_recall: 0.7885 - val_auc: 0.9734 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6336 - accuracy: 0.8987 - precision: 0.9568 - recall: 0.8418 - auc: 0.9855 - val_loss: 0.4463 - val_accuracy: 0.9038 - val_precision: 0.9318 - val_recall: 0.7885 - val_auc: 0.9721 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5872 - accuracy: 0.8924 - precision: 0.9493 - recall: 0.8291 - auc: 0.9854 - val_loss: 0.4211 - val_accuracy: 0.8846 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9745 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5445 - accuracy: 0.9114 - precision: 0.9514 - recall: 0.8671 - auc: 0.9892 - val_loss: 0.4190 - val_accuracy: 0.8846 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9758 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4885 - accuracy: 0.9304 - precision: 0.9583 - recall: 0.8734 - auc: 0.9925 - val_loss: 0.4068 - val_accuracy: 0.8846 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4583 - accuracy: 0.9430 - precision: 0.9658 - recall: 0.8924 - auc: 0.9936 - val_loss: 0.3998 - val_accuracy: 0.9038 - val_precision: 0.9362 - val_recall: 0.8462 - val_auc: 0.9754 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4291 - accuracy: 0.9367 - precision: 0.9724 - recall: 0.8924 - auc: 0.9934 - val_loss: 0.3959 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4114 - accuracy: 0.9430 - precision: 0.9664 - recall: 0.9114 - auc: 0.9943 - val_loss: 0.3879 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3861 - accuracy: 0.9557 - precision: 0.9669 - recall: 0.9241 - auc: 0.9958 - val_loss: 0.3757 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3661 - accuracy: 0.9430 - precision: 0.9733 - recall: 0.9241 - auc: 0.9959 - val_loss: 0.3760 - val_accuracy: 0.8654 - val_precision: 0.9184 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3565 - accuracy: 0.9557 - precision: 0.9613 - recall: 0.9430 - auc: 0.9958 - val_loss: 0.3723 - val_accuracy: 0.8654 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3336 - accuracy: 0.9494 - precision: 0.9675 - recall: 0.9430 - auc: 0.9967 - val_loss: 0.3660 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3235 - accuracy: 0.9620 - precision: 0.9615 - recall: 0.9494 - auc: 0.9971 - val_loss: 0.3598 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3122 - accuracy: 0.9557 - precision: 0.9675 - recall: 0.9430 - auc: 0.9968 - val_loss: 0.3575 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3068 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9972 - val_loss: 0.3520 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2877 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9973 - val_loss: 0.3513 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2772 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9982 - val_loss: 0.3456 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2711 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9978 - val_loss: 0.3451 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2619 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9982 - val_loss: 0.3437 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2539 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9982 - val_loss: 0.3341 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2476 - accuracy: 0.9620 - precision: 0.9618 - recall: 0.9557 - auc: 0.9988 - val_loss: 0.3342 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2384 - accuracy: 0.9557 - precision: 0.9742 - recall: 0.9557 - auc: 0.9987 - val_loss: 0.3354 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2329 - accuracy: 0.9557 - precision: 0.9742 - recall: 0.9557 - auc: 0.9989 - val_loss: 0.3332 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2271 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3322 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2222 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3280 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2162 - accuracy: 0.9684 - precision: 0.9805 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3254 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2110 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3229 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2061 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9991 - val_loss: 0.3236 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2027 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3251 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9765 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2007 - accuracy: 0.9747 - precision: 0.9744 - recall: 0.9620 - auc: 0.9991 - val_loss: 0.3204 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1931 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3182 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1897 - accuracy: 0.9684 - precision: 0.9679 - recall: 0.9557 - auc: 0.9992 - val_loss: 0.3198 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1858 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3209 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9761 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1853 - accuracy: 0.9747 - precision: 0.9744 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3158 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1782 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3146 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1758 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3147 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1739 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3126 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1700 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3112 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1661 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3117 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1645 - accuracy: 0.9873 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3107 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1620 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3123 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9765 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1592 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3090 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1552 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9997 - val_loss: 0.3077 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1537 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3095 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1510 - accuracy: 0.9873 - precision: 0.9871 - recall: 0.9684 - auc: 0.9997 - val_loss: 0.3075 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1490 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9997 - val_loss: 0.3058 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1468 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3044 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1443 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3041 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1416 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3047 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1404 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3042 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1385 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3046 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1360 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3020 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1342 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3006 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1332 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3010 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1303 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3016 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1300 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3021 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1284 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3014 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1259 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.2990 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1238 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1237 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2980 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1219 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2968 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1200 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1186 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2959 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1168 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1160 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2951 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1151 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1129 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1120 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1111 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1099 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1082 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1066 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1059 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1046 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1035 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1027 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1015 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0996 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0985 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0978 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0967 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0956 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0949 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0942 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0928 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0921 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0914 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0905 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0896 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0887 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0882 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0875 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0867 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0865 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0851 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0842 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0835 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0829 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0831 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0814 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0810 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0797 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0788 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0785 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0780 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0776 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0766 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0763 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0758 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0747 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0746 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0739 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0739 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0727 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0727 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0719 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0712 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0706 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0701 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0700 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0697 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0688 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0682 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0678 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0672 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0667 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0664 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0660 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0655 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0654 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0650 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0642 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0640 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0629 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0632 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0621 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0621 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0616 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0612 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0609 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0603 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0601 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0599 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0594 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0589 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0586 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0583 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0581 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0577 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0572 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0569 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0569 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0564 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0562 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0557 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0551 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9797 - lr: 5.0000e-04\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0550 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9796 - lr: 5.0000e-04\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0550 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9797 - lr: 5.0000e-04\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0548 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0545 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9797 - lr: 5.0000e-04\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0545 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9800 - lr: 5.0000e-04\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0543 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9797 - lr: 5.0000e-04\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0543 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0540 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0540 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0537 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0537 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0534 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0532 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9800 - lr: 5.0000e-04\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0531 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0530 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0529 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0527 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0526 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0524 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0524 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0522 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0521 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0518 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0519 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0518 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0514 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0514 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9799 - lr: 5.0000e-04\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0512 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0511 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0509 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0508 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 5.0000e-04\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0506 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0505 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0505 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 5.0000e-04\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0502 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 5.0000e-04\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0501 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 2.5000e-04\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0501 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 2.5000e-04\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0500 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 2.5000e-04\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0499 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 2.5000e-04\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0499 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 2.5000e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 30s 2s/step - loss: 0.6571 - accuracy: 0.9430 - precision: 0.9778 - recall: 0.8354 - auc: 0.9927 - val_loss: 0.7656 - val_accuracy: 0.7115 - val_precision: 0.7419 - val_recall: 0.4423 - val_auc: 0.8554 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5752 - accuracy: 0.9430 - precision: 0.9795 - recall: 0.9051 - auc: 0.9951 - val_loss: 0.7679 - val_accuracy: 0.6731 - val_precision: 0.7429 - val_recall: 0.5000 - val_auc: 0.8594 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5154 - accuracy: 0.9430 - precision: 0.9796 - recall: 0.9114 - auc: 0.9964 - val_loss: 0.7171 - val_accuracy: 0.6731 - val_precision: 0.7632 - val_recall: 0.5577 - val_auc: 0.8819 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4651 - accuracy: 0.9494 - precision: 0.9863 - recall: 0.9114 - auc: 0.9970 - val_loss: 0.6723 - val_accuracy: 0.7308 - val_precision: 0.7838 - val_recall: 0.5577 - val_auc: 0.8915 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4350 - accuracy: 0.9494 - precision: 0.9800 - recall: 0.9304 - auc: 0.9975 - val_loss: 0.6557 - val_accuracy: 0.7500 - val_precision: 0.8333 - val_recall: 0.5769 - val_auc: 0.8956 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3935 - accuracy: 0.9557 - precision: 0.9600 - recall: 0.9114 - auc: 0.9973 - val_loss: 0.6624 - val_accuracy: 0.7115 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.8909 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3727 - accuracy: 0.9747 - precision: 0.9867 - recall: 0.9367 - auc: 0.9987 - val_loss: 0.6236 - val_accuracy: 0.7308 - val_precision: 0.7857 - val_recall: 0.6346 - val_auc: 0.9036 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3452 - accuracy: 0.9747 - precision: 0.9804 - recall: 0.9494 - auc: 0.9990 - val_loss: 0.6215 - val_accuracy: 0.7500 - val_precision: 0.7805 - val_recall: 0.6154 - val_auc: 0.9054 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3260 - accuracy: 0.9620 - precision: 0.9869 - recall: 0.9557 - auc: 0.9988 - val_loss: 0.6159 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9058 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3107 - accuracy: 0.9747 - precision: 0.9869 - recall: 0.9557 - auc: 0.9991 - val_loss: 0.5990 - val_accuracy: 0.7308 - val_precision: 0.7955 - val_recall: 0.6731 - val_auc: 0.9104 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2947 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9994 - val_loss: 0.5958 - val_accuracy: 0.7308 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9102 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2826 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.5832 - val_accuracy: 0.7308 - val_precision: 0.8182 - val_recall: 0.6923 - val_auc: 0.9135 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2654 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.5780 - val_accuracy: 0.7308 - val_precision: 0.7609 - val_recall: 0.6731 - val_auc: 0.9127 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2561 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9684 - auc: 0.9994 - val_loss: 0.5792 - val_accuracy: 0.7308 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9124 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2445 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5675 - val_accuracy: 0.7308 - val_precision: 0.7872 - val_recall: 0.7115 - val_auc: 0.9157 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2357 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5621 - val_accuracy: 0.7308 - val_precision: 0.7917 - val_recall: 0.7308 - val_auc: 0.9171 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2289 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5676 - val_accuracy: 0.7500 - val_precision: 0.7917 - val_recall: 0.7308 - val_auc: 0.9146 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2209 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5541 - val_accuracy: 0.7500 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9191 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2126 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5550 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9169 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2068 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5502 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9179 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2010 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5428 - val_accuracy: 0.7500 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9206 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1944 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5430 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9201 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1899 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5400 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9204 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1850 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5348 - val_accuracy: 0.7692 - val_precision: 0.7959 - val_recall: 0.7500 - val_auc: 0.9225 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1809 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5413 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9196 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1741 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9200 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1704 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5307 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1665 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9225 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1625 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9227 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1595 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.7692 - val_precision: 0.7959 - val_recall: 0.7500 - val_auc: 0.9239 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1577 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5287 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9208 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1526 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5286 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9207 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1499 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9217 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1466 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9209 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1444 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1409 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5208 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9227 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1373 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9225 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1353 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9245 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1324 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5179 - val_accuracy: 0.7692 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9230 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1303 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5152 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9243 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1282 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9234 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1255 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9233 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1240 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9249 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1221 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1198 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1179 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9249 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1161 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9234 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1145 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9249 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1127 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9235 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1110 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9234 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1097 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1083 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1062 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1052 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9248 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1035 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1021 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1007 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9245 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0993 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9249 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0980 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9252 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0973 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9255 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0960 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9255 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0955 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9254 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0948 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9257 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0944 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9255 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0938 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0930 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9257 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0927 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9260 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0923 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9259 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0916 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9260 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0908 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5037 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9260 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0904 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9261 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0899 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0894 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5037 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9260 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0890 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9259 - lr: 2.5000e-04\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0885 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9266 - lr: 2.5000e-04\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0882 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5037 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9263 - lr: 2.5000e-04\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0882 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9268 - lr: 2.5000e-04\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0879 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9266 - lr: 2.5000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0875 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9263 - lr: 1.2500e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0874 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 1.2500e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0873 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9261 - lr: 1.2500e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0871 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 1.2500e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0870 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9261 - lr: 1.2500e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0868 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 1.2500e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0868 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 1.2500e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0866 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 6.2500e-05\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0866 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9261 - lr: 6.2500e-05\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0865 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 6.2500e-05\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0864 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 6.2500e-05\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0864 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9261 - lr: 6.2500e-05\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0863 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 3.1250e-05\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0863 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 3.1250e-05\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0862 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9265 - lr: 3.1250e-05\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0862 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 3.1250e-05\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0862 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9263 - lr: 3.1250e-05\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.0862 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 3.1250e-05\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0861 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9265 - lr: 3.1250e-05\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0861 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9265 - lr: 1.5625e-05\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0861 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9263 - lr: 1.5625e-05\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0861 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9263 - lr: 1.5625e-05\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9265 - lr: 1.5625e-05\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9265 - lr: 1.5625e-05\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 7.8125e-06\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 7.8125e-06\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 7.8125e-06\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 7.8125e-06\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 7.8125e-06\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 3.9063e-06\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 3.9063e-06\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 3.9063e-06\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9263 - lr: 3.9063e-06\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0860 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 3.9063e-06\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 1.9531e-06\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 1.9531e-06\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 1.9531e-06\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 1.9531e-06\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 1.9531e-06\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 9.7656e-07\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 9.7656e-07\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 9.7656e-07\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 9.7656e-07\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 9.7656e-07\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 4.8828e-07\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 4.8828e-07\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 4.8828e-07\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 4.8828e-07\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 4.8828e-07\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 2.4414e-07\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 2.4414e-07\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 2.4414e-07\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 2.4414e-07\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.74; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.74 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0.5):\n",
      "> Accuracy: 0.69 (+- 0.04)\n",
      "> Loss: 0.75 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 3/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 31s 2s/step - loss: 0.8189 - accuracy: 0.8544 - precision: 0.9302 - recall: 0.7595 - auc: 0.9685 - val_loss: 0.5440 - val_accuracy: 0.8654 - val_precision: 0.9318 - val_recall: 0.7885 - val_auc: 0.9640 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6110 - accuracy: 0.8671 - precision: 0.9197 - recall: 0.7975 - auc: 0.9794 - val_loss: 0.3788 - val_accuracy: 0.9038 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9724 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4446 - accuracy: 0.9051 - precision: 0.9392 - recall: 0.8797 - auc: 0.9902 - val_loss: 0.4009 - val_accuracy: 0.8654 - val_precision: 0.8800 - val_recall: 0.8462 - val_auc: 0.9724 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3110 - accuracy: 0.9367 - precision: 0.9542 - recall: 0.9241 - auc: 0.9956 - val_loss: 0.3300 - val_accuracy: 0.9038 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9738 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2543 - accuracy: 0.9430 - precision: 0.9548 - recall: 0.9367 - auc: 0.9961 - val_loss: 0.3271 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9762 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2050 - accuracy: 0.9684 - precision: 0.9742 - recall: 0.9557 - auc: 0.9980 - val_loss: 0.3310 - val_accuracy: 0.8654 - val_precision: 0.8627 - val_recall: 0.8462 - val_auc: 0.9734 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1875 - accuracy: 0.9620 - precision: 0.9618 - recall: 0.9557 - auc: 0.9983 - val_loss: 0.3069 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9763 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1584 - accuracy: 0.9747 - precision: 0.9745 - recall: 0.9684 - auc: 0.9994 - val_loss: 0.3218 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9739 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1513 - accuracy: 0.9747 - precision: 0.9744 - recall: 0.9620 - auc: 0.9991 - val_loss: 0.3032 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1353 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.3004 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1260 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.2988 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1169 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.3013 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1114 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.2919 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1054 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2929 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1005 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0945 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0900 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.8654 - val_precision: 0.8800 - val_recall: 0.8462 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0859 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.8654 - val_precision: 0.8627 - val_recall: 0.8462 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0834 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0789 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0762 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0732 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0706 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0682 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0667 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0642 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0627 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0597 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0576 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0559 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0543 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0540 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0513 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0512 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0493 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0481 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.8654 - val_precision: 0.8800 - val_recall: 0.8462 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0461 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0458 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0445 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0433 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0424 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0415 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0410 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0402 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0390 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0381 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0374 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0366 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0361 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0354 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0348 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0342 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0337 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0332 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0324 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0320 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0318 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0308 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0304 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0299 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0295 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0291 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9804 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0287 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0282 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0279 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0275 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0269 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0267 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9802 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0263 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0258 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0256 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0252 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0249 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0245 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0242 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0239 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0236 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0234 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0232 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0229 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9802 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0226 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0222 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0220 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0217 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0217 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9809 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0213 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0211 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0208 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0206 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0203 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0201 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0199 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0198 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0195 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0194 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0191 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0190 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0188 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0186 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0184 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9804 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0179 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9808 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0177 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9803 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0176 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0174 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0174 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9810 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0171 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9808 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0170 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9810 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0169 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9808 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0168 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0167 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0166 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9803 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0166 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0165 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 5.0000e-04\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0164 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 5.0000e-04\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0164 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9804 - lr: 5.0000e-04\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0163 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9810 - lr: 5.0000e-04\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0162 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0162 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 5.0000e-04\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0161 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9802 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0160 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9803 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0160 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0160 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0159 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0159 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2500e-04\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0159 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2500e-04\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0158 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2500e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0158 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 1.2500e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0158 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9802 - lr: 1.2500e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0158 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9804 - lr: 6.2500e-05\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0158 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.2500e-05\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0158 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.2500e-05\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0158 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 6.2500e-05\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0157 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 6.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.91; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 34s 2s/step - loss: 0.6422 - accuracy: 0.9304 - precision: 0.9568 - recall: 0.8418 - auc: 0.9915 - val_loss: 0.7129 - val_accuracy: 0.7500 - val_precision: 0.7568 - val_recall: 0.5385 - val_auc: 0.8780 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5110 - accuracy: 0.9620 - precision: 0.9796 - recall: 0.9114 - auc: 0.9966 - val_loss: 0.6718 - val_accuracy: 0.7500 - val_precision: 0.7895 - val_recall: 0.5769 - val_auc: 0.8900 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3266 - accuracy: 0.9557 - precision: 0.9739 - recall: 0.9430 - auc: 0.9985 - val_loss: 0.5475 - val_accuracy: 0.7308 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9161 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2315 - accuracy: 0.9747 - precision: 0.9871 - recall: 0.9684 - auc: 0.9993 - val_loss: 0.5635 - val_accuracy: 0.7500 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9170 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1907 - accuracy: 0.9810 - precision: 1.0000 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5346 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9186 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1591 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5056 - val_accuracy: 0.7692 - val_precision: 0.7600 - val_recall: 0.7308 - val_auc: 0.9254 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1379 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5051 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9267 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1236 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.7692 - val_precision: 0.7692 - val_recall: 0.7692 - val_auc: 0.9260 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1137 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5026 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9269 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9273 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0990 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.7885 - val_precision: 0.8000 - val_recall: 0.7692 - val_auc: 0.9293 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0913 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9278 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0862 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9292 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0810 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0769 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9287 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0743 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.8077 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9291 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0704 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.7885 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9315 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0682 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9302 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0658 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.8077 - val_precision: 0.8077 - val_recall: 0.8077 - val_auc: 0.9293 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0641 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.8077 - val_precision: 0.8077 - val_recall: 0.8077 - val_auc: 0.9294 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0631 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0614 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9292 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0602 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9291 - lr: 2.5000e-04\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0595 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9291 - lr: 2.5000e-04\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0592 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8077 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9294 - lr: 2.5000e-04\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0584 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9290 - lr: 2.5000e-04\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0577 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9293 - lr: 2.5000e-04\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0571 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9296 - lr: 1.2500e-04\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0567 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0564 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9294 - lr: 1.2500e-04\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0563 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9293 - lr: 1.2500e-04\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0559 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9292 - lr: 1.2500e-04\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0556 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9296 - lr: 6.2500e-05\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0555 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9296 - lr: 6.2500e-05\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0553 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9297 - lr: 6.2500e-05\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0552 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9297 - lr: 6.2500e-05\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0551 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9297 - lr: 6.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.74; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.91 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.74 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0.9):\n",
      "> Accuracy: 0.72 (+- 0.01)\n",
      "> Loss: 0.83 (+- 0.08)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 4/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 30s 2s/step - loss: 0.8269 - accuracy: 0.8418 - precision: 0.9194 - recall: 0.7215 - auc: 0.9658 - val_loss: 0.5290 - val_accuracy: 0.9038 - val_precision: 0.9302 - val_recall: 0.7692 - val_auc: 0.9683 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.7708 - accuracy: 0.8481 - precision: 0.9528 - recall: 0.7658 - auc: 0.9737 - val_loss: 0.4995 - val_accuracy: 0.9038 - val_precision: 0.9111 - val_recall: 0.7885 - val_auc: 0.9712 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.7201 - accuracy: 0.8734 - precision: 0.9624 - recall: 0.8101 - auc: 0.9801 - val_loss: 0.4763 - val_accuracy: 0.9231 - val_precision: 0.9111 - val_recall: 0.7885 - val_auc: 0.9727 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6789 - accuracy: 0.8924 - precision: 0.9489 - recall: 0.8228 - auc: 0.9834 - val_loss: 0.4684 - val_accuracy: 0.9038 - val_precision: 0.9111 - val_recall: 0.7885 - val_auc: 0.9731 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.6516 - accuracy: 0.8861 - precision: 0.9420 - recall: 0.8228 - auc: 0.9849 - val_loss: 0.4651 - val_accuracy: 0.8846 - val_precision: 0.9111 - val_recall: 0.7885 - val_auc: 0.9731 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6127 - accuracy: 0.9051 - precision: 0.9562 - recall: 0.8291 - auc: 0.9867 - val_loss: 0.4446 - val_accuracy: 0.9038 - val_precision: 0.9130 - val_recall: 0.8077 - val_auc: 0.9739 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5867 - accuracy: 0.9241 - precision: 0.9577 - recall: 0.8608 - auc: 0.9878 - val_loss: 0.4374 - val_accuracy: 0.9038 - val_precision: 0.9130 - val_recall: 0.8077 - val_auc: 0.9743 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5610 - accuracy: 0.9114 - precision: 0.9514 - recall: 0.8671 - auc: 0.9877 - val_loss: 0.4276 - val_accuracy: 0.8846 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9745 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5365 - accuracy: 0.9304 - precision: 0.9580 - recall: 0.8671 - auc: 0.9904 - val_loss: 0.4195 - val_accuracy: 0.8846 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9748 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.5130 - accuracy: 0.9304 - precision: 0.9514 - recall: 0.8671 - auc: 0.9914 - val_loss: 0.4166 - val_accuracy: 0.8846 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9755 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.4983 - accuracy: 0.9367 - precision: 0.9580 - recall: 0.8671 - auc: 0.9916 - val_loss: 0.4155 - val_accuracy: 0.8654 - val_precision: 0.8958 - val_recall: 0.8269 - val_auc: 0.9749 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4760 - accuracy: 0.9367 - precision: 0.9653 - recall: 0.8797 - auc: 0.9930 - val_loss: 0.4060 - val_accuracy: 0.8654 - val_precision: 0.8958 - val_recall: 0.8269 - val_auc: 0.9754 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4618 - accuracy: 0.9367 - precision: 0.9586 - recall: 0.8797 - auc: 0.9931 - val_loss: 0.4089 - val_accuracy: 0.8654 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9753 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4478 - accuracy: 0.9367 - precision: 0.9658 - recall: 0.8924 - auc: 0.9939 - val_loss: 0.3993 - val_accuracy: 0.9038 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4315 - accuracy: 0.9367 - precision: 0.9592 - recall: 0.8924 - auc: 0.9942 - val_loss: 0.3958 - val_accuracy: 0.8654 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9762 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4199 - accuracy: 0.9557 - precision: 0.9662 - recall: 0.9051 - auc: 0.9945 - val_loss: 0.3876 - val_accuracy: 0.9038 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4095 - accuracy: 0.9430 - precision: 0.9660 - recall: 0.8987 - auc: 0.9949 - val_loss: 0.3863 - val_accuracy: 0.8846 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4003 - accuracy: 0.9494 - precision: 0.9664 - recall: 0.9114 - auc: 0.9957 - val_loss: 0.3773 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9763 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3885 - accuracy: 0.9430 - precision: 0.9667 - recall: 0.9177 - auc: 0.9956 - val_loss: 0.3815 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3818 - accuracy: 0.9557 - precision: 0.9730 - recall: 0.9114 - auc: 0.9956 - val_loss: 0.3744 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3682 - accuracy: 0.9557 - precision: 0.9732 - recall: 0.9177 - auc: 0.9961 - val_loss: 0.3723 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3584 - accuracy: 0.9494 - precision: 0.9673 - recall: 0.9367 - auc: 0.9964 - val_loss: 0.3679 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3543 - accuracy: 0.9557 - precision: 0.9737 - recall: 0.9367 - auc: 0.9963 - val_loss: 0.3708 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3444 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9965 - val_loss: 0.3673 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3365 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9967 - val_loss: 0.3603 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3317 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9966 - val_loss: 0.3575 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3238 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9970 - val_loss: 0.3567 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3185 - accuracy: 0.9557 - precision: 0.9615 - recall: 0.9494 - auc: 0.9971 - val_loss: 0.3573 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3121 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9969 - val_loss: 0.3543 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3056 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9974 - val_loss: 0.3517 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2997 - accuracy: 0.9620 - precision: 0.9740 - recall: 0.9494 - auc: 0.9976 - val_loss: 0.3527 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2942 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9977 - val_loss: 0.3525 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2901 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9976 - val_loss: 0.3492 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2848 - accuracy: 0.9557 - precision: 0.9615 - recall: 0.9494 - auc: 0.9979 - val_loss: 0.3484 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2803 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9982 - val_loss: 0.3503 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2748 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9981 - val_loss: 0.3467 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2723 - accuracy: 0.9620 - precision: 0.9677 - recall: 0.9494 - auc: 0.9982 - val_loss: 0.3450 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2675 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9982 - val_loss: 0.3420 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2635 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9982 - val_loss: 0.3425 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2580 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9983 - val_loss: 0.3402 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2561 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9986 - val_loss: 0.3380 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2515 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9986 - val_loss: 0.3400 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2475 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9986 - val_loss: 0.3370 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2453 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9987 - val_loss: 0.3366 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2427 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9987 - val_loss: 0.3353 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2376 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3348 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2350 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9988 - val_loss: 0.3320 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2323 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9988 - val_loss: 0.3322 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2286 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3306 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2263 - accuracy: 0.9620 - precision: 0.9618 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3303 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2246 - accuracy: 0.9557 - precision: 0.9742 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3295 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2200 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9991 - val_loss: 0.3280 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2181 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3282 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2179 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3275 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2124 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9991 - val_loss: 0.3265 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2108 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3258 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2091 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3246 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2055 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3233 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2038 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3226 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2036 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3222 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1986 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3206 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1969 - accuracy: 0.9747 - precision: 0.9744 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3216 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1967 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3217 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1929 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3206 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1910 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3196 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1884 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3182 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1869 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3182 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1855 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3163 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1841 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3159 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1821 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3156 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1800 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3168 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1784 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3160 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1768 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3150 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1748 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3151 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1744 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3136 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1716 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3145 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1711 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3127 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1695 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3120 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1685 - accuracy: 0.9684 - precision: 0.9870 - recall: 0.9620 - auc: 0.9995 - val_loss: 0.3119 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1672 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9995 - val_loss: 0.3117 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1657 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3124 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1632 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3102 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1618 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3096 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1604 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3095 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1607 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3089 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1578 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3088 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1563 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3094 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1552 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3093 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1547 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3095 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1533 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9997 - val_loss: 0.3084 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1517 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3086 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1515 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3067 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1494 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3069 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1487 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3057 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1471 - accuracy: 0.9810 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3060 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1465 - accuracy: 0.9810 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3057 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1450 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3054 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1440 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3045 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1436 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3046 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1419 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3049 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1404 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3047 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1400 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3040 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1395 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3034 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1384 - accuracy: 0.9937 - precision: 0.9935 - recall: 0.9747 - auc: 0.9999 - val_loss: 0.3027 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1370 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3031 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1364 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.3029 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1353 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3031 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1344 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3025 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1332 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3017 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1329 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3009 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1318 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3008 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1310 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1294 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3005 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1291 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1278 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3003 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1275 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2997 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1265 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2993 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1258 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2994 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1249 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1240 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2985 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1235 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1230 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1218 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1214 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1208 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1202 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1191 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1179 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1178 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1173 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1168 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1167 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1164 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1160 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1158 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1152 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1149 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1144 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1142 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1140 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1136 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1132 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1129 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1126 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1123 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1123 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1117 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1115 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1111 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1108 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1104 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1101 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1098 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1095 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1095 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1090 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1089 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1084 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1080 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1077 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1074 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1073 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1069 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1067 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1065 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1061 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1060 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1056 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1053 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1050 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1044 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1041 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1037 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1036 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1032 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1032 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1031 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1026 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1023 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1020 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1008 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1005 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1004 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0998 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0996 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0992 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0990 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0986 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0985 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0982 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0982 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0979 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0975 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0974 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.71; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 34s 2s/step - loss: 0.6653 - accuracy: 0.9494 - precision: 0.9851 - recall: 0.8354 - auc: 0.9934 - val_loss: 0.8029 - val_accuracy: 0.6538 - val_precision: 0.7188 - val_recall: 0.4423 - val_auc: 0.8436 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6243 - accuracy: 0.9241 - precision: 0.9928 - recall: 0.8671 - auc: 0.9942 - val_loss: 0.7607 - val_accuracy: 0.6731 - val_precision: 0.7812 - val_recall: 0.4808 - val_auc: 0.8629 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5817 - accuracy: 0.9304 - precision: 0.9724 - recall: 0.8924 - auc: 0.9948 - val_loss: 0.7641 - val_accuracy: 0.6731 - val_precision: 0.7222 - val_recall: 0.5000 - val_auc: 0.8611 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.5462 - accuracy: 0.9557 - precision: 0.9862 - recall: 0.9051 - auc: 0.9965 - val_loss: 0.7745 - val_accuracy: 0.6538 - val_precision: 0.7500 - val_recall: 0.5192 - val_auc: 0.8540 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5128 - accuracy: 0.9557 - precision: 0.9862 - recall: 0.9051 - auc: 0.9967 - val_loss: 0.7292 - val_accuracy: 0.6923 - val_precision: 0.7368 - val_recall: 0.5385 - val_auc: 0.8775 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4893 - accuracy: 0.9494 - precision: 0.9863 - recall: 0.9114 - auc: 0.9969 - val_loss: 0.6973 - val_accuracy: 0.7115 - val_precision: 0.7692 - val_recall: 0.5769 - val_auc: 0.8852 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4667 - accuracy: 0.9684 - precision: 0.9733 - recall: 0.9241 - auc: 0.9976 - val_loss: 0.6962 - val_accuracy: 0.7115 - val_precision: 0.7436 - val_recall: 0.5577 - val_auc: 0.8867 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4496 - accuracy: 0.9620 - precision: 0.9867 - recall: 0.9367 - auc: 0.9980 - val_loss: 0.6879 - val_accuracy: 0.7115 - val_precision: 0.7632 - val_recall: 0.5577 - val_auc: 0.8898 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4270 - accuracy: 0.9557 - precision: 0.9800 - recall: 0.9304 - auc: 0.9976 - val_loss: 0.6721 - val_accuracy: 0.7308 - val_precision: 0.7500 - val_recall: 0.5769 - val_auc: 0.8931 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4103 - accuracy: 0.9684 - precision: 0.9868 - recall: 0.9430 - auc: 0.9987 - val_loss: 0.6534 - val_accuracy: 0.7308 - val_precision: 0.7692 - val_recall: 0.5769 - val_auc: 0.8975 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3973 - accuracy: 0.9494 - precision: 0.9799 - recall: 0.9241 - auc: 0.9975 - val_loss: 0.6653 - val_accuracy: 0.7115 - val_precision: 0.7619 - val_recall: 0.6154 - val_auc: 0.8929 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3846 - accuracy: 0.9620 - precision: 0.9868 - recall: 0.9430 - auc: 0.9986 - val_loss: 0.6541 - val_accuracy: 0.7308 - val_precision: 0.7561 - val_recall: 0.5962 - val_auc: 0.8969 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3757 - accuracy: 0.9684 - precision: 0.9866 - recall: 0.9304 - auc: 0.9984 - val_loss: 0.6432 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.8994 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3593 - accuracy: 0.9620 - precision: 0.9867 - recall: 0.9367 - auc: 0.9985 - val_loss: 0.6383 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.8997 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3472 - accuracy: 0.9684 - precision: 0.9804 - recall: 0.9494 - auc: 0.9990 - val_loss: 0.6323 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9020 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3369 - accuracy: 0.9747 - precision: 0.9869 - recall: 0.9557 - auc: 0.9992 - val_loss: 0.6228 - val_accuracy: 0.7500 - val_precision: 0.7561 - val_recall: 0.5962 - val_auc: 0.9048 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3280 - accuracy: 0.9684 - precision: 0.9868 - recall: 0.9430 - auc: 0.9989 - val_loss: 0.6153 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9063 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3175 - accuracy: 0.9747 - precision: 0.9935 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.6094 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9075 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.3115 - accuracy: 0.9810 - precision: 0.9934 - recall: 0.9494 - auc: 0.9992 - val_loss: 0.6059 - val_accuracy: 0.7308 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9079 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3020 - accuracy: 0.9684 - precision: 0.9869 - recall: 0.9557 - auc: 0.9991 - val_loss: 0.6070 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9075 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2942 - accuracy: 0.9747 - precision: 0.9935 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.6007 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9084 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2887 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9995 - val_loss: 0.5976 - val_accuracy: 0.7308 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9096 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2850 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9684 - auc: 0.9994 - val_loss: 0.5922 - val_accuracy: 0.7308 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9102 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2751 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.5850 - val_accuracy: 0.7308 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9114 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2701 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9995 - val_loss: 0.5817 - val_accuracy: 0.7308 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9124 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2632 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.5824 - val_accuracy: 0.7308 - val_precision: 0.7660 - val_recall: 0.6923 - val_auc: 0.9132 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2585 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.5810 - val_accuracy: 0.7308 - val_precision: 0.7660 - val_recall: 0.6923 - val_auc: 0.9129 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2536 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5772 - val_accuracy: 0.7308 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9143 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2476 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.5727 - val_accuracy: 0.7308 - val_precision: 0.7660 - val_recall: 0.6923 - val_auc: 0.9148 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2427 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.5722 - val_accuracy: 0.7308 - val_precision: 0.7872 - val_recall: 0.7115 - val_auc: 0.9148 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2388 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.5697 - val_accuracy: 0.7500 - val_precision: 0.7872 - val_recall: 0.7115 - val_auc: 0.9148 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2347 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5628 - val_accuracy: 0.7500 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9173 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2303 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5600 - val_accuracy: 0.7308 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9168 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2268 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5583 - val_accuracy: 0.7308 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9180 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2232 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5548 - val_accuracy: 0.7308 - val_precision: 0.8043 - val_recall: 0.7115 - val_auc: 0.9184 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2185 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.5559 - val_accuracy: 0.7500 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9183 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2167 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5545 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9182 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2119 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5540 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9179 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2083 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5537 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9173 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2049 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5515 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9184 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2020 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5484 - val_accuracy: 0.7500 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9199 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1990 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5464 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9201 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1983 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5466 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9193 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1934 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9191 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1912 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5435 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9196 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1879 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5405 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9210 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1867 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.5446 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9187 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1834 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5403 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9210 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1810 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5375 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9213 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1781 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9207 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1757 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9210 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1738 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9219 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1727 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9218 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1696 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1681 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9221 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1665 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5290 - val_accuracy: 0.7692 - val_precision: 0.7959 - val_recall: 0.7500 - val_auc: 0.9228 - lr: 0.0010\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 13s 2s/step - loss: 0.0627 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.8077 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9283 - lr: 2.5000e-04\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0618 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9283 - lr: 2.5000e-04\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0613 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9285 - lr: 2.5000e-04\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0604 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9287 - lr: 1.2500e-04\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0602 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9289 - lr: 1.2500e-04\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0598 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9290 - lr: 1.2500e-04\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0596 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9286 - lr: 1.2500e-04\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0594 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9289 - lr: 1.2500e-04\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0589 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9285 - lr: 6.2500e-05\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0587 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9283 - lr: 6.2500e-05\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0586 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9284 - lr: 6.2500e-05\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0584 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9284 - lr: 6.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.73; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.9 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.73 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.9):\n",
      "> Accuracy: 0.72 (+- 0.01)\n",
      "> Loss: 0.82 (+- 0.08)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 7/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 35s 3s/step - loss: 0.8221 - accuracy: 0.8544 - precision: 0.9435 - recall: 0.7405 - auc: 0.9701 - val_loss: 0.5544 - val_accuracy: 0.9038 - val_precision: 0.9302 - val_recall: 0.7692 - val_auc: 0.9663 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.7659 - accuracy: 0.8734 - precision: 0.9380 - recall: 0.7658 - auc: 0.9773 - val_loss: 0.5328 - val_accuracy: 0.9038 - val_precision: 0.9318 - val_recall: 0.7885 - val_auc: 0.9681 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.7203 - accuracy: 0.8797 - precision: 0.9535 - recall: 0.7785 - auc: 0.9800 - val_loss: 0.4989 - val_accuracy: 0.8846 - val_precision: 0.9318 - val_recall: 0.7885 - val_auc: 0.9711 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6788 - accuracy: 0.8734 - precision: 0.9478 - recall: 0.8038 - auc: 0.9820 - val_loss: 0.4634 - val_accuracy: 0.9038 - val_precision: 0.9111 - val_recall: 0.7885 - val_auc: 0.9735 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6377 - accuracy: 0.8797 - precision: 0.9562 - recall: 0.8291 - auc: 0.9855 - val_loss: 0.4522 - val_accuracy: 0.9038 - val_precision: 0.9130 - val_recall: 0.8077 - val_auc: 0.9738 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.6092 - accuracy: 0.8924 - precision: 0.9568 - recall: 0.8418 - auc: 0.9875 - val_loss: 0.4545 - val_accuracy: 0.8654 - val_precision: 0.9130 - val_recall: 0.8077 - val_auc: 0.9737 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5831 - accuracy: 0.9241 - precision: 0.9504 - recall: 0.8481 - auc: 0.9877 - val_loss: 0.4444 - val_accuracy: 0.8846 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9732 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5557 - accuracy: 0.9241 - precision: 0.9650 - recall: 0.8734 - auc: 0.9906 - val_loss: 0.4291 - val_accuracy: 0.9038 - val_precision: 0.9130 - val_recall: 0.8077 - val_auc: 0.9744 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.5406 - accuracy: 0.9241 - precision: 0.9638 - recall: 0.8418 - auc: 0.9896 - val_loss: 0.4259 - val_accuracy: 0.8654 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9747 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.5156 - accuracy: 0.9367 - precision: 0.9586 - recall: 0.8797 - auc: 0.9915 - val_loss: 0.4261 - val_accuracy: 0.8654 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9751 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4948 - accuracy: 0.9367 - precision: 0.9580 - recall: 0.8671 - auc: 0.9922 - val_loss: 0.4161 - val_accuracy: 0.8654 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9761 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4793 - accuracy: 0.9304 - precision: 0.9655 - recall: 0.8861 - auc: 0.9931 - val_loss: 0.4048 - val_accuracy: 0.8846 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4677 - accuracy: 0.9367 - precision: 0.9586 - recall: 0.8797 - auc: 0.9929 - val_loss: 0.4098 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9753 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4445 - accuracy: 0.9430 - precision: 0.9664 - recall: 0.9114 - auc: 0.9943 - val_loss: 0.3935 - val_accuracy: 0.9038 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4379 - accuracy: 0.9367 - precision: 0.9658 - recall: 0.8924 - auc: 0.9937 - val_loss: 0.3926 - val_accuracy: 0.8654 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9762 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4225 - accuracy: 0.9494 - precision: 0.9660 - recall: 0.8987 - auc: 0.9945 - val_loss: 0.3873 - val_accuracy: 0.8846 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4068 - accuracy: 0.9367 - precision: 0.9660 - recall: 0.8987 - auc: 0.9950 - val_loss: 0.3862 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3992 - accuracy: 0.9557 - precision: 0.9667 - recall: 0.9177 - auc: 0.9956 - val_loss: 0.3809 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.3886 - accuracy: 0.9430 - precision: 0.9603 - recall: 0.9177 - auc: 0.9950 - val_loss: 0.3796 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3784 - accuracy: 0.9557 - precision: 0.9669 - recall: 0.9241 - auc: 0.9960 - val_loss: 0.3805 - val_accuracy: 0.8846 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3710 - accuracy: 0.9557 - precision: 0.9667 - recall: 0.9177 - auc: 0.9956 - val_loss: 0.3761 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3610 - accuracy: 0.9494 - precision: 0.9675 - recall: 0.9430 - auc: 0.9963 - val_loss: 0.3756 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3529 - accuracy: 0.9557 - precision: 0.9737 - recall: 0.9367 - auc: 0.9962 - val_loss: 0.3700 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3466 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9967 - val_loss: 0.3675 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3376 - accuracy: 0.9557 - precision: 0.9675 - recall: 0.9430 - auc: 0.9966 - val_loss: 0.3637 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3301 - accuracy: 0.9557 - precision: 0.9675 - recall: 0.9430 - auc: 0.9969 - val_loss: 0.3628 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3238 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9971 - val_loss: 0.3606 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3183 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9971 - val_loss: 0.3607 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3122 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9972 - val_loss: 0.3594 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3052 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9976 - val_loss: 0.3553 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3001 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9976 - val_loss: 0.3522 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2961 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9974 - val_loss: 0.3493 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2896 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9979 - val_loss: 0.3525 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2869 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9979 - val_loss: 0.3474 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2817 - accuracy: 0.9620 - precision: 0.9677 - recall: 0.9494 - auc: 0.9980 - val_loss: 0.3474 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2753 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9979 - val_loss: 0.3471 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2711 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9983 - val_loss: 0.3431 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2673 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9982 - val_loss: 0.3465 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2622 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9983 - val_loss: 0.3426 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2602 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9984 - val_loss: 0.3403 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2556 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9984 - val_loss: 0.3391 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2512 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9986 - val_loss: 0.3379 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2480 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9985 - val_loss: 0.3384 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.2442 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9987 - val_loss: 0.3348 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.2421 - accuracy: 0.9620 - precision: 0.9677 - recall: 0.9494 - auc: 0.9986 - val_loss: 0.3347 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2396 - accuracy: 0.9557 - precision: 0.9742 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3339 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2357 - accuracy: 0.9557 - precision: 0.9742 - recall: 0.9557 - auc: 0.9988 - val_loss: 0.3339 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.2318 - accuracy: 0.9620 - precision: 0.9804 - recall: 0.9494 - auc: 0.9989 - val_loss: 0.3331 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2288 - accuracy: 0.9620 - precision: 0.9744 - recall: 0.9620 - auc: 0.9991 - val_loss: 0.3319 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2256 - accuracy: 0.9620 - precision: 0.9742 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3317 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2233 - accuracy: 0.9557 - precision: 0.9742 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3308 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2204 - accuracy: 0.9620 - precision: 0.9744 - recall: 0.9620 - auc: 0.9990 - val_loss: 0.3277 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2183 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3292 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2153 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9991 - val_loss: 0.3275 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2123 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3264 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2098 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3252 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2082 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3260 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2071 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9991 - val_loss: 0.3247 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2042 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3235 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2015 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3225 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1995 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3235 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9768 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1970 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3223 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1952 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3204 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1926 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3196 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1907 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3205 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1891 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3180 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1874 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3188 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1855 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3186 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1834 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3184 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1823 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3182 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9765 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1802 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3192 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9766 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1784 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9994 - val_loss: 0.3174 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9771 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1779 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3173 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9771 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1764 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3168 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9770 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1757 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3165 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9770 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1747 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3163 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9771 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1740 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3154 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1731 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9995 - val_loss: 0.3153 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1724 - accuracy: 0.9747 - precision: 0.9871 - recall: 0.9684 - auc: 0.9994 - val_loss: 0.3143 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1716 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9995 - val_loss: 0.3142 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1707 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3143 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1700 - accuracy: 0.9810 - precision: 0.9870 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3141 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1691 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3135 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1684 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3129 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1680 - accuracy: 0.9810 - precision: 0.9870 - recall: 0.9620 - auc: 0.9995 - val_loss: 0.3126 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1670 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3125 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1661 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3123 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1655 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3123 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1649 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3119 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1644 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3115 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1638 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3117 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1636 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9995 - val_loss: 0.3116 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1627 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3118 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9776 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1614 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3113 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9776 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1612 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3112 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9776 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1602 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3108 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1593 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3102 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1590 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9997 - val_loss: 0.3098 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1584 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3099 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1573 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3099 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1570 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3094 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1561 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3091 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1558 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3086 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1551 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3085 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1546 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3083 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1539 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3085 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1533 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3084 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1524 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3080 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1522 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3082 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1513 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3080 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1511 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3074 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1502 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3071 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1496 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3070 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1490 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3070 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1485 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3068 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1483 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3069 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1474 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3066 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1469 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3065 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1463 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3065 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1461 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3062 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1454 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3062 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1450 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3060 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1442 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3055 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1437 - accuracy: 0.9937 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3054 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1431 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3052 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1428 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3053 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1423 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3052 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1419 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3048 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1413 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3049 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1405 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3048 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1402 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3046 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1395 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3042 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1395 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3039 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1384 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3039 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1382 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3036 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1377 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3034 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1371 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3034 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1366 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3032 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1362 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3031 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1359 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3029 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1352 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3027 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1351 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3026 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1346 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3025 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1340 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3026 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1334 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3026 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1334 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3021 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1325 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3020 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1324 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3017 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1319 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3017 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1315 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.3015 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1307 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3014 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1304 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3013 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1304 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3012 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1297 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3010 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1292 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3008 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1289 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3006 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1284 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3002 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1279 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2999 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 5.0000e-04\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1276 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1270 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1267 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2999 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1262 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 5.0000e-04\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1259 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2995 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1256 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1252 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2992 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 5.0000e-04\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1248 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1243 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1240 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 5.0000e-04\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1236 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1234 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1226 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1225 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1224 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2990 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1224 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 2.5000e-04\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1220 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 2.5000e-04\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1218 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 2.5000e-04\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1216 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 2.5000e-04\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1214 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 2.5000e-04\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1213 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2984 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1211 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1209 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1206 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1204 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1204 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1200 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 2.5000e-04\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1199 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1199 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 2.5000e-04\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1196 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 2.5000e-04\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1195 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 2.5000e-04\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1192 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1191 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 2.5000e-04\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1188 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1187 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1184 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1183 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1182 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1180 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1178 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 2.5000e-04\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1176 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1175 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 2.5000e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.7; accuracy of 76.92%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 31s 2s/step - loss: 0.6601 - accuracy: 0.9430 - precision: 0.9927 - recall: 0.8608 - auc: 0.9933 - val_loss: 0.8028 - val_accuracy: 0.6346 - val_precision: 0.7188 - val_recall: 0.4423 - val_auc: 0.8420 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.6111 - accuracy: 0.9494 - precision: 0.9858 - recall: 0.8797 - auc: 0.9960 - val_loss: 0.7764 - val_accuracy: 0.6731 - val_precision: 0.7188 - val_recall: 0.4423 - val_auc: 0.8547 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5767 - accuracy: 0.9304 - precision: 0.9795 - recall: 0.9051 - auc: 0.9960 - val_loss: 0.7779 - val_accuracy: 0.6538 - val_precision: 0.7500 - val_recall: 0.4615 - val_auc: 0.8542 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5495 - accuracy: 0.9241 - precision: 0.9792 - recall: 0.8924 - auc: 0.9952 - val_loss: 0.7511 - val_accuracy: 0.6731 - val_precision: 0.7297 - val_recall: 0.5192 - val_auc: 0.8670 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.5154 - accuracy: 0.9620 - precision: 0.9864 - recall: 0.9177 - auc: 0.9971 - val_loss: 0.7129 - val_accuracy: 0.6923 - val_precision: 0.8000 - val_recall: 0.5385 - val_auc: 0.8813 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4890 - accuracy: 0.9430 - precision: 0.9793 - recall: 0.8987 - auc: 0.9963 - val_loss: 0.7074 - val_accuracy: 0.7115 - val_precision: 0.7568 - val_recall: 0.5385 - val_auc: 0.8814 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4712 - accuracy: 0.9557 - precision: 0.9863 - recall: 0.9114 - auc: 0.9977 - val_loss: 0.6934 - val_accuracy: 0.7115 - val_precision: 0.7500 - val_recall: 0.5769 - val_auc: 0.8878 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4506 - accuracy: 0.9557 - precision: 0.9865 - recall: 0.9241 - auc: 0.9972 - val_loss: 0.6754 - val_accuracy: 0.7115 - val_precision: 0.7632 - val_recall: 0.5577 - val_auc: 0.8916 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4288 - accuracy: 0.9747 - precision: 0.9866 - recall: 0.9304 - auc: 0.9983 - val_loss: 0.6701 - val_accuracy: 0.7500 - val_precision: 0.7692 - val_recall: 0.5769 - val_auc: 0.8949 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4121 - accuracy: 0.9684 - precision: 0.9867 - recall: 0.9367 - auc: 0.9979 - val_loss: 0.6559 - val_accuracy: 0.7500 - val_precision: 0.7692 - val_recall: 0.5769 - val_auc: 0.8976 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4004 - accuracy: 0.9557 - precision: 0.9800 - recall: 0.9304 - auc: 0.9981 - val_loss: 0.6448 - val_accuracy: 0.7500 - val_precision: 0.7692 - val_recall: 0.5769 - val_auc: 0.9011 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3840 - accuracy: 0.9620 - precision: 0.9868 - recall: 0.9430 - auc: 0.9982 - val_loss: 0.6433 - val_accuracy: 0.7308 - val_precision: 0.7857 - val_recall: 0.6346 - val_auc: 0.8996 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3712 - accuracy: 0.9620 - precision: 0.9868 - recall: 0.9430 - auc: 0.9986 - val_loss: 0.6420 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.8995 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3588 - accuracy: 0.9620 - precision: 0.9868 - recall: 0.9430 - auc: 0.9986 - val_loss: 0.6341 - val_accuracy: 0.7308 - val_precision: 0.7857 - val_recall: 0.6346 - val_auc: 0.8993 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3479 - accuracy: 0.9747 - precision: 0.9805 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.6303 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9031 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3372 - accuracy: 0.9747 - precision: 0.9934 - recall: 0.9494 - auc: 0.9992 - val_loss: 0.6241 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9046 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3274 - accuracy: 0.9747 - precision: 0.9935 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.6159 - val_accuracy: 0.7500 - val_precision: 0.7857 - val_recall: 0.6346 - val_auc: 0.9061 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3197 - accuracy: 0.9684 - precision: 0.9934 - recall: 0.9557 - auc: 0.9992 - val_loss: 0.6136 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9071 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3106 - accuracy: 0.9747 - precision: 0.9934 - recall: 0.9494 - auc: 0.9992 - val_loss: 0.6085 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9074 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3037 - accuracy: 0.9747 - precision: 0.9935 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.6028 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9082 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2954 - accuracy: 0.9684 - precision: 0.9869 - recall: 0.9557 - auc: 0.9992 - val_loss: 0.5993 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9088 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2882 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9994 - val_loss: 0.5966 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9092 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2808 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9995 - val_loss: 0.5920 - val_accuracy: 0.7308 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9106 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2753 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9995 - val_loss: 0.5880 - val_accuracy: 0.7308 - val_precision: 0.7609 - val_recall: 0.6731 - val_auc: 0.9119 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2701 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.5860 - val_accuracy: 0.7308 - val_precision: 0.7660 - val_recall: 0.6923 - val_auc: 0.9120 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2658 - accuracy: 0.9810 - precision: 0.9934 - recall: 0.9557 - auc: 0.9994 - val_loss: 0.5851 - val_accuracy: 0.7308 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9112 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2583 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5777 - val_accuracy: 0.7308 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9137 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2524 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.5780 - val_accuracy: 0.7308 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9127 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2474 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5720 - val_accuracy: 0.7308 - val_precision: 0.7660 - val_recall: 0.6923 - val_auc: 0.9150 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2441 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.5713 - val_accuracy: 0.7308 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9156 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2388 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.5681 - val_accuracy: 0.7308 - val_precision: 0.7872 - val_recall: 0.7115 - val_auc: 0.9159 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2337 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5702 - val_accuracy: 0.7500 - val_precision: 0.7872 - val_recall: 0.7115 - val_auc: 0.9139 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2308 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5660 - val_accuracy: 0.7500 - val_precision: 0.7872 - val_recall: 0.7115 - val_auc: 0.9156 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2259 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5618 - val_accuracy: 0.7500 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9165 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2228 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5565 - val_accuracy: 0.7308 - val_precision: 0.7708 - val_recall: 0.7115 - val_auc: 0.9183 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2192 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5570 - val_accuracy: 0.7500 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9184 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2150 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5566 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9175 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2128 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5545 - val_accuracy: 0.7500 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9183 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2088 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.5540 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9169 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2059 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5527 - val_accuracy: 0.7500 - val_precision: 0.7600 - val_recall: 0.7308 - val_auc: 0.9167 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2027 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5489 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9190 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1988 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5466 - val_accuracy: 0.7500 - val_precision: 0.7600 - val_recall: 0.7308 - val_auc: 0.9197 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1960 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5449 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9208 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1926 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5427 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9215 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1905 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5451 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9202 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1884 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5429 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9199 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1855 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5425 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9199 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1847 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5433 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9191 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1809 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9203 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1785 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5352 - val_accuracy: 0.7692 - val_precision: 0.7959 - val_recall: 0.7500 - val_auc: 0.9234 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1769 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5367 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9211 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1742 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5356 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9212 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1723 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9217 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1696 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9221 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1685 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9220 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1653 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5318 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1646 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9224 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1619 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9226 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1597 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9226 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1578 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9225 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1565 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5286 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9223 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1548 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1529 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5261 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9227 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1513 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9232 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1498 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9226 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1482 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9226 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1473 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9223 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1462 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9229 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1445 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9235 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1427 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5214 - val_accuracy: 0.7692 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9230 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1415 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9235 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1404 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9224 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1391 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1376 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5181 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1367 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.7885 - val_precision: 0.8000 - val_recall: 0.7692 - val_auc: 0.9246 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.1358 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1338 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1331 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1325 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1298 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9235 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1288 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9234 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1280 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9236 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1278 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9235 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1274 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9230 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1265 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5162 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9235 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1259 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9236 - lr: 2.5000e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1257 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5157 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9236 - lr: 2.5000e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1255 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9237 - lr: 2.5000e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1252 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9235 - lr: 2.5000e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1249 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5153 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9236 - lr: 2.5000e-04\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1246 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9234 - lr: 2.5000e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1243 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9234 - lr: 2.5000e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1241 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9238 - lr: 2.5000e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1237 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 2.5000e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1235 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 2.5000e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1233 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1230 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 2.5000e-04\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1231 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5141 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1225 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1224 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1220 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5138 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1218 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1215 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1213 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1210 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 2.5000e-04\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1208 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1206 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1204 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1201 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1199 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1197 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1194 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1191 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1188 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1187 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1184 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1184 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5123 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1182 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5122 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1177 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1175 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1173 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1170 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1169 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1167 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9237 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1163 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9237 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1161 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9237 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1160 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9237 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1156 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1154 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1153 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1150 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9245 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1149 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9243 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1147 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9243 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1144 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9243 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1141 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1139 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1137 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1135 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1133 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1131 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1129 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1126 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1124 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1122 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9245 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1122 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1120 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1117 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1116 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5101 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1112 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5101 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1111 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9245 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1108 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9246 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1107 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9246 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1105 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 2.5000e-04\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1102 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 2.5000e-04\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1100 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1099 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1097 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1094 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1092 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1090 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1088 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1087 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1084 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 2.5000e-04\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1082 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1081 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1079 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1078 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1075 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1073 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 2.5000e-04\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1072 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1069 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 2.5000e-04\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1068 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9240 - lr: 2.5000e-04\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1066 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9238 - lr: 2.5000e-04\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1063 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9236 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1063 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9236 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1061 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9237 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1061 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9236 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1060 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9236 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1059 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9236 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1059 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9239 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1058 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9239 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1056 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9239 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1055 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9239 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1054 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9239 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1053 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9240 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1052 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1051 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1051 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1050 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1049 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1048 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1047 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1045 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1043 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1042 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1042 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1041 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1040 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9241 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.73; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.7 - Accuracy: 0.77%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.73 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0):\n",
      "> Accuracy: 0.72 (+- 0.05)\n",
      "> Loss: 0.71 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 8/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 30s 2s/step - loss: 0.8231 - accuracy: 0.8418 - precision: 0.9280 - recall: 0.7342 - auc: 0.9649 - val_loss: 0.4894 - val_accuracy: 0.9038 - val_precision: 0.9091 - val_recall: 0.7692 - val_auc: 0.9707 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7367 - accuracy: 0.8734 - precision: 0.9323 - recall: 0.7848 - auc: 0.9776 - val_loss: 0.4968 - val_accuracy: 0.8846 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9722 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.6331 - accuracy: 0.8797 - precision: 0.9412 - recall: 0.8101 - auc: 0.9834 - val_loss: 0.4446 - val_accuracy: 0.8846 - val_precision: 0.9149 - val_recall: 0.8269 - val_auc: 0.9732 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5734 - accuracy: 0.9241 - precision: 0.9580 - recall: 0.8671 - auc: 0.9903 - val_loss: 0.4483 - val_accuracy: 0.8654 - val_precision: 0.9362 - val_recall: 0.8462 - val_auc: 0.9740 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.5271 - accuracy: 0.9241 - precision: 0.9510 - recall: 0.8608 - auc: 0.9897 - val_loss: 0.4232 - val_accuracy: 0.8654 - val_precision: 0.9167 - val_recall: 0.8462 - val_auc: 0.9759 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.4907 - accuracy: 0.9304 - precision: 0.9586 - recall: 0.8797 - auc: 0.9925 - val_loss: 0.4157 - val_accuracy: 0.8654 - val_precision: 0.9362 - val_recall: 0.8462 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4594 - accuracy: 0.9367 - precision: 0.9586 - recall: 0.8797 - auc: 0.9925 - val_loss: 0.3961 - val_accuracy: 0.8654 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9763 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4300 - accuracy: 0.9430 - precision: 0.9595 - recall: 0.8987 - auc: 0.9942 - val_loss: 0.3903 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.4144 - accuracy: 0.9494 - precision: 0.9660 - recall: 0.8987 - auc: 0.9947 - val_loss: 0.3778 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9763 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3855 - accuracy: 0.9494 - precision: 0.9732 - recall: 0.9177 - auc: 0.9957 - val_loss: 0.3795 - val_accuracy: 0.8846 - val_precision: 0.9184 - val_recall: 0.8654 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3682 - accuracy: 0.9557 - precision: 0.9673 - recall: 0.9367 - auc: 0.9957 - val_loss: 0.3738 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3542 - accuracy: 0.9494 - precision: 0.9673 - recall: 0.9367 - auc: 0.9956 - val_loss: 0.3596 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.3437 - accuracy: 0.9304 - precision: 0.9669 - recall: 0.9241 - auc: 0.9960 - val_loss: 0.3692 - val_accuracy: 0.8846 - val_precision: 0.8980 - val_recall: 0.8462 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3245 - accuracy: 0.9557 - precision: 0.9675 - recall: 0.9430 - auc: 0.9968 - val_loss: 0.3608 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3087 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9972 - val_loss: 0.3514 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2983 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9972 - val_loss: 0.3492 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2889 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9977 - val_loss: 0.3425 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2777 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9980 - val_loss: 0.3440 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2712 - accuracy: 0.9557 - precision: 0.9740 - recall: 0.9494 - auc: 0.9981 - val_loss: 0.3436 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2620 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9982 - val_loss: 0.3384 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2526 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9987 - val_loss: 0.3379 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2467 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9986 - val_loss: 0.3340 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2425 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9986 - val_loss: 0.3368 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2325 - accuracy: 0.9557 - precision: 0.9677 - recall: 0.9494 - auc: 0.9987 - val_loss: 0.3320 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2298 - accuracy: 0.9620 - precision: 0.9679 - recall: 0.9557 - auc: 0.9987 - val_loss: 0.3325 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2222 - accuracy: 0.9684 - precision: 0.9744 - recall: 0.9620 - auc: 0.9991 - val_loss: 0.3307 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2160 - accuracy: 0.9557 - precision: 0.9805 - recall: 0.9557 - auc: 0.9990 - val_loss: 0.3300 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2112 - accuracy: 0.9620 - precision: 0.9806 - recall: 0.9620 - auc: 0.9990 - val_loss: 0.3222 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.2080 - accuracy: 0.9684 - precision: 0.9742 - recall: 0.9557 - auc: 0.9992 - val_loss: 0.3270 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9771 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2019 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3207 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1985 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3194 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1944 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3180 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1903 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3184 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1870 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3199 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9765 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1836 - accuracy: 0.9747 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3172 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1787 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.3145 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1777 - accuracy: 0.9747 - precision: 0.9744 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3160 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1739 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9994 - val_loss: 0.3133 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1701 - accuracy: 0.9684 - precision: 0.9806 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3119 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1672 - accuracy: 0.9747 - precision: 0.9870 - recall: 0.9620 - auc: 0.9994 - val_loss: 0.3109 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1636 - accuracy: 0.9810 - precision: 0.9871 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.3101 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1606 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3103 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1583 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3101 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1555 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3088 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1546 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.3091 - val_accuracy: 0.8654 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1503 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3071 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1493 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3066 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1461 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3052 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1441 - accuracy: 0.9810 - precision: 0.9873 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3050 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1425 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3034 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1409 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3031 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1386 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.3036 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1370 - accuracy: 0.9873 - precision: 0.9872 - recall: 0.9747 - auc: 0.9998 - val_loss: 0.3020 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1351 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3019 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1329 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3012 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1307 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3011 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1292 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.3011 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1280 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2998 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1260 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2993 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1242 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1236 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.2975 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1219 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1199 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1186 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1182 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2959 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1161 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1158 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2947 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1130 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1119 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1112 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1098 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1082 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9779 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1081 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1068 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1048 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1043 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1030 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1012 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.1007 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0997 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0984 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0976 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0966 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0957 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0948 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0939 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0937 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0920 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0920 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9781 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0906 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0899 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0891 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9785 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0891 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9784 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0878 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0864 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9783 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0856 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0851 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0845 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0840 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0836 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0824 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0819 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0811 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0810 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0795 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0791 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9787 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0785 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9788 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0780 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0775 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0767 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0766 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0754 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0752 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0748 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0738 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0734 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0727 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0722 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0719 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0709 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9790 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0704 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 5.0000e-04\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0703 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9792 - lr: 5.0000e-04\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0701 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 5.0000e-04\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0701 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9792 - lr: 5.0000e-04\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0697 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9792 - lr: 5.0000e-04\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0693 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 5.0000e-04\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0690 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 5.0000e-04\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0688 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 5.0000e-04\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0685 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 5.0000e-04\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0684 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 5.0000e-04\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0681 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 5.0000e-04\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0679 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9791 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0677 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9796 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0676 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9793 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0675 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0673 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0672 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0670 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0670 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0669 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0668 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0666 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0665 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0664 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0663 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0663 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0661 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0660 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0659 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0657 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0657 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0657 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0655 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0654 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0652 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0652 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0650 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0649 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0648 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0648 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0646 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0645 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0645 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0643 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0642 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0640 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 1.2500e-04\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0640 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 1.2500e-04\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0639 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 1.2500e-04\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0639 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0638 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0638 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0637 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0637 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0636 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 6.2500e-05\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0636 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 6.2500e-05\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0635 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 6.2500e-05\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0635 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 6.2500e-05\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0635 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 6.2500e-05\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0635 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 6.2500e-05\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0635 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 6.2500e-05\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 3.1250e-05\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 3.1250e-05\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9794 - lr: 3.1250e-05\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 3.1250e-05\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0634 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 3.1250e-05\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 1.5625e-05\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 1.5625e-05\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 1.5625e-05\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 1.5625e-05\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 1.5625e-05\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 7.8125e-06\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 7.8125e-06\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 7.8125e-06\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 7.8125e-06\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 7.8125e-06\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 3.9063e-06\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 3.9063e-06\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 3.9063e-06\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 3.9063e-06\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0633 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9795 - lr: 3.9063e-06\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.75; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 30s 2s/step - loss: 0.6466 - accuracy: 0.9430 - precision: 0.9928 - recall: 0.8671 - auc: 0.9952 - val_loss: 0.7856 - val_accuracy: 0.6538 - val_precision: 0.7333 - val_recall: 0.4231 - val_auc: 0.8525 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.5791 - accuracy: 0.9241 - precision: 0.9650 - recall: 0.8734 - auc: 0.9941 - val_loss: 0.7125 - val_accuracy: 0.7115 - val_precision: 0.7632 - val_recall: 0.5577 - val_auc: 0.8794 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.5143 - accuracy: 0.9494 - precision: 0.9726 - recall: 0.8987 - auc: 0.9963 - val_loss: 0.7005 - val_accuracy: 0.7115 - val_precision: 0.7632 - val_recall: 0.5577 - val_auc: 0.8823 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.4608 - accuracy: 0.9747 - precision: 0.9800 - recall: 0.9304 - auc: 0.9984 - val_loss: 0.6905 - val_accuracy: 0.7115 - val_precision: 0.7838 - val_recall: 0.5577 - val_auc: 0.8903 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.4241 - accuracy: 0.9620 - precision: 0.9800 - recall: 0.9304 - auc: 0.9976 - val_loss: 0.6626 - val_accuracy: 0.7692 - val_precision: 0.7838 - val_recall: 0.5577 - val_auc: 0.8963 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.3940 - accuracy: 0.9684 - precision: 0.9801 - recall: 0.9367 - auc: 0.9984 - val_loss: 0.6492 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.5769 - val_auc: 0.8996 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.3665 - accuracy: 0.9620 - precision: 0.9868 - recall: 0.9430 - auc: 0.9983 - val_loss: 0.6427 - val_accuracy: 0.7500 - val_precision: 0.7561 - val_recall: 0.5962 - val_auc: 0.9012 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.3464 - accuracy: 0.9620 - precision: 0.9868 - recall: 0.9430 - auc: 0.9986 - val_loss: 0.6247 - val_accuracy: 0.7308 - val_precision: 0.7674 - val_recall: 0.6346 - val_auc: 0.9045 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.3241 - accuracy: 0.9747 - precision: 0.9934 - recall: 0.9557 - auc: 0.9991 - val_loss: 0.6095 - val_accuracy: 0.7308 - val_precision: 0.7727 - val_recall: 0.6538 - val_auc: 0.9073 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.3103 - accuracy: 0.9747 - precision: 0.9935 - recall: 0.9620 - auc: 0.9993 - val_loss: 0.6016 - val_accuracy: 0.7308 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9084 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2933 - accuracy: 0.9747 - precision: 0.9935 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.5908 - val_accuracy: 0.7308 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9108 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2788 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9684 - auc: 0.9996 - val_loss: 0.5863 - val_accuracy: 0.7308 - val_precision: 0.7778 - val_recall: 0.6731 - val_auc: 0.9118 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2710 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5736 - val_accuracy: 0.7308 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9137 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2583 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9994 - val_loss: 0.5714 - val_accuracy: 0.7500 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9146 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2473 - accuracy: 0.9810 - precision: 0.9935 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.5701 - val_accuracy: 0.7308 - val_precision: 0.7826 - val_recall: 0.6923 - val_auc: 0.9151 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2420 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5616 - val_accuracy: 0.7692 - val_precision: 0.8000 - val_recall: 0.6923 - val_auc: 0.9173 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2338 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9997 - val_loss: 0.5593 - val_accuracy: 0.7692 - val_precision: 0.7872 - val_recall: 0.7115 - val_auc: 0.9183 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2217 - accuracy: 0.9873 - precision: 0.9935 - recall: 0.9747 - auc: 0.9996 - val_loss: 0.5570 - val_accuracy: 0.7500 - val_precision: 0.7755 - val_recall: 0.7308 - val_auc: 0.9181 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2134 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5556 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9176 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.2068 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5529 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9177 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2014 - accuracy: 0.9873 - precision: 1.0000 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.5481 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9197 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1960 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5439 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9201 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1898 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5426 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9194 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1857 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9810 - auc: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9206 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1825 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9873 - auc: 0.9998 - val_loss: 0.5416 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9184 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1765 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5389 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9206 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1715 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5361 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9210 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1674 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9810 - auc: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9213 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1627 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.7500 - val_precision: 0.7959 - val_recall: 0.7500 - val_auc: 0.9222 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1594 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.7885 - val_precision: 0.8000 - val_recall: 0.7692 - val_auc: 0.9239 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1555 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5270 - val_accuracy: 0.7500 - val_precision: 0.7500 - val_recall: 0.7500 - val_auc: 0.9224 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1530 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.5231 - val_accuracy: 0.7692 - val_precision: 0.7959 - val_recall: 0.7500 - val_auc: 0.9234 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1493 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9873 - auc: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.7692 - val_precision: 0.8000 - val_recall: 0.7692 - val_auc: 0.9237 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1463 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9231 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1430 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9237 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1408 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.7500 - val_precision: 0.7647 - val_recall: 0.7500 - val_auc: 0.9225 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1376 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5199 - val_accuracy: 0.7692 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9236 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1351 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1340 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9243 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1309 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5162 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1279 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9246 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1254 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9246 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1244 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9246 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1213 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9244 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1197 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.7692 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9235 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1182 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1161 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9247 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1145 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1128 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1111 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9248 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1099 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1080 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9250 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1062 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9250 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1053 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9256 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1047 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9243 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1022 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9252 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1009 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9248 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0994 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9248 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0981 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9255 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0973 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9255 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0959 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9259 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0948 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9259 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0939 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.7885 - val_precision: 0.7843 - val_recall: 0.7692 - val_auc: 0.9256 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0919 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9262 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0912 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9260 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0899 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9260 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0899 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9260 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0880 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9265 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0869 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9269 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.0858 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0858 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9260 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0849 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0846 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9268 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0841 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9267 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0835 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9267 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0831 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0827 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9265 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0824 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9270 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0820 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9268 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0814 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9271 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0811 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9269 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0806 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9271 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0801 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9265 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0798 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9268 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0795 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9263 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0790 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9264 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0786 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9263 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0783 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9270 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0778 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9271 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0773 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9268 - lr: 2.5000e-04\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0771 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9270 - lr: 2.5000e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0769 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9271 - lr: 2.5000e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0767 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9271 - lr: 2.5000e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0765 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9270 - lr: 2.5000e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0764 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9270 - lr: 1.2500e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0762 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9270 - lr: 1.2500e-04\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0762 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9270 - lr: 1.2500e-04\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0761 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9270 - lr: 1.2500e-04\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0760 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9271 - lr: 1.2500e-04\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0759 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9274 - lr: 6.2500e-05\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0758 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9274 - lr: 6.2500e-05\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0758 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9272 - lr: 6.2500e-05\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0758 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9270 - lr: 6.2500e-05\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0757 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9274 - lr: 6.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.74; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.75 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.74 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.5):\n",
      "> Accuracy: 0.69 (+- 0.04)\n",
      "> Loss: 0.74 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 9/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 34s 2s/step - loss: 0.8268 - accuracy: 0.8734 - precision: 0.9160 - recall: 0.7595 - auc: 0.9631 - val_loss: 0.5239 - val_accuracy: 0.8269 - val_precision: 0.9302 - val_recall: 0.7692 - val_auc: 0.9533 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.6074 - accuracy: 0.8861 - precision: 0.9241 - recall: 0.8481 - auc: 0.9805 - val_loss: 0.3983 - val_accuracy: 0.8654 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9755 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.4162 - accuracy: 0.9114 - precision: 0.9342 - recall: 0.8987 - auc: 0.9904 - val_loss: 0.3760 - val_accuracy: 0.8462 - val_precision: 0.8800 - val_recall: 0.8462 - val_auc: 0.9734 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.3108 - accuracy: 0.9367 - precision: 0.9542 - recall: 0.9241 - auc: 0.9937 - val_loss: 0.3400 - val_accuracy: 0.8846 - val_precision: 0.9200 - val_recall: 0.8846 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2468 - accuracy: 0.9684 - precision: 0.9679 - recall: 0.9557 - auc: 0.9976 - val_loss: 0.3204 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9755 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.2081 - accuracy: 0.9494 - precision: 0.9615 - recall: 0.9494 - auc: 0.9981 - val_loss: 0.3443 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9729 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1831 - accuracy: 0.9557 - precision: 0.9679 - recall: 0.9557 - auc: 0.9984 - val_loss: 0.3080 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9762 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1639 - accuracy: 0.9684 - precision: 0.9682 - recall: 0.9620 - auc: 0.9992 - val_loss: 0.3164 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9754 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1475 - accuracy: 0.9747 - precision: 0.9808 - recall: 0.9684 - auc: 0.9993 - val_loss: 0.3064 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1354 - accuracy: 0.9810 - precision: 0.9808 - recall: 0.9684 - auc: 0.9994 - val_loss: 0.3017 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9769 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1280 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.2994 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9772 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.1183 - accuracy: 0.9810 - precision: 0.9872 - recall: 0.9747 - auc: 0.9997 - val_loss: 0.3034 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9761 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1130 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9810 - auc: 0.9998 - val_loss: 0.2963 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9767 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1154 - accuracy: 0.9873 - precision: 0.9936 - recall: 0.9873 - auc: 0.9999 - val_loss: 0.2923 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1004 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8846 - val_precision: 0.8846 - val_recall: 0.8846 - val_auc: 0.9759 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0946 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2898 - val_accuracy: 0.8654 - val_precision: 0.8800 - val_recall: 0.8462 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0918 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0863 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9764 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0838 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.2901 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9763 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0815 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9773 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0760 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0752 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.8846 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0706 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.8654 - val_precision: 0.8800 - val_recall: 0.8462 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0681 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9786 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0659 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9774 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0638 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0618 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9789 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0596 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.8846 - val_precision: 0.8824 - val_recall: 0.8654 - val_auc: 0.9777 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0591 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.8654 - val_precision: 0.8627 - val_recall: 0.8462 - val_auc: 0.9778 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0564 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9793 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0546 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9038 - val_precision: 0.9000 - val_recall: 0.8654 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0529 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.8654 - val_precision: 0.8654 - val_recall: 0.8654 - val_auc: 0.9780 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0522 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0427 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0417 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0408 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0400 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0390 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0382 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0375 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0371 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0359 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9794 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0359 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0351 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0319 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0297 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0291 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9796 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0282 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0279 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0273 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0269 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0266 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0262 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9792 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0258 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0255 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0252 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9802 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0248 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9802 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0246 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9802 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0242 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0241 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0237 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0234 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9810 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0231 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0229 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0225 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9799 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0223 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9809 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0221 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9804 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0217 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0215 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0212 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9804 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0210 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0208 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0206 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9800 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0204 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9804 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0202 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9038 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0200 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0198 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0198 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9801 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0197 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9804 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0195 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0194 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0193 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9804 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0192 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0191 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0191 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9803 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0190 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0188 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0188 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0187 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 2.5000e-04\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0186 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 2.5000e-04\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0185 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 2.5000e-04\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0185 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 2.5000e-04\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0184 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 2.5000e-04\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0184 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 1.2500e-04\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0184 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2500e-04\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0183 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2500e-04\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0183 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 1.2500e-04\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0183 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9805 - lr: 1.2500e-04\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0183 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9806 - lr: 1.2500e-04\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2500e-04\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.2500e-05\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.2500e-05\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.2500e-05\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.2500e-05\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.2500e-05\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.1250e-05\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.1250e-05\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0182 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.1250e-05\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.1250e-05\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.1250e-05\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.5625e-05\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.5625e-05\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.5625e-05\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.5625e-05\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.5625e-05\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 7.8125e-06\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.9063e-06\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.9063e-06\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.9063e-06\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.9063e-06\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 3.9063e-06\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.9531e-06\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.9531e-06\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.9531e-06\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.9531e-06\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.9531e-06\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 9.7656e-07\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 9.7656e-07\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 9.7656e-07\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 9.7656e-07\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 4.8828e-07\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 4.8828e-07\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 4.8828e-07\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 4.8828e-07\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 4.8828e-07\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 2.4414e-07\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 2.4414e-07\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 2.4414e-07\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 2.4414e-07\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 2.4414e-07\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2207e-07\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2207e-07\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2207e-07\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2207e-07\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 1.2207e-07\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.1035e-08\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.1035e-08\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.1035e-08\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.1035e-08\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0181 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8846 - val_precision: 0.9020 - val_recall: 0.8846 - val_auc: 0.9807 - lr: 6.1035e-08\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.9; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/2 ...\n",
      "------------------------------------------------------------------------\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 31s 2s/step - loss: 0.6807 - accuracy: 0.9241 - precision: 0.9653 - recall: 0.8797 - auc: 0.9930 - val_loss: 0.8880 - val_accuracy: 0.5769 - val_precision: 0.6667 - val_recall: 0.3462 - val_auc: 0.7706 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1934 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5135 - val_accuracy: 0.7500 - val_precision: 0.7800 - val_recall: 0.7500 - val_auc: 0.9262 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1689 - accuracy: 0.9810 - precision: 0.9809 - recall: 0.9747 - auc: 0.9995 - val_loss: 0.5175 - val_accuracy: 0.7885 - val_precision: 0.8367 - val_recall: 0.7885 - val_auc: 0.9253 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1465 - accuracy: 0.9937 - precision: 0.9936 - recall: 0.9810 - auc: 0.9999 - val_loss: 0.5199 - val_accuracy: 0.7500 - val_precision: 0.7451 - val_recall: 0.7308 - val_auc: 0.9219 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1108 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.7885 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.1058 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.7692 - val_precision: 0.7692 - val_recall: 0.7692 - val_auc: 0.9252 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0973 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9277 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0916 - accuracy: 0.9937 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.4887 - val_accuracy: 0.7885 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9291 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0854 - accuracy: 1.0000 - precision: 1.0000 - recall: 0.9937 - auc: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9275 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0812 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9287 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0767 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9287 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0728 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9307 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0693 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9295 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0661 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.7885 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0645 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8077 - val_precision: 0.8077 - val_recall: 0.8077 - val_auc: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0626 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0612 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9297 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0601 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9294 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0589 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9292 - lr: 2.5000e-04\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0586 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.7885 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9288 - lr: 2.5000e-04\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0576 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.7885 - val_precision: 0.8039 - val_recall: 0.7885 - val_auc: 0.9292 - lr: 2.5000e-04\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0570 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9295 - lr: 2.5000e-04\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0564 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9292 - lr: 2.5000e-04\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0559 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9297 - lr: 1.2500e-04\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0555 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9291 - lr: 1.2500e-04\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 13s 2s/step - loss: 0.0552 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9297 - lr: 1.2500e-04\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0550 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9293 - lr: 1.2500e-04\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 14s 2s/step - loss: 0.0547 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.7885 - val_precision: 0.7885 - val_recall: 0.7885 - val_auc: 0.9298 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.73; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.9 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.73 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.9):\n",
      "> Accuracy: 0.72 (+- 0.01)\n",
      "> Loss: 0.81 (+- 0.08)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Average Training Time: 1937.63 seconds\n",
      "Average Inference Time: 3.25 seconds\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "learn_rate = [0.01, 0.001, 0.0001]\n",
    "momentum = [0, 0.5, 0.9]\n",
    "\n",
    "tot_comb = len(learn_rate) * len(momentum)\n",
    "glob_param = np.empty([tot_comb, 2])\n",
    "\n",
    "history_list = []\n",
    "scores_glob_array = np.empty([tot_comb, n_folds, 5])\n",
    "training_times = []  # Initialize list to store training times\n",
    "inference_times = []  # Initialize list to store inference times\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "auc_list = []\n",
    "\n",
    "for idx, x in enumerate(itertools.product(learn_rate, momentum)):\n",
    "    learn_rate = x[0]\n",
    "    momentum = x[1]\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for combination {idx + 1}/{tot_comb} ...')\n",
    "    print(f'Learning rate = {learn_rate}')\n",
    "    print(f'Momentum = {momentum}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    history_array = np.array([])\n",
    "    scores_array = np.empty([n_folds, 5])\n",
    "\n",
    "    glob_param[idx, 0] = learn_rate\n",
    "    glob_param[idx, 1] = momentum\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold + 1}/{n_folds} ...')\n",
    "        print('------------------------------------------------------------------------')\n",
    "\n",
    "        # Generate the fold sample for train-test\n",
    "        X_train_cc, X_train_mlo, Y_train, X_test_cc, X_test_mlo, Y_test = part_traintest(X_traintest_cc, X_traintest_mlo, Y_traintest, rand_seed + fold, frac_test)\n",
    "\n",
    "        # Define the model architecture\n",
    "        model_2ramas = DenseNet_2Ramas(model_cc, model_mlo, rand_seed, learning_rate, momentum)\n",
    "        \n",
    "        # Measure training time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Fit data to model -> entrenamos con los distintos parametros \n",
    "        history = model_2ramas.fit([X_train_cc, X_train_mlo], Y_train,\n",
    "                                   batch_size = batch_size,\n",
    "                                   epochs = no_epochs,\n",
    "                                   validation_data = ([X_test_cc, X_test_mlo], Y_test),\n",
    "                                   class_weight = class_weight,\n",
    "                                   verbose = 1,\n",
    "                                   callbacks = [early_stopping, reduce_lr])\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        training_times.append(training_time)\n",
    "        \n",
    "        # Generate generalization metrics\n",
    "        start_time = time.time()\n",
    "        scores = model_2ramas.evaluate([X_val_cc, X_val_mlo], Y_val, verbose=0)\n",
    "        inference_time = time.time() - start_time\n",
    "        inference_times.append(inference_time)\n",
    "        \n",
    "        # Append scores\n",
    "        scores_array[fold, :] = scores\n",
    "        accuracy_list.append(scores[1])  # Accuracy is the second metric\n",
    "        precision_list.append(scores[2])  # Precision is the third metric\n",
    "        recall_list.append(scores[3])  # Recall is the fourth metric\n",
    "        auc_list.append(scores[4])  # AUC is the fifth metric\n",
    "        \n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Score for fold {fold + 1}: {model_2ramas.metrics_names[0]} of {round(scores_array[fold, 0], 2)}; {model_2ramas.metrics_names[1]} of {round(scores_array[fold, 1]*100, 2)}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('')\n",
    "\n",
    "        # Append history callback into array\n",
    "        history_array = np.append(history_array, [history])\n",
    "\n",
    "        \n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, scores_array.shape[0]):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i + 1} - Loss: {round(scores_array[i, 0], 2)} - Accuracy: {round(scores_array[i, 1], 2)}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Average scores for all folds (LR = {learn_rate}, mtm = {momentum}):')\n",
    "    print(f'> Accuracy: {round(np.mean(scores_array[:, 1]), 2)} (+- {round(np.std(scores_array[:, 1]), 2)})')\n",
    "    print(f'> Loss: {round(np.mean(scores_array[:, 0]), 2)} (+- {round(np.std(scores_array[:, 0]), 2)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "    idx_best_hist = np.argmax(scores_array[:, 1])\n",
    "    history_list.append(history_array[idx_best_hist])\n",
    "    \n",
    "    scores_glob_array[idx, :, :] = scores_array\n",
    "\n",
    "# Print the average training and inference times\n",
    "print(f'Average Training Time: {np.mean(training_times):.2f} seconds')\n",
    "print(f'Average Inference Time: {np.mean(inference_times):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d7cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados promedios del entrenamiento DenseNet169:\n",
      "- LR=0.01 / mom=0.0:\tAcc=0.71 (+- 0.06) - Loss=0.72 (+- 0.01)\n",
      "- LR=0.01 / mom=0.5:\tAcc=0.69 (+- 0.04) - Loss=0.75 (+- 0.02)\n",
      "- LR=0.01 / mom=0.9:\tAcc=0.72 (+- 0.01) - Loss=0.83 (+- 0.08)\n",
      "- LR=0.001 / mom=0.0:\tAcc=0.71 (+- 0.06) - Loss=0.72 (+- 0.01)\n",
      "- LR=0.001 / mom=0.5:\tAcc=0.69 (+- 0.04) - Loss=0.75 (+- 0.02)\n",
      "- LR=0.001 / mom=0.9:\tAcc=0.72 (+- 0.01) - Loss=0.82 (+- 0.08)\n",
      "- LR=0.0001 / mom=0.0:\tAcc=0.72 (+- 0.05) - Loss=0.71 (+- 0.01)\n",
      "- LR=0.0001 / mom=0.5:\tAcc=0.69 (+- 0.04) - Loss=0.74 (+- 0.0)\n",
      "- LR=0.0001 / mom=0.9:\tAcc=0.72 (+- 0.01) - Loss=0.81 (+- 0.08)\n",
      "\n",
      "El mejor resultado para la DenseNet169 se obtiene para LR = 0.0001 y momentum = 0.0.\n"
     ]
    }
   ],
   "source": [
    "print(f'Resultados promedios del entrenamiento DenseNet169:')\n",
    "for i in range(len(glob_param)):\n",
    "    print(f'- LR={glob_param[i, 0]} / mom={glob_param[i, 1]}:\\tAcc={round(np.mean(scores_glob_array[i, :, 1]), 2)} (+- {round(np.std(scores_glob_array[i, :, 1]), 2)}) - Loss={round(np.mean(scores_glob_array[i, :, 0]), 2)} (+- {round(np.std(scores_glob_array[i, :, 0]), 2)})')\n",
    "\n",
    "idx_best = np.argmax(np.mean(scores_glob_array, 1)[:, 1])\n",
    "history_best = history_list[idx_best]\n",
    "model_best = history_best.model\n",
    "print(f'\\nEl mejor resultado para la DenseNet169 se obtiene para LR = {glob_param[idx_best, 0]} y momentum = {glob_param[idx_best, 1]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50aea2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_best = np.argmax(scores_array[:, 1])\n",
    "model_best = history_array[idx_best].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab2c58f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./DN201_model_CC-MLO/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./DN201_model_CC-MLO/assets\n"
     ]
    }
   ],
   "source": [
    "if google_colab:\n",
    "    file_path = '/content/gdrive/MyDrive/Colab Notebooks/model_CC-MLO'\n",
    "else:\n",
    "    file_path = './DN201_model_CC-MLO'\n",
    "K.models.save_model(model_best, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d8c2e",
   "metadata": {
    "id": "super-progressive"
   },
   "source": [
    "## Representación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac5fde6",
   "metadata": {
    "id": "streaming-recruitment"
   },
   "source": [
    "Definimos una serie de funciones auxiliares para facilitar la visualización de resultados (representación de la evolución de las métricas durante el proceso de entrenamiento y resultados de la matriz de confusión finalmente obtenida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef51a87",
   "metadata": {
    "executionInfo": {
     "elapsed": 1434193,
     "status": "ok",
     "timestamp": 1621190143830,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "published-lingerie"
   },
   "outputs": [],
   "source": [
    "def get_metrics(history_array, no_epochs):\n",
    "    \"\"\"\n",
    "    Function that extracts the metrics from the k-fold history from the training process\n",
    "        - history_array is the array of histories generated during the training process\n",
    "        - no_epochs is number of epochs fixed for the training process\n",
    "    Returns:\n",
    "        - accuracy is the output array of accuracies\n",
    "        - val_accuracy is the output array of validation accuracies\n",
    "        - loss is the output array of losses\n",
    "        - val_loss is the output array of validation losses\n",
    "    \"\"\"\n",
    "    accuracy = np.empty([no_epochs, len(history_array)])\n",
    "    accuracy[:, :] = np.nan\n",
    "    val_accuracy = np.empty([no_epochs, len(history_array)])\n",
    "    val_accuracy[:, :] = np.nan\n",
    "    loss = np.empty([no_epochs, len(history_array)])\n",
    "    loss[:, :] = np.nan\n",
    "    val_loss = np.empty([no_epochs, len(history_array)])\n",
    "    val_loss[:, :] = np.nan\n",
    "\n",
    "    for idx, fold in enumerate(history_array):\n",
    "        max_epochs = max(fold.epoch)\n",
    "        accuracy[:max_epochs + 1, idx] = fold.history['accuracy']\n",
    "        val_accuracy[:max_epochs + 1, idx] = fold.history['val_accuracy']\n",
    "        loss[:max_epochs + 1, idx] = fold.history['loss']\n",
    "        val_loss[:max_epochs + 1, idx] = fold.history['val_loss']\n",
    "\n",
    "    return accuracy, val_accuracy, loss, val_loss\n",
    "\n",
    "def plot_metrics(history_array, no_epochs):\n",
    "    \"\"\"\n",
    "    Function that plots the metrics from the training process\n",
    "        - history_array is the array of histories generated during the training process\n",
    "        - no_epochs is number of epochs fixed for the training process\n",
    "    Returns:\n",
    "        - accuracy is the output array of accuracies\n",
    "        - val_accuracy is the output array of validation accuracies\n",
    "        - loss is the output array of losses\n",
    "        - val_loss is the output array of validation losses\n",
    "    \"\"\"\n",
    "    accuracy, val_accuracy, loss, val_loss = get_metrics(history_array, no_epochs)\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(np.mean(accuracy, axis = 1))\n",
    "    plt.plot(np.mean(val_accuracy, axis = 1))\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(np.mean(loss, axis = 1))\n",
    "    plt.plot(np.mean(val_loss, axis = 1))\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"\n",
    "    Credit to:\n",
    "    https://gist.github.com/zachguo/10296432\n",
    "    \n",
    "    Function that makes a pretty print for confusion matrixes\n",
    "        - cm is the array of histories generated during the training process\n",
    "        - labels is number of epochs fixed for the training process\n",
    "        - hide_zeroes is a boolean that allows the user to hide the zeroes in the matrix\n",
    "        - hide_diagonal is a boolean that allows the user to hide the diagonal in the matrix\n",
    "        - hide_threshold is a number that allows the user to hide results in the matrix below that value\n",
    "    \"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06bf7a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 2276,
     "status": "ok",
     "timestamp": 1620075964551,
     "user": {
      "displayName": "Duun V",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GipsnLzW9bWFJbKNrxY-F-xi7XKh0HhowJGi0hF9A=s64",
      "userId": "10921869077997462696"
     },
     "user_tz": -120
    },
    "id": "marked-decimal"
   },
   "source": [
    "Visualizamos la evolución de las métricas durante el proceso de entrenamiento de las redes, haciendo la media por época de las distintas iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c40adab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 1434738,
     "status": "ok",
     "timestamp": 1621190144383,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "racial-tribute",
    "outputId": "a5234e36-de66-4044-d2d5-2e0943b85ff3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history_array, no_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "582705be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step\n",
      "                    benigno seguimiento     maligno \n",
      "        benigno        24.0         0.0         4.0 \n",
      "    seguimiento         3.0         1.0         0.0 \n",
      "        maligno         7.0         0.0        13.0 \n"
     ]
    }
   ],
   "source": [
    "conf_matrix = metrics.confusion_matrix(Y_val.argmax(axis = 1), model_best.predict([X_val_cc, X_val_mlo]).argmax(axis = 1))\n",
    "print_cm(conf_matrix, list(dict_valores.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebccda3",
   "metadata": {
    "id": "viral-constitutional"
   },
   "source": [
    "Mostramos las métricas de resultados según categoría para poder evaluar el desempeño de la red en cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7b98f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     benigno       0.71      0.86      0.77        28\n",
      " seguimiento       1.00      0.25      0.40         4\n",
      "     maligno       0.76      0.65      0.70        20\n",
      "\n",
      "    accuracy                           0.73        52\n",
      "   macro avg       0.82      0.59      0.63        52\n",
      "weighted avg       0.75      0.73      0.72        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classif_report = metrics.classification_report(Y_val.argmax(axis = 1), model_best.predict([X_val_cc, X_val_mlo]).argmax(axis = 1),\n",
    "                                               target_names = list(dict_valores.keys()))\n",
    "print(classif_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4ef8a",
   "metadata": {},
   "source": [
    "# Guardamos las metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bcabf2f",
   "metadata": {
    "executionInfo": {
     "elapsed": 1434737,
     "status": "ok",
     "timestamp": 1621190144384,
     "user": {
      "displayName": "Iago Veiras Lens",
      "photoUrl": "",
      "userId": "00127513713424041949"
     },
     "user_tz": -120
    },
    "id": "YV9gGPf5TIDj"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# Function to convert numpy types to native Python types\n",
    "def convert_to_native_types(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_native_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native_types(v) for v in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(convert_to_native_types(v) for v in obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Assuming history_list contains History objects\n",
    "# Extract the history dictionaries\n",
    "history_dicts = [convert_to_native_types(hist.history) for hist in history_list]\n",
    "\n",
    "# Save the history dictionaries using pickle\n",
    "with open('history_DN201.pkl', 'wb') as file:\n",
    "    pickle.dump(history_dicts, file)\n",
    "\n",
    "# Save the history dictionaries using JSON\n",
    "with open('history_DN201.json', 'w') as file:\n",
    "    json.dump(history_dicts, file)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Entrenamiento_DenseNet_2Ramas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
