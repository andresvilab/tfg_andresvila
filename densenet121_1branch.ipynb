{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dpJp_QlaKt_X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 07:00:36.015448: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-21 07:00:36.018022: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 07:00:36.055882: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 07:00:36.057069: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 07:00:36.809869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "opIGkDVFLTxH"
   },
   "outputs": [],
   "source": [
    "vista = 'CC' ## 'CC' o 'MLO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yDmco7yQLWMQ"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, Y):\n",
    "    \"\"\"\n",
    "    Pre-processes the data for the model\n",
    "        - X is a numpy.ndarray of shape (m, 1024, 1024, 3) containing\n",
    "         the mammography, where m is the number of data points\n",
    "        - Y is a numpy.ndarray of shape (m,) containing\n",
    "         the Bi-Rads labels for X\n",
    "    Returns:\n",
    "        - X_p is a numpy.ndarray containing the preprocessed X\n",
    "        - Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    X_p = K.applications.densenet.preprocess_input(X)\n",
    "\n",
    "    Y_p = K.utils.to_categorical(Y, 3)\n",
    "\n",
    "    return X_p, Y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FacbWZE3LaZl"
   },
   "outputs": [],
   "source": [
    "df_INbreast_train = pd.read_pickle('/workspace/container_0/andres/data/df_INbreast_train.pkl')\n",
    "df_INbreast_val = pd.read_pickle('/workspace/container_0/andres/data/df_INbreast_val.pkl')\n",
    "\n",
    "if vista == 'CC':\n",
    "    df_INbreast_train = df_INbreast_train.drop(columns = ['MLO Image']).rename(columns = {'CC Image': 'Image'})\n",
    "    df_INbreast_val = df_INbreast_val.drop(columns = ['MLO Image']).rename(columns = {'CC Image': 'Image'})\n",
    "elif vista == 'MLO':\n",
    "    df_INbreast_train = df_INbreast_train.drop(columns = ['CC Image']).rename(columns = {'MLO Image': 'Image'})\n",
    "    df_INbreast_val = df_INbreast_val.drop(columns = ['CC Image']).rename(columns = {'MLO Image': 'Image'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fhw02QVrNDBP"
   },
   "outputs": [],
   "source": [
    "dict_valores = {'benigno': 0, 'seguimiento': 1, 'maligno': 2}\n",
    "Y_traintest = np.array(df_INbreast_train['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_traintest = np.array(df_INbreast_train['Image'].tolist())\n",
    "Y_val = np.array(df_INbreast_val['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_val = np.array(df_INbreast_val['Image'].tolist())\n",
    "X_val, Y_val = preprocess_data(X_val, Y_val)\n",
    "del df_INbreast_train\n",
    "del df_INbreast_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5ZMfWXVRNHEq"
   },
   "outputs": [],
   "source": [
    "def DenseNet_1Rama(vista, input_dim = 512, rand_seed = 13, learning_rate = 0.0001, momentum = 0.9):\n",
    "    \"\"\"\n",
    "    Define the DenseNet architecture and compile the model\n",
    "        - vista is a mammogram view we want to train\n",
    "        - input_dim is the size of the mammogram in pixels\n",
    "        - rand_seed is a random seed number used during the fc layer initialization\n",
    "        - learning_rate is the learning rate used during the training\n",
    "        - momentum is the parameters that defines the momentun for the SGD optimizer\n",
    "    Returns:\n",
    "        - model_1rama is the output compiled DenseNet model\n",
    "    \"\"\"\n",
    "    # Definimos la architectura del modelo\n",
    "    densenet = K.applications.DenseNet121(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_tensor = None,\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = 'avg'\n",
    "    )\n",
    "\n",
    "    densenet.trainable = True\n",
    "\n",
    "    # Entrenaremos solo el bloque de capas conv5, las demas las dejamos con los pesos preestablecidos de la DenseNet121\n",
    "    for layer in densenet.layers:\n",
    "        if 'conv5' in layer.name:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Deefinimos el tama침o de las im치genes de entrada.\n",
    "    input_img = K.Input(shape = (input_dim, input_dim, 3))\n",
    "    # Lambda que ajustar치 la imagenes a un tama침o de  256x256\n",
    "    preprocess = K.layers.Lambda(lambda x: tf.image.resize(x, (256, 256)), name = 'resize_' + vista)(input_img)\n",
    "\n",
    "    initializer = K.initializers.he_normal(seed = rand_seed)\n",
    "\n",
    "    fc_layer = densenet(inputs = preprocess)\n",
    "\n",
    "    fc_layer = K.layers.Dense(units = 3,\n",
    "                              activation = 'softmax',\n",
    "                              kernel_initializer = initializer\n",
    "                              )(fc_layer)\n",
    "\n",
    "    model_1rama = K.models.Model(inputs = input_img, outputs = fc_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    opt = K.optimizers.SGD(learning_rate = learning_rate, momentum = momentum)\n",
    "\n",
    "    model_1rama.compile(loss = 'categorical_crossentropy',\n",
    "                        optimizer = opt,\n",
    "                        metrics = ['accuracy'])\n",
    "\n",
    "    return model_1rama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxbDJlkxNKPJ",
    "outputId": "ef2b1451-d388-4ec0-ba88-e0486fd6d0c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 07:00:43.331584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 07:00:43.332718: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
      "                                                                 \n",
      " resize_CC (Lambda)          (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " densenet121 (Functional)    (None, 1024)              7037504   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7040579 (26.86 MB)\n",
      "Trainable params: 2161155 (8.24 MB)\n",
      "Non-trainable params: 4879424 (18.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DenseNet_1Rama(vista).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hDp_ZPrONO_8"
   },
   "outputs": [],
   "source": [
    "def part_traintest(X_traintest, Y_traintest, rand_seed = 13, frac_test = .2/.8):\n",
    "    \"\"\"\n",
    "    Function that makes a partition for training and testing from the original dataset\n",
    "        - X_traintest is the array of images from the original dataset\n",
    "        - Y_traintest is the array of labels from the original dataset\n",
    "        - rand_seed is a random seed number used during the sampling\n",
    "        - frac_test is the fraction of cases used in the test subset\n",
    "    Returns:\n",
    "        - X_train is the train array of images\n",
    "        - Y_train is the train array of labels\n",
    "        - X_test is the test array of images\n",
    "        - Y_test is the test array of labels\n",
    "    \"\"\"\n",
    "    np.random.seed(rand_seed)\n",
    "    index_test = np.array([], dtype = 'int')\n",
    "\n",
    "    for i in np.unique(Y_traintest):\n",
    "        index_test = np.append(index_test,\n",
    "                               np.random.choice(list(np.where(Y_traintest == i)[0]), size = int(np.where(Y_traintest == i)[0].shape[0]*frac_test), replace = False))\n",
    "\n",
    "    index_test = [int(x) for x in index_test]\n",
    "    print(index_test)\n",
    "    X_train = np.delete(X_traintest, index_test, axis = 0)\n",
    "\n",
    "    Y_train = np.delete(Y_traintest, index_test)\n",
    "    X_test = np.take(X_traintest, index_test, axis = 0)\n",
    "    Y_test = np.take(Y_traintest, index_test)\n",
    "#     print(X_train)\n",
    "#     print(Y_train)\n",
    "#     print(Y_traintest)\n",
    "    X_train, Y_train = preprocess_data(X_train, Y_train)\n",
    "    X_test, Y_test = preprocess_data(X_test, Y_test)\n",
    "\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-Z-b6SEdNRsZ"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "no_epochs = 300\n",
    "input_dim = X_traintest.shape[1]\n",
    "rand_seed = 2021\n",
    "n_folds = 3\n",
    "frac_test = .2/.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kFogoCuWNT5R"
   },
   "outputs": [],
   "source": [
    "label, counts = np.unique(Y_traintest, return_counts = True)\n",
    "class_weight = {}\n",
    "for lab, con in zip(label, counts):\n",
    "  class_weight.update({lab: round(max(counts)/con, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MhD1kj9jNWRU"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(factor = 0.5, patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlN-yfIuNL1m",
    "outputId": "4f123c6d-c5fd-4f0d-89d4-bedc079e9c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for combination 1/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 873ms/step - loss: 2.9792 - accuracy: 0.3924 - val_loss: 0.9663 - val_accuracy: 0.5192 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 7s 690ms/step - loss: 1.8367 - accuracy: 0.4747 - val_loss: 3.2230 - val_accuracy: 0.0769 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4156 - accuracy: 0.5949 - val_loss: 1.0630 - val_accuracy: 0.4615 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 995ms/step - loss: 0.7429 - accuracy: 0.7975 - val_loss: 0.7687 - val_accuracy: 0.6923 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6627 - accuracy: 0.7595 - val_loss: 1.0985 - val_accuracy: 0.4808 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3725 - accuracy: 0.9114 - val_loss: 1.3414 - val_accuracy: 0.4615 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1581 - accuracy: 0.9810 - val_loss: 1.0260 - val_accuracy: 0.5192 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 982ms/step - loss: 0.0892 - accuracy: 1.0000 - val_loss: 1.3219 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 1.0229 - val_accuracy: 0.5577 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 1.1432 - val_accuracy: 0.5385 - lr: 0.0050\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 9s 954ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.9999 - val_accuracy: 0.5769 - lr: 0.0050\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 1.2711 - val_accuracy: 0.5577 - lr: 0.0050\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.6923 - lr: 0.0050\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 999ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.0505 - val_accuracy: 0.6154 - lr: 0.0050\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.9891 - val_accuracy: 0.6346 - lr: 0.0025\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.9394 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.9407 - val_accuracy: 0.6538 - lr: 0.0025\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.9837 - val_accuracy: 0.6154 - lr: 0.0025\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.6346 - lr: 0.0025\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 984ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.9190 - val_accuracy: 0.6731 - lr: 0.0012\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.9112 - val_accuracy: 0.6731 - lr: 0.0012\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.8918 - val_accuracy: 0.7115 - lr: 0.0012\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.0191 - val_accuracy: 0.6346 - lr: 0.0012\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.6538 - lr: 0.0012\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.81; accuracy of 57.69%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 22s 2s/step - loss: 3.5924 - accuracy: 0.3165 - val_loss: 1.0556 - val_accuracy: 0.5385 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 15s 2s/step - loss: 1.8492 - accuracy: 0.4810 - val_loss: 0.9150 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.1374 - accuracy: 0.6582 - val_loss: 2.1238 - val_accuracy: 0.0769 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.3922 - accuracy: 0.6646 - val_loss: 0.8907 - val_accuracy: 0.5385 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.6028 - accuracy: 0.8291 - val_loss: 2.1323 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4869 - accuracy: 0.8797 - val_loss: 0.8976 - val_accuracy: 0.5192 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.1563 - accuracy: 0.9810 - val_loss: 1.0184 - val_accuracy: 0.5962 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 987ms/step - loss: 0.1795 - accuracy: 0.9494 - val_loss: 0.8091 - val_accuracy: 0.6346 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 1.2883 - val_accuracy: 0.5769 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 1.0826 - val_accuracy: 0.6154 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 1.5971 - val_accuracy: 0.5577 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0742 - accuracy: 0.9810 - val_loss: 1.7070 - val_accuracy: 0.5577 - lr: 0.0100\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2863 - accuracy: 0.9241 - val_loss: 1.8988 - val_accuracy: 0.4231 - lr: 0.0100\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 0.1198 - accuracy: 0.9684 - val_loss: 0.8552 - val_accuracy: 0.6923 - lr: 0.0050\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.8349 - val_accuracy: 0.7115 - lr: 0.0050\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.8343 - val_accuracy: 0.7308 - lr: 0.0050\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.8503 - val_accuracy: 0.7308 - lr: 0.0050\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 989ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.8757 - val_accuracy: 0.7500 - lr: 0.0050\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.8904 - val_accuracy: 0.7500 - lr: 0.0025\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.7500 - lr: 0.0025\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.9108 - val_accuracy: 0.7500 - lr: 0.0025\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.7500 - lr: 0.0025\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 974ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.9348 - val_accuracy: 0.7500 - lr: 0.0025\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.7500 - lr: 0.0012\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.7500 - lr: 0.0012\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.7500 - lr: 0.0012\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 981ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.9706 - val_accuracy: 0.7500 - lr: 0.0012\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.9839 - val_accuracy: 0.7500 - lr: 0.0012\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.82; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 16s 1s/step - loss: 3.5153 - accuracy: 0.3291 - val_loss: 1.8771 - val_accuracy: 0.0769 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 8s 779ms/step - loss: 1.5646 - accuracy: 0.4620 - val_loss: 1.4984 - val_accuracy: 0.5385 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 9s 907ms/step - loss: 1.4499 - accuracy: 0.5633 - val_loss: 0.9342 - val_accuracy: 0.5385 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 9s 950ms/step - loss: 0.6891 - accuracy: 0.8544 - val_loss: 1.0822 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4232 - accuracy: 0.9367 - val_loss: 0.9125 - val_accuracy: 0.5577 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2626 - accuracy: 0.9620 - val_loss: 0.8864 - val_accuracy: 0.5962 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2585 - accuracy: 0.9241 - val_loss: 1.0340 - val_accuracy: 0.6538 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2151 - accuracy: 0.9430 - val_loss: 0.9240 - val_accuracy: 0.6538 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0992 - accuracy: 0.9937 - val_loss: 0.9448 - val_accuracy: 0.6154 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 997ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.6346 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.0400 - val_accuracy: 0.6154 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.9856 - val_accuracy: 0.6346 - lr: 0.0050\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.6731 - lr: 0.0050\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.6538 - lr: 0.0050\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.0022 - val_accuracy: 0.6538 - lr: 0.0050\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 991ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 1.1129 - val_accuracy: 0.6538 - lr: 0.0050\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.0498 - val_accuracy: 0.6538 - lr: 0.0025\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.6538 - lr: 0.0025\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.0183 - val_accuracy: 0.6538 - lr: 0.0025\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.0137 - val_accuracy: 0.6538 - lr: 0.0025\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.0190 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 964ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.0104 - val_accuracy: 0.6731 - lr: 0.0012\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 9s 972ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.0038 - val_accuracy: 0.6731 - lr: 0.0012\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 974ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.0017 - val_accuracy: 0.6923 - lr: 0.0012\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 996ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.6923 - lr: 0.0012\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 9s 896ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.6923 - lr: 0.0012\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.88; accuracy of 69.23%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.81 - Accuracy: 0.58%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.82 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.88 - Accuracy: 0.69%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0):\n",
      "> Accuracy: 0.66 (+- 0.06)\n",
      "> Loss: 0.84 (+- 0.03)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 2/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 16s 1s/step - loss: 4.6060 - accuracy: 0.3165 - val_loss: 1.6269 - val_accuracy: 0.2885 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.9007 - accuracy: 0.3165 - val_loss: 1.0895 - val_accuracy: 0.4038 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.2987 - accuracy: 0.6456 - val_loss: 1.2466 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8271 - accuracy: 0.7468 - val_loss: 0.7324 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5953 - accuracy: 0.8481 - val_loss: 3.7101 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 973ms/step - loss: 0.3797 - accuracy: 0.8861 - val_loss: 4.3846 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 995ms/step - loss: 0.2098 - accuracy: 0.9430 - val_loss: 0.8155 - val_accuracy: 0.6731 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2179 - accuracy: 0.9620 - val_loss: 3.5155 - val_accuracy: 0.4615 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0704 - accuracy: 0.9810 - val_loss: 1.6152 - val_accuracy: 0.6154 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 9s 905ms/step - loss: 0.5955 - accuracy: 0.8354 - val_loss: 1.8493 - val_accuracy: 0.4615 - lr: 0.0050\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 9s 876ms/step - loss: 0.1477 - accuracy: 0.9810 - val_loss: 1.1576 - val_accuracy: 0.5962 - lr: 0.0050\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0816 - accuracy: 0.9873 - val_loss: 1.7019 - val_accuracy: 0.4808 - lr: 0.0050\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.8665 - val_accuracy: 0.6538 - lr: 0.0050\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.6538 - lr: 0.0050\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 0.7712 - val_accuracy: 0.7115 - lr: 0.0025\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0304 - accuracy: 0.9937 - val_loss: 0.7991 - val_accuracy: 0.6923 - lr: 0.0025\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.7663 - val_accuracy: 0.6923 - lr: 0.0025\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 999ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.6923 - lr: 0.0012\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.7478 - val_accuracy: 0.7115 - lr: 0.0012\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 9s 966ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.9; accuracy of 53.85%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 16s 1s/step - loss: 4.6762 - accuracy: 0.2911 - val_loss: 1.1582 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7392 - accuracy: 0.3544 - val_loss: 0.9167 - val_accuracy: 0.5385 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 995ms/step - loss: 1.3630 - accuracy: 0.6646 - val_loss: 1.4953 - val_accuracy: 0.0769 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1714 - accuracy: 0.6772 - val_loss: 0.8808 - val_accuracy: 0.6154 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7599 - accuracy: 0.8228 - val_loss: 1.1893 - val_accuracy: 0.4231 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3330 - accuracy: 0.9430 - val_loss: 0.9538 - val_accuracy: 0.6346 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2052 - accuracy: 0.9684 - val_loss: 0.9787 - val_accuracy: 0.6346 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2883 - accuracy: 0.9051 - val_loss: 6.3138 - val_accuracy: 0.4038 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2334 - accuracy: 0.9177 - val_loss: 8.4954 - val_accuracy: 0.4038 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1966 - accuracy: 0.9684 - val_loss: 4.4724 - val_accuracy: 0.4423 - lr: 0.0050\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 2.8768 - val_accuracy: 0.5000 - lr: 0.0050\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 1.3404 - val_accuracy: 0.5769 - lr: 0.0050\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0329 - accuracy: 0.9873 - val_loss: 3.6498 - val_accuracy: 0.4808 - lr: 0.0050\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.8821 - val_accuracy: 0.5769 - lr: 0.0050\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0163 - accuracy: 0.9937 - val_loss: 1.1788 - val_accuracy: 0.6154 - lr: 0.0025\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1316 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.1210 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.1682 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 1.7292 - val_accuracy: 0.5962 - lr: 0.0025\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.5593 - val_accuracy: 0.6154 - lr: 0.0012\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4549 - val_accuracy: 0.5962 - lr: 0.0012\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 973ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.3584 - val_accuracy: 0.6346 - lr: 0.0012\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.1927 - val_accuracy: 0.6731 - lr: 0.0012\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.1703 - val_accuracy: 0.6923 - lr: 0.0012\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.86; accuracy of 69.23%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 4.2007 - accuracy: 0.2595 - val_loss: 0.9039 - val_accuracy: 0.6538 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7458 - accuracy: 0.4241 - val_loss: 0.8888 - val_accuracy: 0.5385 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.3515 - accuracy: 0.6519 - val_loss: 0.9350 - val_accuracy: 0.5385 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0804 - accuracy: 0.7152 - val_loss: 0.8580 - val_accuracy: 0.4615 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 996ms/step - loss: 0.5861 - accuracy: 0.8101 - val_loss: 0.9674 - val_accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 997ms/step - loss: 0.3680 - accuracy: 0.8861 - val_loss: 0.7271 - val_accuracy: 0.7115 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1974 - accuracy: 0.9747 - val_loss: 0.7162 - val_accuracy: 0.7115 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 9s 967ms/step - loss: 0.1146 - accuracy: 0.9684 - val_loss: 1.0921 - val_accuracy: 0.6346 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 985ms/step - loss: 0.1083 - accuracy: 0.9684 - val_loss: 0.8286 - val_accuracy: 0.7885 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.9356 - val_accuracy: 0.7115 - lr: 0.0100\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 987ms/step - loss: 0.0343 - accuracy: 0.9937 - val_loss: 1.3474 - val_accuracy: 0.6346 - lr: 0.0100\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2464 - accuracy: 0.9494 - val_loss: 1.1230 - val_accuracy: 0.6923 - lr: 0.0100\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1322 - accuracy: 0.9747 - val_loss: 1.0982 - val_accuracy: 0.6923 - lr: 0.0050\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 998ms/step - loss: 0.0327 - accuracy: 0.9937 - val_loss: 0.8671 - val_accuracy: 0.7692 - lr: 0.0050\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.9352 - val_accuracy: 0.7308 - lr: 0.0050\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.7500 - lr: 0.0050\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.7308 - lr: 0.0050\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.9967 - val_accuracy: 0.7308 - lr: 0.0025\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 7s 761ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9985 - val_accuracy: 0.7308 - lr: 0.0025\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 9s 955ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.7500 - lr: 0.0025\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 9s 964ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.7500 - lr: 0.0025\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.7308 - lr: 0.0025\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0418 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.7115 - lr: 0.0012\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0219 - val_accuracy: 0.7115 - lr: 0.0012\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0265 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.8; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.9 - Accuracy: 0.54%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.86 - Accuracy: 0.69%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.8 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0.5):\n",
      "> Accuracy: 0.62 (+- 0.06)\n",
      "> Loss: 0.86 (+- 0.04)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 3/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 3.6952 - accuracy: 0.2911 - val_loss: 1.7721 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 2.0243 - accuracy: 0.4051 - val_loss: 6.8705 - val_accuracy: 0.0769 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.3522 - accuracy: 0.6266 - val_loss: 8.2273 - val_accuracy: 0.0769 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.2226 - accuracy: 0.7152 - val_loss: 0.9410 - val_accuracy: 0.5385 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 997ms/step - loss: 0.8015 - accuracy: 0.7911 - val_loss: 3.0718 - val_accuracy: 0.2692 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7457 - accuracy: 0.7975 - val_loss: 23.8923 - val_accuracy: 0.0962 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7042 - accuracy: 0.7975 - val_loss: 9.3321 - val_accuracy: 0.1731 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 982ms/step - loss: 1.0393 - accuracy: 0.8228 - val_loss: 16.2305 - val_accuracy: 0.1731 - lr: 0.0100\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8603 - accuracy: 0.7911 - val_loss: 14.9956 - val_accuracy: 0.5192 - lr: 0.0100\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7258 - accuracy: 0.8101 - val_loss: 2.5040 - val_accuracy: 0.6538 - lr: 0.0050\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5125 - accuracy: 0.8354 - val_loss: 11.1381 - val_accuracy: 0.4423 - lr: 0.0050\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 994ms/step - loss: 0.4191 - accuracy: 0.8481 - val_loss: 2.0345 - val_accuracy: 0.6923 - lr: 0.0050\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7541 - accuracy: 0.9177 - val_loss: 5.6148 - val_accuracy: 0.4231 - lr: 0.0050\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 983ms/step - loss: 0.1051 - accuracy: 0.9873 - val_loss: 2.5526 - val_accuracy: 0.5962 - lr: 0.0050\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0787 - accuracy: 0.9810 - val_loss: 3.3180 - val_accuracy: 0.5385 - lr: 0.0025\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.5938 - val_accuracy: 0.6538 - lr: 0.0025\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 9s 955ms/step - loss: 0.0616 - accuracy: 0.9937 - val_loss: 2.5768 - val_accuracy: 0.5577 - lr: 0.0025\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 7s 692ms/step - loss: 0.0377 - accuracy: 0.9937 - val_loss: 1.7469 - val_accuracy: 0.7308 - lr: 0.0025\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 9s 903ms/step - loss: 0.0281 - accuracy: 0.9937 - val_loss: 2.0477 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 9s 882ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.4610 - val_accuracy: 0.6538 - lr: 0.0012\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0156 - accuracy: 0.9937 - val_loss: 1.3886 - val_accuracy: 0.6731 - lr: 0.0012\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.3083 - val_accuracy: 0.7115 - lr: 0.0012\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.7115 - lr: 0.0012\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.2790 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.87; accuracy of 59.62%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 3.2393 - accuracy: 0.4177 - val_loss: 1.2588 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5899 - accuracy: 0.5443 - val_loss: 2.5111 - val_accuracy: 0.0769 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0841 - accuracy: 0.7152 - val_loss: 2.3046 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 980ms/step - loss: 1.0162 - accuracy: 0.6709 - val_loss: 2.5792 - val_accuracy: 0.4423 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 997ms/step - loss: 0.5525 - accuracy: 0.8291 - val_loss: 4.9787 - val_accuracy: 0.1346 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6179 - accuracy: 0.8481 - val_loss: 10.2632 - val_accuracy: 0.1154 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 997ms/step - loss: 0.3604 - accuracy: 0.9304 - val_loss: 9.2549 - val_accuracy: 0.4231 - lr: 0.0050\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1324 - accuracy: 0.9684 - val_loss: 7.6522 - val_accuracy: 0.4231 - lr: 0.0050\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0498 - accuracy: 0.9937 - val_loss: 7.9158 - val_accuracy: 0.4808 - lr: 0.0050\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0800 - accuracy: 0.9747 - val_loss: 4.9888 - val_accuracy: 0.5000 - lr: 0.0050\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0799 - accuracy: 0.9684 - val_loss: 8.7200 - val_accuracy: 0.4615 - lr: 0.0050\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 993ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 7.3220 - val_accuracy: 0.4615 - lr: 0.0025\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1055 - accuracy: 0.9684 - val_loss: 8.1187 - val_accuracy: 0.4423 - lr: 0.0025\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 9s 963ms/step - loss: 0.0268 - accuracy: 0.9937 - val_loss: 6.4592 - val_accuracy: 0.4615 - lr: 0.0025\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0606 - accuracy: 0.9747 - val_loss: 6.0718 - val_accuracy: 0.4808 - lr: 0.0025\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 9s 966ms/step - loss: 0.4464 - accuracy: 0.9177 - val_loss: 10.2541 - val_accuracy: 0.2115 - lr: 0.0025\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 9s 958ms/step - loss: 0.4061 - accuracy: 0.9051 - val_loss: 2.6042 - val_accuracy: 0.5385 - lr: 0.0012\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 992ms/step - loss: 0.1583 - accuracy: 0.9557 - val_loss: 6.2707 - val_accuracy: 0.4231 - lr: 0.0012\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 7s 698ms/step - loss: 0.1131 - accuracy: 0.9620 - val_loss: 1.9897 - val_accuracy: 0.5577 - lr: 0.0012\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 9s 905ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.6270 - val_accuracy: 0.6154 - lr: 0.0012\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 9s 919ms/step - loss: 0.0482 - accuracy: 0.9937 - val_loss: 1.9349 - val_accuracy: 0.6346 - lr: 0.0012\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 1.25; accuracy of 38.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 16s 1s/step - loss: 3.0670 - accuracy: 0.2975 - val_loss: 1.2284 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8432 - accuracy: 0.4304 - val_loss: 0.9116 - val_accuracy: 0.5385 - lr: 0.0100\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9290 - accuracy: 0.7152 - val_loss: 2.3563 - val_accuracy: 0.2500 - lr: 0.0100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7981 - accuracy: 0.7595 - val_loss: 2.8368 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4672 - accuracy: 0.8608 - val_loss: 7.2174 - val_accuracy: 0.3846 - lr: 0.0100\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3955 - accuracy: 0.9051 - val_loss: 3.2593 - val_accuracy: 0.4615 - lr: 0.0100\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2991 - accuracy: 0.8924 - val_loss: 26.4019 - val_accuracy: 0.1346 - lr: 0.0100\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4935 - accuracy: 0.9114 - val_loss: 23.9104 - val_accuracy: 0.3846 - lr: 0.0050\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7301 - accuracy: 0.7025 - val_loss: 5.6443 - val_accuracy: 0.5962 - lr: 0.0050\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4352 - accuracy: 0.8797 - val_loss: 5.7036 - val_accuracy: 0.6154 - lr: 0.0050\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4223 - accuracy: 0.8861 - val_loss: 17.9199 - val_accuracy: 0.5577 - lr: 0.0050\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1547 - accuracy: 0.9620 - val_loss: 9.9372 - val_accuracy: 0.6346 - lr: 0.0050\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0273 - accuracy: 0.9937 - val_loss: 3.6550 - val_accuracy: 0.5962 - lr: 0.0025\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 3.0107 - val_accuracy: 0.6538 - lr: 0.0025\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0571 - accuracy: 0.9810 - val_loss: 2.8809 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0231 - accuracy: 0.9937 - val_loss: 2.7956 - val_accuracy: 0.6731 - lr: 0.0025\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0405 - accuracy: 0.9873 - val_loss: 2.5961 - val_accuracy: 0.7115 - lr: 0.0025\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.4129 - val_accuracy: 0.6923 - lr: 0.0012\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0291 - accuracy: 0.9937 - val_loss: 2.2130 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.1334 - val_accuracy: 0.7115 - lr: 0.0012\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 983ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.9453 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 9s 886ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7659 - val_accuracy: 0.7308 - lr: 0.0012\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.95; accuracy of 53.85%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.87 - Accuracy: 0.6%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.25 - Accuracy: 0.38%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.95 - Accuracy: 0.54%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0.9):\n",
      "> Accuracy: 0.51 (+- 0.09)\n",
      "> Loss: 1.02 (+- 0.16)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 4/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 16s 1s/step - loss: 1.9282 - accuracy: 0.2785 - val_loss: 0.9916 - val_accuracy: 0.4231 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7094 - accuracy: 0.4177 - val_loss: 1.0087 - val_accuracy: 0.3462 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5645 - accuracy: 0.4937 - val_loss: 0.9512 - val_accuracy: 0.4615 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.3706 - accuracy: 0.6013 - val_loss: 1.0339 - val_accuracy: 0.4038 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.3042 - accuracy: 0.6392 - val_loss: 0.9777 - val_accuracy: 0.4615 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1537 - accuracy: 0.7152 - val_loss: 0.9062 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0929 - accuracy: 0.7278 - val_loss: 0.9120 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0021 - accuracy: 0.8291 - val_loss: 0.9212 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8812 - accuracy: 0.8165 - val_loss: 0.8516 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8980 - accuracy: 0.8481 - val_loss: 0.9423 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8039 - accuracy: 0.8608 - val_loss: 0.8905 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7187 - accuracy: 0.8861 - val_loss: 0.8770 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1000ms/step - loss: 0.6662 - accuracy: 0.8861 - val_loss: 0.8640 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6437 - accuracy: 0.9051 - val_loss: 0.7757 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5917 - accuracy: 0.9241 - val_loss: 0.7850 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 986ms/step - loss: 0.5646 - accuracy: 0.8987 - val_loss: 0.7529 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5293 - accuracy: 0.9304 - val_loss: 0.8159 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5438 - accuracy: 0.9177 - val_loss: 0.7925 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4254 - accuracy: 0.9557 - val_loss: 0.7358 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.4195 - accuracy: 0.9430 - val_loss: 0.8325 - val_accuracy: 0.5769 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4024 - accuracy: 0.9557 - val_loss: 0.8161 - val_accuracy: 0.5962 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3633 - accuracy: 0.9620 - val_loss: 0.7277 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3606 - accuracy: 0.9684 - val_loss: 0.7696 - val_accuracy: 0.7308 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3548 - accuracy: 0.9747 - val_loss: 0.7334 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2878 - accuracy: 0.9747 - val_loss: 0.7425 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2888 - accuracy: 0.9747 - val_loss: 0.7198 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2635 - accuracy: 0.9810 - val_loss: 0.7207 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 995ms/step - loss: 0.2415 - accuracy: 0.9810 - val_loss: 0.7159 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2348 - accuracy: 0.9873 - val_loss: 0.7035 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2185 - accuracy: 0.9873 - val_loss: 0.7925 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 10s 984ms/step - loss: 0.2071 - accuracy: 0.9937 - val_loss: 0.7047 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 10s 999ms/step - loss: 0.1937 - accuracy: 0.9937 - val_loss: 0.7097 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1980 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1898 - accuracy: 0.9937 - val_loss: 0.6990 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 9s 992ms/step - loss: 0.1731 - accuracy: 0.9873 - val_loss: 0.7214 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1595 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1433 - accuracy: 0.9937 - val_loss: 0.7248 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1468 - accuracy: 0.9873 - val_loss: 0.7609 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1438 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1239 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1296 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1241 - accuracy: 0.9937 - val_loss: 0.7198 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 10s 992ms/step - loss: 0.1283 - accuracy: 0.9937 - val_loss: 0.7189 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 10s 988ms/step - loss: 0.1141 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1082 - accuracy: 1.0000 - val_loss: 0.7301 - val_accuracy: 0.6538 - lr: 5.0000e-04\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.0994 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.6538 - lr: 1.2500e-04\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 9s 970ms/step - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.6538 - lr: 1.2500e-04\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1274 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.6731 - lr: 1.2500e-04\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 10s 999ms/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 0.7293 - val_accuracy: 0.6731 - lr: 1.2500e-04\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.6731 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 14s 942ms/step - loss: 1.9227 - accuracy: 0.2468 - val_loss: 1.0282 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 9s 939ms/step - loss: 1.7046 - accuracy: 0.3861 - val_loss: 1.0637 - val_accuracy: 0.4231 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 9s 920ms/step - loss: 1.5535 - accuracy: 0.4747 - val_loss: 0.9874 - val_accuracy: 0.4615 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4877 - accuracy: 0.5633 - val_loss: 1.0397 - val_accuracy: 0.4231 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 993ms/step - loss: 1.2409 - accuracy: 0.5506 - val_loss: 0.9495 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1727 - accuracy: 0.7278 - val_loss: 0.9137 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1008 - accuracy: 0.7785 - val_loss: 0.9516 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 975ms/step - loss: 0.9431 - accuracy: 0.8418 - val_loss: 0.9971 - val_accuracy: 0.4423 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9399 - accuracy: 0.8354 - val_loss: 0.9964 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8027 - accuracy: 0.8481 - val_loss: 0.8689 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7580 - accuracy: 0.8671 - val_loss: 0.9477 - val_accuracy: 0.4615 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7052 - accuracy: 0.8861 - val_loss: 0.9206 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6425 - accuracy: 0.8861 - val_loss: 0.8770 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6032 - accuracy: 0.8987 - val_loss: 0.8658 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5448 - accuracy: 0.9241 - val_loss: 0.9419 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5205 - accuracy: 0.9177 - val_loss: 0.8925 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5085 - accuracy: 0.9114 - val_loss: 0.8892 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4363 - accuracy: 0.9494 - val_loss: 0.8647 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3933 - accuracy: 0.9494 - val_loss: 0.8992 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 9s 964ms/step - loss: 0.4201 - accuracy: 0.9494 - val_loss: 0.8705 - val_accuracy: 0.5769 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3584 - accuracy: 0.9620 - val_loss: 0.8531 - val_accuracy: 0.5769 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3884 - accuracy: 0.9620 - val_loss: 0.8369 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2999 - accuracy: 0.9810 - val_loss: 0.8563 - val_accuracy: 0.5962 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2944 - accuracy: 0.9873 - val_loss: 0.8650 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 7s 683ms/step - loss: 0.2784 - accuracy: 0.9747 - val_loss: 0.8460 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 8s 886ms/step - loss: 0.2631 - accuracy: 0.9684 - val_loss: 0.8720 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 9s 924ms/step - loss: 0.3071 - accuracy: 0.9494 - val_loss: 0.8609 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2315 - accuracy: 0.9937 - val_loss: 0.8563 - val_accuracy: 0.5577 - lr: 5.0000e-04\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2296 - accuracy: 0.9937 - val_loss: 0.8555 - val_accuracy: 0.5385 - lr: 5.0000e-04\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2236 - accuracy: 0.9873 - val_loss: 0.8548 - val_accuracy: 0.5385 - lr: 5.0000e-04\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2256 - accuracy: 0.9810 - val_loss: 0.8585 - val_accuracy: 0.5192 - lr: 5.0000e-04\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 10s 975ms/step - loss: 0.2031 - accuracy: 0.9937 - val_loss: 0.8651 - val_accuracy: 0.5577 - lr: 5.0000e-04\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 10s 997ms/step - loss: 0.2042 - accuracy: 0.9937 - val_loss: 0.8647 - val_accuracy: 0.5385 - lr: 2.5000e-04\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 10s 994ms/step - loss: 0.2244 - accuracy: 0.9810 - val_loss: 0.8658 - val_accuracy: 0.5385 - lr: 2.5000e-04\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2122 - accuracy: 0.9810 - val_loss: 0.8704 - val_accuracy: 0.5962 - lr: 2.5000e-04\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 10s 996ms/step - loss: 0.2258 - accuracy: 0.9873 - val_loss: 0.8683 - val_accuracy: 0.5385 - lr: 2.5000e-04\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1960 - accuracy: 0.9937 - val_loss: 0.8693 - val_accuracy: 0.5577 - lr: 2.5000e-04\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1919 - accuracy: 0.9937 - val_loss: 0.8689 - val_accuracy: 0.5385 - lr: 1.2500e-04\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1978 - accuracy: 0.9937 - val_loss: 0.8686 - val_accuracy: 0.5385 - lr: 1.2500e-04\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1957 - accuracy: 1.0000 - val_loss: 0.8689 - val_accuracy: 0.5385 - lr: 1.2500e-04\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2067 - accuracy: 1.0000 - val_loss: 0.8693 - val_accuracy: 0.5385 - lr: 1.2500e-04\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1918 - accuracy: 0.9937 - val_loss: 0.8695 - val_accuracy: 0.5577 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.77; accuracy of 69.23%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 1.9098 - accuracy: 0.3165 - val_loss: 1.0422 - val_accuracy: 0.4231 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7212 - accuracy: 0.4051 - val_loss: 0.9834 - val_accuracy: 0.4423 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5616 - accuracy: 0.5000 - val_loss: 0.9607 - val_accuracy: 0.4423 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.3933 - accuracy: 0.5949 - val_loss: 0.9429 - val_accuracy: 0.4423 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.2935 - accuracy: 0.7089 - val_loss: 0.9567 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1296 - accuracy: 0.7152 - val_loss: 0.9626 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0984 - accuracy: 0.7848 - val_loss: 0.9302 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.9963 - accuracy: 0.7595 - val_loss: 0.8954 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8997 - accuracy: 0.8291 - val_loss: 0.8890 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8148 - accuracy: 0.8671 - val_loss: 0.8918 - val_accuracy: 0.5769 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.7405 - accuracy: 0.9241 - val_loss: 0.8721 - val_accuracy: 0.5769 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.7188 - accuracy: 0.9051 - val_loss: 0.8864 - val_accuracy: 0.5962 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 985ms/step - loss: 0.6194 - accuracy: 0.9241 - val_loss: 0.8539 - val_accuracy: 0.5962 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5694 - accuracy: 0.9241 - val_loss: 0.8567 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5303 - accuracy: 0.9430 - val_loss: 0.8412 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5189 - accuracy: 0.9241 - val_loss: 0.8371 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4534 - accuracy: 0.9367 - val_loss: 0.8547 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4774 - accuracy: 0.9241 - val_loss: 0.8592 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4066 - accuracy: 0.9494 - val_loss: 0.8317 - val_accuracy: 0.5962 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3702 - accuracy: 0.9684 - val_loss: 0.8326 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3606 - accuracy: 0.9747 - val_loss: 0.8324 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3271 - accuracy: 0.9747 - val_loss: 0.8253 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2994 - accuracy: 0.9873 - val_loss: 0.8193 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2803 - accuracy: 0.9937 - val_loss: 0.8147 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2981 - accuracy: 0.9747 - val_loss: 0.8136 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2649 - accuracy: 0.9810 - val_loss: 0.8265 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2729 - accuracy: 0.9810 - val_loss: 0.8237 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2281 - accuracy: 0.9937 - val_loss: 0.8160 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2317 - accuracy: 0.9810 - val_loss: 0.8241 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1965 - accuracy: 0.9937 - val_loss: 0.8371 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2012 - accuracy: 0.9873 - val_loss: 0.8244 - val_accuracy: 0.6346 - lr: 5.0000e-04\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 7s 711ms/step - loss: 0.1921 - accuracy: 0.9937 - val_loss: 0.8221 - val_accuracy: 0.6346 - lr: 5.0000e-04\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 9s 955ms/step - loss: 0.1933 - accuracy: 1.0000 - val_loss: 0.8199 - val_accuracy: 0.6346 - lr: 5.0000e-04\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 10s 996ms/step - loss: 0.1974 - accuracy: 0.9937 - val_loss: 0.8211 - val_accuracy: 0.6538 - lr: 5.0000e-04\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1972 - accuracy: 0.9873 - val_loss: 0.8189 - val_accuracy: 0.6346 - lr: 5.0000e-04\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1595 - accuracy: 1.0000 - val_loss: 0.8202 - val_accuracy: 0.6346 - lr: 2.5000e-04\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2072 - accuracy: 0.9873 - val_loss: 0.8190 - val_accuracy: 0.6346 - lr: 2.5000e-04\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1600 - accuracy: 1.0000 - val_loss: 0.8201 - val_accuracy: 0.6346 - lr: 2.5000e-04\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.8207 - val_accuracy: 0.6346 - lr: 2.5000e-04\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 10s 985ms/step - loss: 0.1569 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.6346 - lr: 2.5000e-04\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1526 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1495 - accuracy: 0.9937 - val_loss: 0.8238 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1576 - accuracy: 1.0000 - val_loss: 0.8241 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1538 - accuracy: 1.0000 - val_loss: 0.8243 - val_accuracy: 0.6154 - lr: 1.2500e-04\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1619 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.8; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.77 - Accuracy: 0.69%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.8 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0):\n",
      "> Accuracy: 0.65 (+- 0.03)\n",
      "> Loss: 0.78 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 5/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 18s 1s/step - loss: 1.9224 - accuracy: 0.3797 - val_loss: 1.0364 - val_accuracy: 0.4231 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5902 - accuracy: 0.4494 - val_loss: 0.9526 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.2731 - accuracy: 0.6709 - val_loss: 0.9564 - val_accuracy: 0.4423 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1384 - accuracy: 0.7215 - val_loss: 0.9322 - val_accuracy: 0.3654 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9495 - accuracy: 0.8418 - val_loss: 0.8994 - val_accuracy: 0.5769 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8296 - accuracy: 0.7848 - val_loss: 0.8291 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7079 - accuracy: 0.8987 - val_loss: 0.8758 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6189 - accuracy: 0.8861 - val_loss: 0.8027 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5643 - accuracy: 0.9114 - val_loss: 0.7640 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4556 - accuracy: 0.9367 - val_loss: 0.7658 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4131 - accuracy: 0.9494 - val_loss: 0.7712 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3713 - accuracy: 0.9494 - val_loss: 0.7781 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3294 - accuracy: 0.9684 - val_loss: 0.7093 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 986ms/step - loss: 0.2848 - accuracy: 0.9557 - val_loss: 0.7273 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2633 - accuracy: 0.9810 - val_loss: 0.7105 - val_accuracy: 0.7308 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2282 - accuracy: 0.9810 - val_loss: 0.7372 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2175 - accuracy: 0.9873 - val_loss: 0.7072 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1000ms/step - loss: 0.1952 - accuracy: 0.9937 - val_loss: 0.6931 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1834 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 991ms/step - loss: 0.1622 - accuracy: 0.9873 - val_loss: 0.7355 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1237 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1151 - accuracy: 0.9937 - val_loss: 0.6999 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1087 - accuracy: 0.9937 - val_loss: 0.7212 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1082 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.6923 - lr: 5.0000e-04\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.7362 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 990ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.7569 - val_accuracy: 0.6538 - lr: 5.0000e-04\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.7611 - val_accuracy: 0.6538 - lr: 5.0000e-04\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.7532 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 10s 984ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.7392 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.7362 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 10s 996ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.6538 - lr: 1.2500e-04\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.6538 - lr: 1.2500e-04\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.7473 - val_accuracy: 0.6538 - lr: 1.2500e-04\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.7460 - val_accuracy: 0.6731 - lr: 1.2500e-04\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 1.8722 - accuracy: 0.4620 - val_loss: 1.1921 - val_accuracy: 0.3846 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6066 - accuracy: 0.3608 - val_loss: 0.9714 - val_accuracy: 0.4615 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.3807 - accuracy: 0.6013 - val_loss: 0.9430 - val_accuracy: 0.4231 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.1402 - accuracy: 0.6962 - val_loss: 0.8995 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9851 - accuracy: 0.7722 - val_loss: 0.9126 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8368 - accuracy: 0.8354 - val_loss: 0.9449 - val_accuracy: 0.4615 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.7461 - accuracy: 0.8861 - val_loss: 0.9360 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.6041 - accuracy: 0.9114 - val_loss: 0.8689 - val_accuracy: 0.4231 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4646 - accuracy: 0.9430 - val_loss: 0.8739 - val_accuracy: 0.4423 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4343 - accuracy: 0.9304 - val_loss: 0.8440 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4067 - accuracy: 0.9367 - val_loss: 0.8761 - val_accuracy: 0.4615 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3423 - accuracy: 0.9557 - val_loss: 0.8625 - val_accuracy: 0.5769 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3469 - accuracy: 0.9367 - val_loss: 0.8299 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 997ms/step - loss: 0.2779 - accuracy: 0.9684 - val_loss: 0.8486 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2461 - accuracy: 0.9747 - val_loss: 0.8877 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2596 - accuracy: 0.9747 - val_loss: 0.9013 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2150 - accuracy: 0.9873 - val_loss: 0.8961 - val_accuracy: 0.5769 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 7s 667ms/step - loss: 0.2042 - accuracy: 0.9937 - val_loss: 0.8344 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 9s 968ms/step - loss: 0.1659 - accuracy: 1.0000 - val_loss: 0.8419 - val_accuracy: 0.6154 - lr: 5.0000e-04\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 983ms/step - loss: 0.1443 - accuracy: 1.0000 - val_loss: 0.8597 - val_accuracy: 0.6154 - lr: 5.0000e-04\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 994ms/step - loss: 0.1539 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 0.6154 - lr: 5.0000e-04\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1497 - accuracy: 0.9937 - val_loss: 0.8620 - val_accuracy: 0.6154 - lr: 5.0000e-04\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.8705 - val_accuracy: 0.5962 - lr: 5.0000e-04\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 993ms/step - loss: 0.1391 - accuracy: 1.0000 - val_loss: 0.8594 - val_accuracy: 0.6154 - lr: 2.5000e-04\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 994ms/step - loss: 0.1293 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.6154 - lr: 2.5000e-04\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1347 - accuracy: 1.0000 - val_loss: 0.8633 - val_accuracy: 0.5962 - lr: 2.5000e-04\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1189 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.5962 - lr: 2.5000e-04\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1266 - accuracy: 1.0000 - val_loss: 0.8659 - val_accuracy: 0.6154 - lr: 2.5000e-04\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1198 - accuracy: 1.0000 - val_loss: 0.8684 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.8681 - val_accuracy: 0.6154 - lr: 1.2500e-04\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1127 - accuracy: 1.0000 - val_loss: 0.8713 - val_accuracy: 0.6154 - lr: 1.2500e-04\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 0.8728 - val_accuracy: 0.6154 - lr: 1.2500e-04\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1385 - accuracy: 1.0000 - val_loss: 0.8741 - val_accuracy: 0.6154 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.76; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 1.8653 - accuracy: 0.3481 - val_loss: 1.1456 - val_accuracy: 0.3846 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6224 - accuracy: 0.4620 - val_loss: 0.9579 - val_accuracy: 0.4615 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 9s 935ms/step - loss: 1.2322 - accuracy: 0.6772 - val_loss: 0.9170 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 9s 889ms/step - loss: 1.0316 - accuracy: 0.7595 - val_loss: 1.0088 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9290 - accuracy: 0.7595 - val_loss: 0.8760 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7445 - accuracy: 0.8861 - val_loss: 0.8849 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6657 - accuracy: 0.8924 - val_loss: 0.8785 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5407 - accuracy: 0.8987 - val_loss: 0.8531 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4807 - accuracy: 0.9494 - val_loss: 0.8334 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4374 - accuracy: 0.9494 - val_loss: 0.8277 - val_accuracy: 0.5962 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3987 - accuracy: 0.9494 - val_loss: 0.8220 - val_accuracy: 0.5962 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3281 - accuracy: 0.9620 - val_loss: 0.8255 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 975ms/step - loss: 0.2742 - accuracy: 0.9937 - val_loss: 0.8416 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2768 - accuracy: 0.9937 - val_loss: 0.8338 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2683 - accuracy: 0.9620 - val_loss: 0.8289 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2215 - accuracy: 0.9810 - val_loss: 0.8170 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2041 - accuracy: 0.9873 - val_loss: 0.8241 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1709 - accuracy: 0.9937 - val_loss: 0.8665 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 0.8466 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 983ms/step - loss: 0.1313 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1348 - accuracy: 0.9937 - val_loss: 0.8528 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1243 - accuracy: 1.0000 - val_loss: 0.8542 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1218 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.6346 - lr: 5.0000e-04\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1168 - accuracy: 0.9937 - val_loss: 0.8662 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 9s 983ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.8696 - val_accuracy: 0.6538 - lr: 5.0000e-04\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.8744 - val_accuracy: 0.6538 - lr: 5.0000e-04\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 994ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.8763 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 9s 895ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.8785 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 8s 852ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 9s 935ms/step - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.6346 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.8; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.76 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.8 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.5):\n",
      "> Accuracy: 0.67 (+- 0.03)\n",
      "> Loss: 0.78 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 6/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 2.1251 - accuracy: 0.2532 - val_loss: 1.0496 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4810 - accuracy: 0.5696 - val_loss: 1.0243 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1000ms/step - loss: 0.9872 - accuracy: 0.6203 - val_loss: 0.8689 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6031 - accuracy: 0.8861 - val_loss: 1.0641 - val_accuracy: 0.4231 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3602 - accuracy: 0.9177 - val_loss: 0.7915 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1960 - accuracy: 0.9873 - val_loss: 0.6691 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1190 - accuracy: 0.9937 - val_loss: 0.6689 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.6774 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 989ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.7885 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.7115 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.6736 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 990ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.8488 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 993ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.6346 - lr: 5.0000e-04\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8426 - val_accuracy: 0.6538 - lr: 5.0000e-04\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8254 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.8288 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.8544 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8751 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8707 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8513 - val_accuracy: 0.6923 - lr: 2.5000e-04\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.8127 - val_accuracy: 0.6923 - lr: 2.5000e-04\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8082 - val_accuracy: 0.6923 - lr: 2.5000e-04\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8197 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 982ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8256 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8289 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8316 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.72; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 2.2765 - accuracy: 0.2722 - val_loss: 1.1440 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7646 - accuracy: 0.5316 - val_loss: 1.3690 - val_accuracy: 0.3077 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1719 - accuracy: 0.6456 - val_loss: 0.9550 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 984ms/step - loss: 0.8012 - accuracy: 0.7468 - val_loss: 0.9314 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 0.5217 - accuracy: 0.8734 - val_loss: 1.2415 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 991ms/step - loss: 0.2894 - accuracy: 0.9304 - val_loss: 0.8587 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1859 - accuracy: 0.9810 - val_loss: 0.7916 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1605 - accuracy: 0.9557 - val_loss: 1.2463 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0920 - accuracy: 0.9873 - val_loss: 0.9203 - val_accuracy: 0.5192 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 983ms/step - loss: 0.0739 - accuracy: 0.9937 - val_loss: 1.2627 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0712 - accuracy: 0.9873 - val_loss: 0.8851 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.8817 - val_accuracy: 0.6731 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.6154 - lr: 5.0000e-04\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.6154 - lr: 5.0000e-04\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 992ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.6154 - lr: 5.0000e-04\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.0177 - val_accuracy: 0.6538 - lr: 2.5000e-04\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 993ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.6346 - lr: 2.5000e-04\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 979ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0875 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.6731 - lr: 1.2500e-04\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 987ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1109 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.1170 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.1205 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 986ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.1196 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.73; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 1.9105 - accuracy: 0.3671 - val_loss: 0.9135 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 999ms/step - loss: 1.2397 - accuracy: 0.6013 - val_loss: 0.8531 - val_accuracy: 0.5769 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5959 - accuracy: 0.8671 - val_loss: 1.0679 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3382 - accuracy: 0.9241 - val_loss: 0.8223 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2797 - accuracy: 0.9241 - val_loss: 0.8432 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1775 - accuracy: 0.9684 - val_loss: 1.5333 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1015 - accuracy: 0.9873 - val_loss: 0.9962 - val_accuracy: 0.5962 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0980 - accuracy: 0.9937 - val_loss: 1.2487 - val_accuracy: 0.5385 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.0658 - accuracy: 0.9873 - val_loss: 0.9451 - val_accuracy: 0.6538 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.6538 - lr: 5.0000e-04\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.1058 - val_accuracy: 0.6346 - lr: 5.0000e-04\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.9747 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.9790 - val_accuracy: 0.6731 - lr: 5.0000e-04\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.9890 - val_accuracy: 0.6923 - lr: 2.5000e-04\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 8s 840ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.0035 - val_accuracy: 0.7308 - lr: 2.5000e-04\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 8s 867ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.0056 - val_accuracy: 0.6923 - lr: 2.5000e-04\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 9s 915ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.0130 - val_accuracy: 0.6923 - lr: 2.5000e-04\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.6731 - lr: 2.5000e-04\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.0305 - val_accuracy: 0.6731 - lr: 1.2500e-04\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.0356 - val_accuracy: 0.6731 - lr: 1.2500e-04\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.0397 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0422 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.6923 - lr: 1.2500e-04\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.81; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.72 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.73 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.81 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.9):\n",
      "> Accuracy: 0.69 (+- 0.04)\n",
      "> Loss: 0.75 (+- 0.04)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 7/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 16s 1s/step - loss: 2.0896 - accuracy: 0.1203 - val_loss: 1.0780 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.9177 - accuracy: 0.2405 - val_loss: 1.0499 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8560 - accuracy: 0.2722 - val_loss: 1.0407 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8276 - accuracy: 0.3291 - val_loss: 1.0422 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7935 - accuracy: 0.3987 - val_loss: 1.0429 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7568 - accuracy: 0.3987 - val_loss: 1.0449 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7361 - accuracy: 0.4114 - val_loss: 1.0441 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7363 - accuracy: 0.3924 - val_loss: 1.0484 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7073 - accuracy: 0.4177 - val_loss: 1.0516 - val_accuracy: 0.3846 - lr: 5.0000e-05\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 980ms/step - loss: 1.6956 - accuracy: 0.4557 - val_loss: 1.0568 - val_accuracy: 0.4038 - lr: 5.0000e-05\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 995ms/step - loss: 1.6821 - accuracy: 0.4620 - val_loss: 1.0614 - val_accuracy: 0.4231 - lr: 5.0000e-05\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6750 - accuracy: 0.4367 - val_loss: 1.0667 - val_accuracy: 0.4231 - lr: 5.0000e-05\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6809 - accuracy: 0.4430 - val_loss: 1.0714 - val_accuracy: 0.3846 - lr: 5.0000e-05\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6622 - accuracy: 0.4494 - val_loss: 1.0749 - val_accuracy: 0.3846 - lr: 2.5000e-05\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6702 - accuracy: 0.4557 - val_loss: 1.0786 - val_accuracy: 0.3462 - lr: 2.5000e-05\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6759 - accuracy: 0.4494 - val_loss: 1.0817 - val_accuracy: 0.3462 - lr: 2.5000e-05\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 979ms/step - loss: 1.6421 - accuracy: 0.4557 - val_loss: 1.0835 - val_accuracy: 0.3462 - lr: 2.5000e-05\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 9s 968ms/step - loss: 1.6417 - accuracy: 0.4304 - val_loss: 1.0846 - val_accuracy: 0.3269 - lr: 2.5000e-05\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6456 - accuracy: 0.4747 - val_loss: 1.0867 - val_accuracy: 0.3846 - lr: 1.2500e-05\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6449 - accuracy: 0.4684 - val_loss: 1.0890 - val_accuracy: 0.3654 - lr: 1.2500e-05\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6307 - accuracy: 0.4937 - val_loss: 1.0912 - val_accuracy: 0.3654 - lr: 1.2500e-05\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 975ms/step - loss: 1.6434 - accuracy: 0.4620 - val_loss: 1.0921 - val_accuracy: 0.3654 - lr: 1.2500e-05\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 989ms/step - loss: 1.6272 - accuracy: 0.4747 - val_loss: 1.0927 - val_accuracy: 0.3462 - lr: 1.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 1.04; accuracy of 38.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 16s 1s/step - loss: 2.0662 - accuracy: 0.1392 - val_loss: 1.0992 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 9s 962ms/step - loss: 1.9178 - accuracy: 0.2152 - val_loss: 1.0659 - val_accuracy: 0.4808 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8449 - accuracy: 0.2595 - val_loss: 1.0517 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8116 - accuracy: 0.3544 - val_loss: 1.0489 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7555 - accuracy: 0.3608 - val_loss: 1.0485 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.7688 - accuracy: 0.3987 - val_loss: 1.0560 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7242 - accuracy: 0.3671 - val_loss: 1.0560 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.7174 - accuracy: 0.4114 - val_loss: 1.0608 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.6832 - accuracy: 0.4557 - val_loss: 1.0637 - val_accuracy: 0.4231 - lr: 1.0000e-04\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6774 - accuracy: 0.4494 - val_loss: 1.0664 - val_accuracy: 0.4231 - lr: 1.0000e-04\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6504 - accuracy: 0.4810 - val_loss: 1.0722 - val_accuracy: 0.4423 - lr: 5.0000e-05\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.6587 - accuracy: 0.4557 - val_loss: 1.0788 - val_accuracy: 0.4231 - lr: 5.0000e-05\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6599 - accuracy: 0.4620 - val_loss: 1.0852 - val_accuracy: 0.4231 - lr: 5.0000e-05\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6535 - accuracy: 0.4114 - val_loss: 1.0924 - val_accuracy: 0.4231 - lr: 5.0000e-05\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6264 - accuracy: 0.4367 - val_loss: 1.0963 - val_accuracy: 0.4423 - lr: 5.0000e-05\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6102 - accuracy: 0.4620 - val_loss: 1.1008 - val_accuracy: 0.4423 - lr: 2.5000e-05\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6228 - accuracy: 0.4304 - val_loss: 1.1040 - val_accuracy: 0.4231 - lr: 2.5000e-05\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6301 - accuracy: 0.4557 - val_loss: 1.1081 - val_accuracy: 0.4231 - lr: 2.5000e-05\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6092 - accuracy: 0.4747 - val_loss: 1.1116 - val_accuracy: 0.4231 - lr: 2.5000e-05\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6102 - accuracy: 0.4873 - val_loss: 1.1152 - val_accuracy: 0.4231 - lr: 2.5000e-05\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5986 - accuracy: 0.4557 - val_loss: 1.1193 - val_accuracy: 0.4231 - lr: 1.2500e-05\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5853 - accuracy: 0.4810 - val_loss: 1.1227 - val_accuracy: 0.4038 - lr: 1.2500e-05\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5757 - accuracy: 0.4937 - val_loss: 1.1258 - val_accuracy: 0.4231 - lr: 1.2500e-05\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5896 - accuracy: 0.4684 - val_loss: 1.1286 - val_accuracy: 0.4231 - lr: 1.2500e-05\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5794 - accuracy: 0.4873 - val_loss: 1.1306 - val_accuracy: 0.4038 - lr: 1.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 1.03; accuracy of 38.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 15s 945ms/step - loss: 2.0603 - accuracy: 0.1456 - val_loss: 1.1042 - val_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 9s 947ms/step - loss: 1.8968 - accuracy: 0.2468 - val_loss: 1.0739 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 979ms/step - loss: 1.8535 - accuracy: 0.2975 - val_loss: 1.0617 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8017 - accuracy: 0.3481 - val_loss: 1.0671 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7886 - accuracy: 0.3671 - val_loss: 1.0696 - val_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7538 - accuracy: 0.3987 - val_loss: 1.0741 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7352 - accuracy: 0.4304 - val_loss: 1.0800 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7204 - accuracy: 0.4051 - val_loss: 1.0816 - val_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6600 - accuracy: 0.4684 - val_loss: 1.0862 - val_accuracy: 0.3654 - lr: 5.0000e-05\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.6727 - accuracy: 0.4747 - val_loss: 1.0889 - val_accuracy: 0.3846 - lr: 5.0000e-05\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6817 - accuracy: 0.4684 - val_loss: 1.0912 - val_accuracy: 0.3654 - lr: 5.0000e-05\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6769 - accuracy: 0.4620 - val_loss: 1.0948 - val_accuracy: 0.4038 - lr: 5.0000e-05\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6488 - accuracy: 0.4684 - val_loss: 1.0975 - val_accuracy: 0.3846 - lr: 5.0000e-05\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6425 - accuracy: 0.4937 - val_loss: 1.1009 - val_accuracy: 0.3846 - lr: 2.5000e-05\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6581 - accuracy: 0.4873 - val_loss: 1.1033 - val_accuracy: 0.3846 - lr: 2.5000e-05\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6384 - accuracy: 0.4620 - val_loss: 1.1050 - val_accuracy: 0.3846 - lr: 2.5000e-05\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6472 - accuracy: 0.4747 - val_loss: 1.1072 - val_accuracy: 0.3846 - lr: 2.5000e-05\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6313 - accuracy: 0.4684 - val_loss: 1.1078 - val_accuracy: 0.3846 - lr: 2.5000e-05\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6268 - accuracy: 0.4684 - val_loss: 1.1083 - val_accuracy: 0.3654 - lr: 1.2500e-05\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6330 - accuracy: 0.4747 - val_loss: 1.1085 - val_accuracy: 0.3846 - lr: 1.2500e-05\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6465 - accuracy: 0.4747 - val_loss: 1.1089 - val_accuracy: 0.3462 - lr: 1.2500e-05\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6273 - accuracy: 0.4684 - val_loss: 1.1093 - val_accuracy: 0.3654 - lr: 1.2500e-05\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 992ms/step - loss: 1.6264 - accuracy: 0.5000 - val_loss: 1.1093 - val_accuracy: 0.3654 - lr: 1.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 1.04; accuracy of 38.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 1.04 - Accuracy: 0.38%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.03 - Accuracy: 0.38%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 1.04 - Accuracy: 0.38%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0):\n",
      "> Accuracy: 0.38 (+- 0.0)\n",
      "> Loss: 1.04 (+- 0.0)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 8/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 18s 1s/step - loss: 2.0670 - accuracy: 0.1392 - val_loss: 1.0592 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 1.8347 - accuracy: 0.2911 - val_loss: 1.0309 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7789 - accuracy: 0.4177 - val_loss: 1.0388 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 8s 836ms/step - loss: 1.7810 - accuracy: 0.4367 - val_loss: 1.0414 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 8s 779ms/step - loss: 1.7068 - accuracy: 0.3924 - val_loss: 1.0417 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7075 - accuracy: 0.4430 - val_loss: 1.0394 - val_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6601 - accuracy: 0.4557 - val_loss: 1.0366 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6134 - accuracy: 0.5190 - val_loss: 1.0346 - val_accuracy: 0.3654 - lr: 5.0000e-05\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.6114 - accuracy: 0.4747 - val_loss: 1.0342 - val_accuracy: 0.3846 - lr: 5.0000e-05\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5799 - accuracy: 0.5000 - val_loss: 1.0346 - val_accuracy: 0.3846 - lr: 5.0000e-05\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5654 - accuracy: 0.5380 - val_loss: 1.0277 - val_accuracy: 0.4038 - lr: 5.0000e-05\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5556 - accuracy: 0.5127 - val_loss: 1.0394 - val_accuracy: 0.4038 - lr: 5.0000e-05\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5315 - accuracy: 0.5570 - val_loss: 1.0358 - val_accuracy: 0.3846 - lr: 5.0000e-05\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5276 - accuracy: 0.5127 - val_loss: 1.0389 - val_accuracy: 0.3846 - lr: 5.0000e-05\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5151 - accuracy: 0.5633 - val_loss: 1.0418 - val_accuracy: 0.4038 - lr: 5.0000e-05\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4970 - accuracy: 0.5886 - val_loss: 1.0376 - val_accuracy: 0.4038 - lr: 5.0000e-05\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4722 - accuracy: 0.5696 - val_loss: 1.0392 - val_accuracy: 0.3654 - lr: 2.5000e-05\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.4645 - accuracy: 0.6203 - val_loss: 1.0382 - val_accuracy: 0.3654 - lr: 2.5000e-05\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4449 - accuracy: 0.5696 - val_loss: 1.0400 - val_accuracy: 0.4038 - lr: 2.5000e-05\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4406 - accuracy: 0.6329 - val_loss: 1.0407 - val_accuracy: 0.4231 - lr: 2.5000e-05\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4668 - accuracy: 0.6076 - val_loss: 1.0421 - val_accuracy: 0.3846 - lr: 2.5000e-05\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4207 - accuracy: 0.6203 - val_loss: 1.0392 - val_accuracy: 0.3846 - lr: 1.2500e-05\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 990ms/step - loss: 1.4567 - accuracy: 0.6203 - val_loss: 1.0395 - val_accuracy: 0.3654 - lr: 1.2500e-05\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4357 - accuracy: 0.6329 - val_loss: 1.0418 - val_accuracy: 0.3654 - lr: 1.2500e-05\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4229 - accuracy: 0.6329 - val_loss: 1.0391 - val_accuracy: 0.3462 - lr: 1.2500e-05\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4282 - accuracy: 0.6013 - val_loss: 1.0399 - val_accuracy: 0.3654 - lr: 1.2500e-05\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4369 - accuracy: 0.6013 - val_loss: 1.0411 - val_accuracy: 0.3462 - lr: 6.2500e-06\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 7s 701ms/step - loss: 1.4318 - accuracy: 0.6329 - val_loss: 1.0409 - val_accuracy: 0.3269 - lr: 6.2500e-06\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 9s 992ms/step - loss: 1.4161 - accuracy: 0.6203 - val_loss: 1.0405 - val_accuracy: 0.3269 - lr: 6.2500e-06\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 10s 988ms/step - loss: 1.4135 - accuracy: 0.6013 - val_loss: 1.0398 - val_accuracy: 0.3269 - lr: 6.2500e-06\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4323 - accuracy: 0.6329 - val_loss: 1.0397 - val_accuracy: 0.3462 - lr: 6.2500e-06\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 1.05; accuracy of 44.23%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 2.0456 - accuracy: 0.1772 - val_loss: 1.0594 - val_accuracy: 0.4808 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8415 - accuracy: 0.3038 - val_loss: 1.0402 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7933 - accuracy: 0.3734 - val_loss: 1.0461 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7462 - accuracy: 0.4241 - val_loss: 1.0447 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6899 - accuracy: 0.4367 - val_loss: 1.0528 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6868 - accuracy: 0.4051 - val_loss: 1.0526 - val_accuracy: 0.4231 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6304 - accuracy: 0.4430 - val_loss: 1.0515 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5846 - accuracy: 0.4937 - val_loss: 1.0484 - val_accuracy: 0.4038 - lr: 5.0000e-05\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5781 - accuracy: 0.5063 - val_loss: 1.0496 - val_accuracy: 0.4231 - lr: 5.0000e-05\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5632 - accuracy: 0.5127 - val_loss: 1.0518 - val_accuracy: 0.4423 - lr: 5.0000e-05\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 983ms/step - loss: 1.5451 - accuracy: 0.5063 - val_loss: 1.0537 - val_accuracy: 0.4231 - lr: 5.0000e-05\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5195 - accuracy: 0.5570 - val_loss: 1.0578 - val_accuracy: 0.4231 - lr: 5.0000e-05\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5036 - accuracy: 0.5506 - val_loss: 1.0671 - val_accuracy: 0.4231 - lr: 2.5000e-05\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5048 - accuracy: 0.5253 - val_loss: 1.0684 - val_accuracy: 0.4231 - lr: 2.5000e-05\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4822 - accuracy: 0.5506 - val_loss: 1.0702 - val_accuracy: 0.4615 - lr: 2.5000e-05\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4950 - accuracy: 0.5570 - val_loss: 1.0733 - val_accuracy: 0.4615 - lr: 2.5000e-05\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4798 - accuracy: 0.5759 - val_loss: 1.0756 - val_accuracy: 0.4615 - lr: 2.5000e-05\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4679 - accuracy: 0.6266 - val_loss: 1.0785 - val_accuracy: 0.4615 - lr: 1.2500e-05\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4311 - accuracy: 0.6076 - val_loss: 1.0822 - val_accuracy: 0.4231 - lr: 1.2500e-05\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4511 - accuracy: 0.5949 - val_loss: 1.0854 - val_accuracy: 0.4423 - lr: 1.2500e-05\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4580 - accuracy: 0.5823 - val_loss: 1.0880 - val_accuracy: 0.4423 - lr: 1.2500e-05\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4594 - accuracy: 0.5886 - val_loss: 1.0927 - val_accuracy: 0.4038 - lr: 1.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 1.03; accuracy of 34.62%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 2.0359 - accuracy: 0.1772 - val_loss: 1.0640 - val_accuracy: 0.4231 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8410 - accuracy: 0.3165 - val_loss: 1.0461 - val_accuracy: 0.4231 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7812 - accuracy: 0.3544 - val_loss: 1.0405 - val_accuracy: 0.4231 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7160 - accuracy: 0.4557 - val_loss: 1.0454 - val_accuracy: 0.4231 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7217 - accuracy: 0.4304 - val_loss: 1.0524 - val_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6453 - accuracy: 0.4620 - val_loss: 1.0501 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 999ms/step - loss: 1.6347 - accuracy: 0.5127 - val_loss: 1.0519 - val_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.6194 - accuracy: 0.4810 - val_loss: 1.0477 - val_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5460 - accuracy: 0.5127 - val_loss: 1.0477 - val_accuracy: 0.4038 - lr: 5.0000e-05\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5311 - accuracy: 0.5316 - val_loss: 1.0528 - val_accuracy: 0.4038 - lr: 5.0000e-05\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5242 - accuracy: 0.5443 - val_loss: 1.0570 - val_accuracy: 0.4615 - lr: 5.0000e-05\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5043 - accuracy: 0.5633 - val_loss: 1.0565 - val_accuracy: 0.4808 - lr: 5.0000e-05\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4815 - accuracy: 0.5633 - val_loss: 1.0577 - val_accuracy: 0.4615 - lr: 5.0000e-05\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4714 - accuracy: 0.5949 - val_loss: 1.0602 - val_accuracy: 0.4423 - lr: 2.5000e-05\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 994ms/step - loss: 1.4733 - accuracy: 0.5949 - val_loss: 1.0634 - val_accuracy: 0.4423 - lr: 2.5000e-05\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4905 - accuracy: 0.5886 - val_loss: 1.0646 - val_accuracy: 0.4423 - lr: 2.5000e-05\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4719 - accuracy: 0.5886 - val_loss: 1.0665 - val_accuracy: 0.4231 - lr: 2.5000e-05\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4385 - accuracy: 0.5570 - val_loss: 1.0648 - val_accuracy: 0.4038 - lr: 2.5000e-05\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4578 - accuracy: 0.5696 - val_loss: 1.0626 - val_accuracy: 0.4038 - lr: 1.2500e-05\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4650 - accuracy: 0.5759 - val_loss: 1.0633 - val_accuracy: 0.4038 - lr: 1.2500e-05\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4381 - accuracy: 0.5949 - val_loss: 1.0635 - val_accuracy: 0.4231 - lr: 1.2500e-05\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 978ms/step - loss: 1.4425 - accuracy: 0.5823 - val_loss: 1.0623 - val_accuracy: 0.4231 - lr: 1.2500e-05\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 988ms/step - loss: 1.4302 - accuracy: 0.5823 - val_loss: 1.0601 - val_accuracy: 0.4423 - lr: 1.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 1.02; accuracy of 36.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 1.05 - Accuracy: 0.44%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.03 - Accuracy: 0.35%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 1.02 - Accuracy: 0.37%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.5):\n",
      "> Accuracy: 0.38 (+- 0.04)\n",
      "> Loss: 1.03 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 9/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 1.9701 - accuracy: 0.2025 - val_loss: 1.0182 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8291 - accuracy: 0.4241 - val_loss: 1.0088 - val_accuracy: 0.3654 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 982ms/step - loss: 1.6072 - accuracy: 0.4810 - val_loss: 1.0336 - val_accuracy: 0.4231 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.4857 - accuracy: 0.5127 - val_loss: 0.9645 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.3830 - accuracy: 0.5949 - val_loss: 0.9999 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.2227 - accuracy: 0.7278 - val_loss: 0.9113 - val_accuracy: 0.5192 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1188 - accuracy: 0.8038 - val_loss: 0.9316 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0646 - accuracy: 0.7975 - val_loss: 0.8941 - val_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9467 - accuracy: 0.8354 - val_loss: 0.9041 - val_accuracy: 0.5577 - lr: 1.0000e-04\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8700 - accuracy: 0.8418 - val_loss: 0.8585 - val_accuracy: 0.5577 - lr: 1.0000e-04\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 987ms/step - loss: 0.8131 - accuracy: 0.8481 - val_loss: 0.8311 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7423 - accuracy: 0.8987 - val_loss: 0.8603 - val_accuracy: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 986ms/step - loss: 0.7134 - accuracy: 0.8734 - val_loss: 0.8045 - val_accuracy: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6569 - accuracy: 0.8861 - val_loss: 0.8124 - val_accuracy: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5960 - accuracy: 0.9367 - val_loss: 0.7870 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5642 - accuracy: 0.9304 - val_loss: 0.8001 - val_accuracy: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5382 - accuracy: 0.9494 - val_loss: 0.7892 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 9s 957ms/step - loss: 0.5050 - accuracy: 0.9304 - val_loss: 0.7628 - val_accuracy: 0.6538 - lr: 1.0000e-04\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4726 - accuracy: 0.9620 - val_loss: 0.7639 - val_accuracy: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 996ms/step - loss: 0.4472 - accuracy: 0.9684 - val_loss: 0.7607 - val_accuracy: 0.6923 - lr: 1.0000e-04\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4155 - accuracy: 0.9684 - val_loss: 0.7410 - val_accuracy: 0.7115 - lr: 1.0000e-04\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3727 - accuracy: 0.9620 - val_loss: 0.7330 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 978ms/step - loss: 0.3535 - accuracy: 0.9810 - val_loss: 0.7426 - val_accuracy: 0.7115 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3451 - accuracy: 0.9747 - val_loss: 0.7376 - val_accuracy: 0.7308 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3267 - accuracy: 0.9557 - val_loss: 0.7145 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3048 - accuracy: 0.9747 - val_loss: 0.7333 - val_accuracy: 0.7115 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2833 - accuracy: 0.9747 - val_loss: 0.7119 - val_accuracy: 0.6923 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2687 - accuracy: 0.9747 - val_loss: 0.7191 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2911 - accuracy: 0.9684 - val_loss: 0.7144 - val_accuracy: 0.6923 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2715 - accuracy: 0.9937 - val_loss: 0.7087 - val_accuracy: 0.6923 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2228 - accuracy: 0.9873 - val_loss: 0.7148 - val_accuracy: 0.7115 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2239 - accuracy: 0.9810 - val_loss: 0.7259 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1917 - accuracy: 0.9937 - val_loss: 0.7147 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1908 - accuracy: 0.9937 - val_loss: 0.7053 - val_accuracy: 0.6538 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1871 - accuracy: 0.9873 - val_loss: 0.7177 - val_accuracy: 0.6923 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1787 - accuracy: 1.0000 - val_loss: 0.7309 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1768 - accuracy: 0.9937 - val_loss: 0.7083 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1438 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.6923 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 10s 990ms/step - loss: 0.1409 - accuracy: 0.9937 - val_loss: 0.7086 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1417 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.6923 - lr: 5.0000e-05\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.6923 - lr: 5.0000e-05\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1241 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.6923 - lr: 5.0000e-05\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1405 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.6731 - lr: 5.0000e-05\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1263 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.6923 - lr: 5.0000e-05\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.6923 - lr: 2.5000e-05\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1240 - accuracy: 0.9937 - val_loss: 0.7190 - val_accuracy: 0.6923 - lr: 2.5000e-05\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 10s 994ms/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.6923 - lr: 2.5000e-05\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.6923 - lr: 2.5000e-05\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.6923 - lr: 2.5000e-05\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1154 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.6923 - lr: 1.2500e-05\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 9s 960ms/step - loss: 0.1240 - accuracy: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.6923 - lr: 1.2500e-05\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.6923 - lr: 1.2500e-05\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.6923 - lr: 1.2500e-05\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.6923 - lr: 1.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 17s 1s/step - loss: 1.9691 - accuracy: 0.1962 - val_loss: 1.0113 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.8230 - accuracy: 0.4367 - val_loss: 1.0283 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.5627 - accuracy: 0.5253 - val_loss: 1.0001 - val_accuracy: 0.4808 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 10s 999ms/step - loss: 1.4552 - accuracy: 0.5000 - val_loss: 1.0325 - val_accuracy: 0.4231 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.2835 - accuracy: 0.6519 - val_loss: 0.9682 - val_accuracy: 0.5192 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1959 - accuracy: 0.7975 - val_loss: 0.9444 - val_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0882 - accuracy: 0.7722 - val_loss: 0.9758 - val_accuracy: 0.4808 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0064 - accuracy: 0.8038 - val_loss: 0.9303 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9369 - accuracy: 0.8544 - val_loss: 0.9567 - val_accuracy: 0.4038 - lr: 1.0000e-04\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8640 - accuracy: 0.8671 - val_loss: 0.9067 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7599 - accuracy: 0.8924 - val_loss: 0.9160 - val_accuracy: 0.4808 - lr: 1.0000e-04\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6989 - accuracy: 0.9114 - val_loss: 0.8899 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7159 - accuracy: 0.8797 - val_loss: 0.8778 - val_accuracy: 0.4808 - lr: 1.0000e-04\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6293 - accuracy: 0.8734 - val_loss: 0.9493 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5540 - accuracy: 0.9304 - val_loss: 0.8600 - val_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5328 - accuracy: 0.9304 - val_loss: 0.8631 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5034 - accuracy: 0.9051 - val_loss: 0.8752 - val_accuracy: 0.5192 - lr: 1.0000e-04\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4506 - accuracy: 0.9620 - val_loss: 0.8737 - val_accuracy: 0.5192 - lr: 1.0000e-04\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4247 - accuracy: 0.9494 - val_loss: 0.8478 - val_accuracy: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3927 - accuracy: 0.9620 - val_loss: 0.8502 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3617 - accuracy: 0.9684 - val_loss: 0.8785 - val_accuracy: 0.5577 - lr: 1.0000e-04\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3634 - accuracy: 0.9620 - val_loss: 0.8505 - val_accuracy: 0.5577 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3276 - accuracy: 0.9747 - val_loss: 0.8786 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2971 - accuracy: 0.9684 - val_loss: 0.8520 - val_accuracy: 0.5577 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2998 - accuracy: 0.9873 - val_loss: 0.8524 - val_accuracy: 0.5577 - lr: 5.0000e-05\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2851 - accuracy: 0.9873 - val_loss: 0.8563 - val_accuracy: 0.5962 - lr: 5.0000e-05\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2670 - accuracy: 0.9684 - val_loss: 0.8650 - val_accuracy: 0.5962 - lr: 5.0000e-05\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 976ms/step - loss: 0.2538 - accuracy: 0.9873 - val_loss: 0.8592 - val_accuracy: 0.5962 - lr: 5.0000e-05\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2747 - accuracy: 0.9810 - val_loss: 0.8558 - val_accuracy: 0.5385 - lr: 5.0000e-05\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 9s 916ms/step - loss: 0.2759 - accuracy: 0.9747 - val_loss: 0.8615 - val_accuracy: 0.5962 - lr: 2.5000e-05\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 9s 918ms/step - loss: 0.2599 - accuracy: 0.9810 - val_loss: 0.8620 - val_accuracy: 0.5769 - lr: 2.5000e-05\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2188 - accuracy: 0.9873 - val_loss: 0.8599 - val_accuracy: 0.5192 - lr: 2.5000e-05\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2579 - accuracy: 0.9873 - val_loss: 0.8601 - val_accuracy: 0.5192 - lr: 2.5000e-05\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2200 - accuracy: 0.9873 - val_loss: 0.8631 - val_accuracy: 0.5385 - lr: 2.5000e-05\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2515 - accuracy: 0.9810 - val_loss: 0.8639 - val_accuracy: 0.5385 - lr: 1.2500e-05\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2326 - accuracy: 0.9873 - val_loss: 0.8658 - val_accuracy: 0.5385 - lr: 1.2500e-05\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2407 - accuracy: 0.9810 - val_loss: 0.8665 - val_accuracy: 0.5385 - lr: 1.2500e-05\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2131 - accuracy: 0.9873 - val_loss: 0.8666 - val_accuracy: 0.5192 - lr: 1.2500e-05\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2236 - accuracy: 0.9937 - val_loss: 0.8682 - val_accuracy: 0.5192 - lr: 1.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.79; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 18s 1s/step - loss: 1.9773 - accuracy: 0.2595 - val_loss: 1.0174 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.7237 - accuracy: 0.4494 - val_loss: 1.0278 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.5782 - accuracy: 0.4937 - val_loss: 0.9914 - val_accuracy: 0.4808 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.4125 - accuracy: 0.6203 - val_loss: 0.9911 - val_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.2989 - accuracy: 0.6139 - val_loss: 1.0008 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1876 - accuracy: 0.7089 - val_loss: 0.9513 - val_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.1122 - accuracy: 0.7595 - val_loss: 0.9234 - val_accuracy: 0.4808 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 1.0270 - accuracy: 0.7975 - val_loss: 0.9370 - val_accuracy: 0.5192 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9454 - accuracy: 0.8101 - val_loss: 0.9251 - val_accuracy: 0.5192 - lr: 1.0000e-04\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.8707 - accuracy: 0.8734 - val_loss: 0.9140 - val_accuracy: 0.4808 - lr: 1.0000e-04\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7754 - accuracy: 0.8987 - val_loss: 0.8890 - val_accuracy: 0.5577 - lr: 1.0000e-04\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.7093 - accuracy: 0.8734 - val_loss: 0.8717 - val_accuracy: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6737 - accuracy: 0.9241 - val_loss: 0.8850 - val_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.6023 - accuracy: 0.9494 - val_loss: 0.8590 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5707 - accuracy: 0.9114 - val_loss: 0.8515 - val_accuracy: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5173 - accuracy: 0.9494 - val_loss: 0.8478 - val_accuracy: 0.5769 - lr: 1.0000e-04\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4846 - accuracy: 0.9620 - val_loss: 0.8318 - val_accuracy: 0.6154 - lr: 1.0000e-04\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4599 - accuracy: 0.9494 - val_loss: 0.8367 - val_accuracy: 0.6154 - lr: 1.0000e-04\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4425 - accuracy: 0.9494 - val_loss: 0.8274 - val_accuracy: 0.5962 - lr: 1.0000e-04\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3747 - accuracy: 0.9810 - val_loss: 0.8240 - val_accuracy: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3744 - accuracy: 0.9620 - val_loss: 0.8152 - val_accuracy: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3468 - accuracy: 0.9747 - val_loss: 0.8207 - val_accuracy: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3471 - accuracy: 0.9810 - val_loss: 0.8189 - val_accuracy: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3172 - accuracy: 0.9873 - val_loss: 0.8136 - val_accuracy: 0.6538 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3017 - accuracy: 0.9684 - val_loss: 0.8128 - val_accuracy: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2662 - accuracy: 0.9810 - val_loss: 0.8198 - val_accuracy: 0.6538 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 10s 981ms/step - loss: 0.2475 - accuracy: 0.9937 - val_loss: 0.8222 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2361 - accuracy: 0.9873 - val_loss: 0.8208 - val_accuracy: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2274 - accuracy: 0.9937 - val_loss: 0.8234 - val_accuracy: 0.6731 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2056 - accuracy: 0.9937 - val_loss: 0.8166 - val_accuracy: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2058 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.6346 - lr: 5.0000e-05\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1929 - accuracy: 0.9937 - val_loss: 0.8200 - val_accuracy: 0.6346 - lr: 5.0000e-05\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1971 - accuracy: 0.9937 - val_loss: 0.8196 - val_accuracy: 0.6346 - lr: 5.0000e-05\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1815 - accuracy: 1.0000 - val_loss: 0.8217 - val_accuracy: 0.6538 - lr: 5.0000e-05\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1799 - accuracy: 0.9937 - val_loss: 0.8250 - val_accuracy: 0.6538 - lr: 5.0000e-05\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 10s 988ms/step - loss: 0.1867 - accuracy: 0.9937 - val_loss: 0.8226 - val_accuracy: 0.6538 - lr: 2.5000e-05\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 10s 985ms/step - loss: 0.1725 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.6538 - lr: 2.5000e-05\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 9s 953ms/step - loss: 0.1753 - accuracy: 0.9937 - val_loss: 0.8253 - val_accuracy: 0.6538 - lr: 2.5000e-05\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1807 - accuracy: 0.9937 - val_loss: 0.8227 - val_accuracy: 0.6346 - lr: 2.5000e-05\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1762 - accuracy: 0.9937 - val_loss: 0.8213 - val_accuracy: 0.6346 - lr: 2.5000e-05\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1781 - accuracy: 0.9937 - val_loss: 0.8232 - val_accuracy: 0.6538 - lr: 1.2500e-05\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1742 - accuracy: 0.9937 - val_loss: 0.8234 - val_accuracy: 0.6538 - lr: 1.2500e-05\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1690 - accuracy: 0.9937 - val_loss: 0.8234 - val_accuracy: 0.6538 - lr: 1.2500e-05\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1570 - accuracy: 0.9937 - val_loss: 0.8235 - val_accuracy: 0.6538 - lr: 1.2500e-05\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1525 - accuracy: 1.0000 - val_loss: 0.8239 - val_accuracy: 0.6538 - lr: 1.2500e-05\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.8; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.79 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.8 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.9):\n",
      "> Accuracy: 0.65 (+- 0.01)\n",
      "> Loss: 0.79 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_rate = [0.01, 0.001, 0.0001]\n",
    "momentum = [0, 0.5, 0.9]\n",
    "\n",
    "tot_comb = len(learn_rate) * len(momentum)\n",
    "glob_param = np.empty([tot_comb, 2])\n",
    "\n",
    "history_list = []\n",
    "scores_glob_array = np.empty([tot_comb, n_folds, 2])\n",
    "\n",
    "import itertools\n",
    "\n",
    "for idx, x in enumerate(itertools.product(learn_rate, momentum)):\n",
    "    learn_rate = x[0]\n",
    "    momentum = x[1]\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for combination {idx + 1}/{tot_comb} ...')\n",
    "    print(f'Learning rate = {learn_rate}')\n",
    "    print(f'Momentum = {momentum}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    history_array = np.array([])\n",
    "    scores_array = np.empty([n_folds, 2])\n",
    "\n",
    "    glob_param[idx, 0] = learn_rate\n",
    "    glob_param[idx, 1] = momentum\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold + 1}/{n_folds} ...')\n",
    "        print('------------------------------------------------------------------------')\n",
    "\n",
    "        # Generate the fold sample for train-test\n",
    "        X_train, Y_train, X_test, Y_test = part_traintest(X_traintest, Y_traintest, rand_seed + fold, frac_test)\n",
    "\n",
    "        # Define the model architecture\n",
    "        model_1rama = DenseNet_1Rama(vista, input_dim, rand_seed, learn_rate, momentum)\n",
    "\n",
    "        # Fit data to model\n",
    "        history = model_1rama.fit(X_train, Y_train,\n",
    "                                  batch_size = batch_size,\n",
    "                                  epochs = no_epochs,\n",
    "                                  validation_data = (X_test, Y_test),\n",
    "                                  class_weight = class_weight,\n",
    "                                  verbose = 1,\n",
    "                                  callbacks = [early_stopping, reduce_lr])\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        scores_array[fold, :] = model_1rama.evaluate(X_val, Y_val, verbose = 0)\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Score for fold {fold + 1}: {model_1rama.metrics_names[0]} of {round(scores_array[fold, 0], 2)}; {model_1rama.metrics_names[1]} of {round(scores_array[fold, 1]*100, 2)}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('')\n",
    "\n",
    "        # Append history callback into array\n",
    "        history_array = np.append(history_array, [history])\n",
    "\n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, scores_array.shape[0]):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i + 1} - Loss: {round(scores_array[i, 0], 2)} - Accuracy: {round(scores_array[i, 1], 2)}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Average scores for all folds (LR = {learn_rate}, mtm = {momentum}):')\n",
    "    print(f'> Accuracy: {round(np.mean(scores_array[:, 1]), 2)} (+- {round(np.std(scores_array[:, 1]), 2)})')\n",
    "    print(f'> Loss: {round(np.mean(scores_array[:, 0]), 2)} (+- {round(np.std(scores_array[:, 0]), 2)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "    idx_best_hist = np.argmax(scores_array[:, 1])\n",
    "    history_list.append(history_array[idx_best_hist])\n",
    "\n",
    "    scores_glob_array[idx, :, :] = scores_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    \"\"\"\n",
    "    Function that plots the metrics from the training process\n",
    "        - history is the output from the training process\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize = (15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"\n",
    "    Credit to:\n",
    "    https://gist.github.com/zachguo/10296432\n",
    "    \n",
    "    Function that makes a pretty print for confusion matrixes\n",
    "        - cm is the array of histories generated during the training process\n",
    "        - labels is number of epochs fixed for the training process\n",
    "        - hide_zeroes is a boolean that allows the user to hide the zeroes in the matrix\n",
    "        - hide_diagonal is a boolean that allows the user to hide the diagonal in the matrix\n",
    "        - hide_threshold is a number that allows the user to hide results in the matrix below that value\n",
    "    \"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados promedios del entrenamiento DenseNet-CC:\n",
      "- LR=0.01 / mom=0.0:\tAcc=0.66 (+- 0.06) - Loss=0.84 (+- 0.03)\n",
      "- LR=0.01 / mom=0.5:\tAcc=0.62 (+- 0.06) - Loss=0.86 (+- 0.04)\n",
      "- LR=0.01 / mom=0.9:\tAcc=0.51 (+- 0.09) - Loss=1.02 (+- 0.16)\n",
      "- LR=0.001 / mom=0.0:\tAcc=0.65 (+- 0.03) - Loss=0.78 (+- 0.02)\n",
      "- LR=0.001 / mom=0.5:\tAcc=0.67 (+- 0.03) - Loss=0.78 (+- 0.02)\n",
      "- LR=0.001 / mom=0.9:\tAcc=0.69 (+- 0.04) - Loss=0.75 (+- 0.04)\n",
      "- LR=0.0001 / mom=0.0:\tAcc=0.38 (+- 0.0) - Loss=1.04 (+- 0.0)\n",
      "- LR=0.0001 / mom=0.5:\tAcc=0.38 (+- 0.04) - Loss=1.03 (+- 0.01)\n",
      "- LR=0.0001 / mom=0.9:\tAcc=0.65 (+- 0.01) - Loss=0.79 (+- 0.02)\n",
      "\n",
      "El mejor resultado para la DenseNet-CC se obtiene para LR = 0.001 y momentum = 0.9.\n"
     ]
    }
   ],
   "source": [
    "print(f'Resultados promedios del entrenamiento DenseNet-{vista}:')\n",
    "for i in range(len(glob_param)):\n",
    "    print(f'- LR={glob_param[i, 0]} / mom={glob_param[i, 1]}:\\tAcc={round(np.mean(scores_glob_array[i, :, 1]), 2)} (+- {round(np.std(scores_glob_array[i, :, 1]), 2)}) - Loss={round(np.mean(scores_glob_array[i, :, 0]), 2)} (+- {round(np.std(scores_glob_array[i, :, 0]), 2)})')\n",
    "\n",
    "idx_best = np.argmax(np.mean(scores_glob_array, 1)[:, 1])\n",
    "history_best = history_list[idx_best]\n",
    "model_best = history_best.model\n",
    "print(f'\\nEl mejor resultado para la DenseNet-{vista} se obtiene para LR = {glob_param[idx_best, 0]} y momentum = {glob_param[idx_best, 1]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 636ms/step\n",
      "                    benigno seguimiento     maligno \n",
      "        benigno        21.0         3.0         4.0 \n",
      "    seguimiento         1.0         2.0         1.0 \n",
      "        maligno         5.0         1.0        14.0 \n"
     ]
    }
   ],
   "source": [
    "conf_matrix = metrics.confusion_matrix(Y_val.argmax(axis = 1), model_best.predict(X_val).argmax(axis = 1))\n",
    "print_cm(conf_matrix, list(dict_valores.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 754ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     benigno       0.78      0.75      0.76        28\n",
      " seguimiento       0.33      0.50      0.40         4\n",
      "     maligno       0.74      0.70      0.72        20\n",
      "\n",
      "    accuracy                           0.71        52\n",
      "   macro avg       0.62      0.65      0.63        52\n",
      "weighted avg       0.73      0.71      0.72        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classif_report = metrics.classification_report(Y_val.argmax(axis = 1), model_best.predict(X_val).argmax(axis = 1),\n",
    "                                               target_names = list(dict_valores.keys()))\n",
    "print(classif_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_best_CC/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_best_CC/assets\n"
     ]
    }
   ],
   "source": [
    "file_path = './model_best_' + vista\n",
    "K.models.save_model(model_best, file_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
