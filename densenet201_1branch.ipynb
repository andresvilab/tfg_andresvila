{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dpJp_QlaKt_X"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "opIGkDVFLTxH"
   },
   "outputs": [],
   "source": [
    "vista = 'CC' ## 'CC' o 'MLO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yDmco7yQLWMQ"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, Y):\n",
    "    \"\"\"\n",
    "    Pre-processes the data for the model\n",
    "        - X is a numpy.ndarray of shape (m, 1024, 1024, 3) containing\n",
    "         the mammography, where m is the number of data points\n",
    "        - Y is a numpy.ndarray of shape (m,) containing\n",
    "         the Bi-Rads labels for X\n",
    "    Returns:\n",
    "        - X_p is a numpy.ndarray containing the preprocessed X\n",
    "        - Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    X_p = K.applications.densenet.preprocess_input(X)\n",
    "\n",
    "    Y_p = K.utils.to_categorical(Y, 3)\n",
    "\n",
    "    return X_p, Y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FacbWZE3LaZl"
   },
   "outputs": [],
   "source": [
    "df_INbreast_train = pd.read_pickle('/workspace/container_0/andres/data/df_INbreast_train.pkl')\n",
    "df_INbreast_val = pd.read_pickle('/workspace/container_0/andres/data/df_INbreast_val.pkl')\n",
    "\n",
    "if vista == 'CC':\n",
    "    df_INbreast_train = df_INbreast_train.drop(columns = ['MLO Image']).rename(columns = {'CC Image': 'Image'})\n",
    "    df_INbreast_val = df_INbreast_val.drop(columns = ['MLO Image']).rename(columns = {'CC Image': 'Image'})\n",
    "elif vista == 'MLO':\n",
    "    df_INbreast_train = df_INbreast_train.drop(columns = ['CC Image']).rename(columns = {'MLO Image': 'Image'})\n",
    "    df_INbreast_val = df_INbreast_val.drop(columns = ['CC Image']).rename(columns = {'MLO Image': 'Image'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fhw02QVrNDBP"
   },
   "outputs": [],
   "source": [
    "dict_valores = {'benigno': 0, 'seguimiento': 1, 'maligno': 2}\n",
    "Y_traintest = np.array(df_INbreast_train['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_traintest = np.array(df_INbreast_train['Image'].tolist())\n",
    "Y_val = np.array(df_INbreast_val['Bi-Rads'].map(dict_valores).tolist())\n",
    "X_val = np.array(df_INbreast_val['Image'].tolist())\n",
    "X_val, Y_val = preprocess_data(X_val, Y_val)\n",
    "del df_INbreast_train\n",
    "del df_INbreast_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5ZMfWXVRNHEq"
   },
   "outputs": [],
   "source": [
    "def DenseNet201_1Rama(vista, input_dim = 512, rand_seed = 13, learning_rate = 0.0001, momentum = 0.9):\n",
    "    \"\"\"\n",
    "    Define the DenseNet architecture and compile the model\n",
    "        - vista is a mammogram view we want to train\n",
    "        - input_dim is the size of the mammogram in pixels\n",
    "        - rand_seed is a random seed number used during the fc layer initialization\n",
    "        - learning_rate is the learning rate used during the training\n",
    "        - momentum is the parameters that defines the momentun for the SGD optimizer\n",
    "    Returns:\n",
    "        - model_1rama is the output compiled DenseNet model\n",
    "    \"\"\"\n",
    "    # Definimos la architectura del modelo\n",
    "    densenet = K.applications.DenseNet201(\n",
    "        include_top = False,\n",
    "        weights = \"imagenet\",\n",
    "        input_tensor = None,\n",
    "        input_shape = (256, 256, 3),\n",
    "        pooling = 'avg'\n",
    "    )\n",
    "\n",
    "    densenet.trainable = True\n",
    "\n",
    "    # Entrenaremos solo el bloque de capas conv5, las demas las dejamos con los pesos preestablecidos de la DenseNet121\n",
    "    for layer in densenet.layers:\n",
    "        if 'conv5' in layer.name:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Deefinimos el tama침o de las im치genes de entrada.\n",
    "    input_img = K.Input(shape = (input_dim, input_dim, 3))\n",
    "    # Lambda que ajustar치 la imagenes a un tama침o de  256x256\n",
    "    preprocess = K.layers.Lambda(lambda x: tf.image.resize(x, (256, 256)), name = 'resize_' + vista)(input_img)\n",
    "\n",
    "    initializer = K.initializers.he_normal(seed = rand_seed)\n",
    "\n",
    "    fc_layer = densenet(inputs = preprocess)\n",
    "\n",
    "    fc_layer = K.layers.Dense(units = 3,\n",
    "                              activation = 'softmax',\n",
    "                              kernel_initializer = initializer\n",
    "                              )(fc_layer)\n",
    "\n",
    "    model_1rama = K.models.Model(inputs = input_img, outputs = fc_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    opt = K.optimizers.SGD(learning_rate = learning_rate, momentum = momentum)\n",
    "\n",
    "    model_1rama.compile(loss = 'categorical_crossentropy',\n",
    "                        optimizer = opt,\n",
    "                        metrics = ['accuracy'])\n",
    "\n",
    "    return model_1rama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxbDJlkxNKPJ",
    "outputId": "ef2b1451-d388-4ec0-ba88-e0486fd6d0c8"
   },
   "outputs": [],
   "source": [
    "# DenseNet201_1Rama(vista).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hDp_ZPrONO_8"
   },
   "outputs": [],
   "source": [
    "def part_traintest(X_traintest, Y_traintest, rand_seed = 13, frac_test = .2/.8):\n",
    "    \"\"\"\n",
    "    Function that makes a partition for training and testing from the original dataset\n",
    "        - X_traintest is the array of images from the original dataset\n",
    "        - Y_traintest is the array of labels from the original dataset\n",
    "        - rand_seed is a random seed number used during the sampling\n",
    "        - frac_test is the fraction of cases used in the test subset\n",
    "    Returns:\n",
    "        - X_train is the train array of images\n",
    "        - Y_train is the train array of labels\n",
    "        - X_test is the test array of images\n",
    "        - Y_test is the test array of labels\n",
    "    \"\"\"\n",
    "    np.random.seed(rand_seed)\n",
    "    index_test = np.array([], dtype = 'int')\n",
    "\n",
    "    for i in np.unique(Y_traintest):\n",
    "        index_test = np.append(index_test,\n",
    "                               np.random.choice(list(np.where(Y_traintest == i)[0]), size = int(np.where(Y_traintest == i)[0].shape[0]*frac_test), replace = False))\n",
    "\n",
    "    index_test = [int(x) for x in index_test]\n",
    "    print(index_test)\n",
    "    X_train = np.delete(X_traintest, index_test, axis = 0)\n",
    "\n",
    "    Y_train = np.delete(Y_traintest, index_test)\n",
    "    X_test = np.take(X_traintest, index_test, axis = 0)\n",
    "    Y_test = np.take(Y_traintest, index_test)\n",
    "#     print(X_train)\n",
    "#     print(Y_train)\n",
    "#     print(Y_traintest)\n",
    "    X_train, Y_train = preprocess_data(X_train, Y_train)\n",
    "    X_test, Y_test = preprocess_data(X_test, Y_test)\n",
    "\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-Z-b6SEdNRsZ"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "no_epochs = 300\n",
    "input_dim = X_traintest.shape[1]\n",
    "rand_seed = 2021\n",
    "n_folds = 3\n",
    "frac_test = .2/.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kFogoCuWNT5R"
   },
   "outputs": [],
   "source": [
    "label, counts = np.unique(Y_traintest, return_counts = True)\n",
    "class_weight = {}\n",
    "for lab, con in zip(label, counts):\n",
    "  class_weight.update({lab: round(max(counts)/con, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MhD1kj9jNWRU"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(factor = 0.5, patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlN-yfIuNL1m",
    "outputId": "4f123c6d-c5fd-4f0d-89d4-bedc079e9c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for combination 1/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 2s 0us/step\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 20s 638ms/step - loss: 2.2539 - accuracy: 0.3529 - val_loss: 1.3755 - val_accuracy: 0.1923\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3646 - accuracy: 0.6372 - val_loss: 0.8356 - val_accuracy: 0.6538\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.9505 - accuracy: 0.6634 - val_loss: 0.8729 - val_accuracy: 0.6154\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5425 - accuracy: 0.8752 - val_loss: 0.7027 - val_accuracy: 0.6923\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2645 - accuracy: 0.9798 - val_loss: 0.7077 - val_accuracy: 0.6731\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2179 - accuracy: 0.9554 - val_loss: 0.6733 - val_accuracy: 0.7115\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0907 - accuracy: 0.9965 - val_loss: 0.7219 - val_accuracy: 0.6731\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0533 - accuracy: 0.9932 - val_loss: 0.9614 - val_accuracy: 0.5577\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.7308\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.7308\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.6538\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.6538\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.8826 - val_accuracy: 0.6346\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.8083 - val_accuracy: 0.6538\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.8566 - val_accuracy: 0.6538\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.8493 - val_accuracy: 0.6538\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.8467 - val_accuracy: 0.6346\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8786 - val_accuracy: 0.6346\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8422 - val_accuracy: 0.6346\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.8436 - val_accuracy: 0.6346\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8412 - val_accuracy: 0.6154\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.8468 - val_accuracy: 0.6346\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8402 - val_accuracy: 0.6154\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.8409 - val_accuracy: 0.6346\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.8372 - val_accuracy: 0.6346\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 374ms/step - loss: 3.0791 - accuracy: 0.2948 - val_loss: 1.0419 - val_accuracy: 0.5385\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3346 - accuracy: 0.6481 - val_loss: 0.9629 - val_accuracy: 0.5385\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.8617 - accuracy: 0.8397 - val_loss: 1.0137 - val_accuracy: 0.4423\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.5771 - accuracy: 0.8054 - val_loss: 0.8847 - val_accuracy: 0.5769\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2688 - accuracy: 0.9640 - val_loss: 1.1423 - val_accuracy: 0.5577\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1665 - accuracy: 0.9982 - val_loss: 0.8141 - val_accuracy: 0.6346\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1097 - accuracy: 0.9975 - val_loss: 1.0267 - val_accuracy: 0.5962\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.6346\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.8683 - val_accuracy: 0.7115\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.7308\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.0239 - accuracy: 0.9988 - val_loss: 1.2400 - val_accuracy: 0.6538\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.8146 - val_accuracy: 0.7115\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.7115\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.8216 - val_accuracy: 0.7115\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.7115\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8372 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.8685 - val_accuracy: 0.6731\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.8532 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.7308\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8265 - val_accuracy: 0.7500\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.7500\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8264 - val_accuracy: 0.7500\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.7500\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.7500\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.8130 - val_accuracy: 0.7500\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.7500\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.7692\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.7692\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.7692\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.7692\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.79; accuracy of 75.0%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 12s 372ms/step - loss: 2.0771 - accuracy: 0.3840 - val_loss: 1.0234 - val_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 1.4360 - accuracy: 0.6382 - val_loss: 0.9658 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.2764 - accuracy: 0.5729 - val_loss: 0.8770 - val_accuracy: 0.6346\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.6399 - accuracy: 0.8480 - val_loss: 0.8221 - val_accuracy: 0.6154\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 0.3601 - accuracy: 0.9066 - val_loss: 0.9052 - val_accuracy: 0.6538\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4808 - accuracy: 0.8477 - val_loss: 1.1857 - val_accuracy: 0.4038\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1960 - accuracy: 0.9328 - val_loss: 0.7576 - val_accuracy: 0.6923\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0564 - accuracy: 0.9982 - val_loss: 1.2617 - val_accuracy: 0.4615\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0917 - accuracy: 0.9828 - val_loss: 1.1756 - val_accuracy: 0.5385\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.7696 - val_accuracy: 0.7115\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.7115\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.8026 - val_accuracy: 0.7500\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.7500\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 2s 169ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.8516 - val_accuracy: 0.7500\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8657 - val_accuracy: 0.7500\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.7308\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.7692\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.9153 - val_accuracy: 0.7692\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9223 - val_accuracy: 0.7692\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.7692\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.7692\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9498 - val_accuracy: 0.7500\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9543 - val_accuracy: 0.7500\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.7500\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.7500\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.7692\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.7692\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.97; accuracy of 53.85%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.79 - Accuracy: 0.75%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.97 - Accuracy: 0.54%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0):\n",
      "> Accuracy: 0.67 (+- 0.1)\n",
      "> Loss: 0.84 (+- 0.09)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 2/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 14s 413ms/step - loss: 2.1430 - accuracy: 0.3481 - val_loss: 0.8443 - val_accuracy: 0.5962\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 1.3713 - accuracy: 0.6262 - val_loss: 0.9881 - val_accuracy: 0.5385\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.8349 - accuracy: 0.7556 - val_loss: 0.9938 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3958 - accuracy: 0.9094 - val_loss: 1.4941 - val_accuracy: 0.3846\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3315 - accuracy: 0.9046 - val_loss: 1.3877 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2214 - accuracy: 0.9653 - val_loss: 0.6557 - val_accuracy: 0.7500\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0588 - accuracy: 0.9920 - val_loss: 0.9548 - val_accuracy: 0.6154\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.7451 - val_accuracy: 0.7500\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.9268 - val_accuracy: 0.5962\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.7926 - val_accuracy: 0.7115\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 0.6731\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8039 - val_accuracy: 0.6731\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8268 - val_accuracy: 0.6731\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.6731\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.6731\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8813 - val_accuracy: 0.6923\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8829 - val_accuracy: 0.6731\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8920 - val_accuracy: 0.6731\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9059 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9128 - val_accuracy: 0.6731\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.6538\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9233 - val_accuracy: 0.6346\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9275 - val_accuracy: 0.6346\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9323 - val_accuracy: 0.6538\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9398 - val_accuracy: 0.6538\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.81; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 15s 399ms/step - loss: 3.0851 - accuracy: 0.3089 - val_loss: 0.9453 - val_accuracy: 0.5577\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 1.4739 - accuracy: 0.5914 - val_loss: 0.9612 - val_accuracy: 0.5385\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.8866 - accuracy: 0.7653 - val_loss: 1.0601 - val_accuracy: 0.4615\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.4762 - accuracy: 0.8977 - val_loss: 0.8615 - val_accuracy: 0.5577\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2517 - accuracy: 0.9287 - val_loss: 0.8530 - val_accuracy: 0.6346\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.1272 - accuracy: 0.9785 - val_loss: 1.2064 - val_accuracy: 0.5577\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.1076 - accuracy: 0.9791 - val_loss: 0.7350 - val_accuracy: 0.6538\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.0394 - val_accuracy: 0.6538\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.6731\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8178 - val_accuracy: 0.6731\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9375 - val_accuracy: 0.7308\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.7308\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8884 - val_accuracy: 0.7308\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9113 - val_accuracy: 0.7500\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9169 - val_accuracy: 0.7308\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9212 - val_accuracy: 0.7308\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.7500\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.8637 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8690 - val_accuracy: 0.7115\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8650 - val_accuracy: 0.7308\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8820 - val_accuracy: 0.7308\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.7115\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8811 - val_accuracy: 0.7115\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8772 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.6923\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8573 - val_accuracy: 0.6923\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8551 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.91; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 14s 489ms/step - loss: 3.8687 - accuracy: 0.2766 - val_loss: 1.0292 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.6204 - accuracy: 0.6067 - val_loss: 1.0986 - val_accuracy: 0.3654\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 1.1828 - accuracy: 0.6999 - val_loss: 0.8014 - val_accuracy: 0.6154\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.7279 - accuracy: 0.7886 - val_loss: 1.2099 - val_accuracy: 0.4423\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3402 - accuracy: 0.9310 - val_loss: 2.4607 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5341 - accuracy: 0.8590 - val_loss: 8.7557 - val_accuracy: 0.2115\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.6880 - accuracy: 0.8461 - val_loss: 13.1429 - val_accuracy: 0.1731\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3279 - accuracy: 0.9350 - val_loss: 8.4167 - val_accuracy: 0.2500\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2479 - accuracy: 0.9216 - val_loss: 1.0443 - val_accuracy: 0.6538\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0994 - accuracy: 0.9816 - val_loss: 1.1195 - val_accuracy: 0.6731\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 1.0198 - val_accuracy: 0.7308\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.7115\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0376 - accuracy: 0.9982 - val_loss: 1.3699 - val_accuracy: 0.6346\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0698 - accuracy: 0.9828 - val_loss: 1.3420 - val_accuracy: 0.6154\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.6923\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.0258 - val_accuracy: 0.6923\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.7308\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.9791 - val_accuracy: 0.7308\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.7115\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.7308\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.7308\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.7500\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.9848 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.92; accuracy of 48.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.81 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.91 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.92 - Accuracy: 0.48%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0.5):\n",
      "> Accuracy: 0.59 (+- 0.08)\n",
      "> Loss: 0.88 (+- 0.05)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 3/9 ...\n",
      "Learning rate = 0.01\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 15s 617ms/step - loss: 2.2581 - accuracy: 0.4352 - val_loss: 2.0554 - val_accuracy: 0.2308\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 2.1108 - accuracy: 0.4185 - val_loss: 0.9071 - val_accuracy: 0.6346\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 1.2955 - accuracy: 0.5822 - val_loss: 9.6236 - val_accuracy: 0.3846\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 1.1323 - accuracy: 0.7006 - val_loss: 25.6151 - val_accuracy: 0.3846\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.7479 - accuracy: 0.7377 - val_loss: 28.4025 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.6002 - accuracy: 0.8532 - val_loss: 88.5456 - val_accuracy: 0.3846\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4824 - accuracy: 0.8751 - val_loss: 36.2165 - val_accuracy: 0.4231\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.5484 - accuracy: 0.7430 - val_loss: 50.2671 - val_accuracy: 0.4038\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3806 - accuracy: 0.8759 - val_loss: 27.1042 - val_accuracy: 0.5192\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1891 - accuracy: 0.9239 - val_loss: 40.7769 - val_accuracy: 0.4038\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0607 - accuracy: 0.9817 - val_loss: 25.8221 - val_accuracy: 0.4615\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0970 - accuracy: 0.9730 - val_loss: 4.5642 - val_accuracy: 0.6154\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3760 - accuracy: 0.8911 - val_loss: 38.7225 - val_accuracy: 0.3846\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1555 - accuracy: 0.9507 - val_loss: 80.1966 - val_accuracy: 0.3846\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0560 - accuracy: 0.9828 - val_loss: 38.3328 - val_accuracy: 0.3846\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0697 - accuracy: 0.9731 - val_loss: 27.9504 - val_accuracy: 0.3846\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 21.6842 - val_accuracy: 0.4038\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 15.9031 - val_accuracy: 0.4615\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 11.8829 - val_accuracy: 0.5385\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0320 - accuracy: 0.9885 - val_loss: 10.3544 - val_accuracy: 0.5385\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 8.4622 - val_accuracy: 0.5962\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 6.7304 - val_accuracy: 0.5962\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.93; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 14s 545ms/step - loss: 2.5989 - accuracy: 0.3366 - val_loss: 1.6017 - val_accuracy: 0.0769\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.8634 - accuracy: 0.2858 - val_loss: 2.8805 - val_accuracy: 0.0769\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.5237 - accuracy: 0.4608 - val_loss: 9.8381 - val_accuracy: 0.0769\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.3427 - accuracy: 0.7525 - val_loss: 7.8342 - val_accuracy: 0.4808\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.9137 - accuracy: 0.7481 - val_loss: 3.1243 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.6609 - accuracy: 0.8448 - val_loss: 377.0871 - val_accuracy: 0.0769\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.1236 - accuracy: 0.7330 - val_loss: 31.4135 - val_accuracy: 0.3846\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.8958 - accuracy: 0.7271 - val_loss: 37.7461 - val_accuracy: 0.3846\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4300 - accuracy: 0.9038 - val_loss: 26.2453 - val_accuracy: 0.3846\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1274 - accuracy: 0.9700 - val_loss: 19.0171 - val_accuracy: 0.3846\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.2712 - accuracy: 0.9071 - val_loss: 10.6332 - val_accuracy: 0.4038\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3685 - accuracy: 0.8970 - val_loss: 28.2988 - val_accuracy: 0.3846\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2280 - accuracy: 0.9478 - val_loss: 10.2779 - val_accuracy: 0.4423\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0765 - accuracy: 0.9795 - val_loss: 3.7791 - val_accuracy: 0.5000\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 2.2788 - val_accuracy: 0.5385\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0914 - accuracy: 0.9720 - val_loss: 2.1722 - val_accuracy: 0.5577\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 1.5570 - val_accuracy: 0.6538\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.6994 - val_accuracy: 0.6538\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.7263 - val_accuracy: 0.6538\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 1.5296 - val_accuracy: 0.6538\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1671 - val_accuracy: 0.6923\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.1313 - val_accuracy: 0.6731\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1366 - val_accuracy: 0.6731\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1432 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1310 - val_accuracy: 0.7308\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1475 - val_accuracy: 0.7308\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1823 - val_accuracy: 0.7115\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1413 - val_accuracy: 0.7308\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1280 - val_accuracy: 0.7500\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1298 - val_accuracy: 0.7500\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1374 - val_accuracy: 0.7500\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1472 - val_accuracy: 0.7308\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.1622 - val_accuracy: 0.7308\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.1949 - val_accuracy: 0.7500\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2072 - val_accuracy: 0.7500\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0088 - accuracy: 0.9946 - val_loss: 1.1740 - val_accuracy: 0.7500\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 9.6964e-04 - accuracy: 1.0000 - val_loss: 1.1645 - val_accuracy: 0.7692\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1629 - val_accuracy: 0.7692\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1623 - val_accuracy: 0.7692\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.1625 - val_accuracy: 0.7692\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1621 - val_accuracy: 0.7692\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1619 - val_accuracy: 0.7500\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1618 - val_accuracy: 0.7692\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1627 - val_accuracy: 0.7692\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 7.8285e-04 - accuracy: 1.0000 - val_loss: 1.1623 - val_accuracy: 0.7692\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1619 - val_accuracy: 0.7500\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1614 - val_accuracy: 0.7500\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1609 - val_accuracy: 0.7500\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1611 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 1.21; accuracy of 75.0%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 14s 383ms/step - loss: 2.1308 - accuracy: 0.4030 - val_loss: 1.7089 - val_accuracy: 0.3846\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.6721 - accuracy: 0.4631 - val_loss: 4.1130 - val_accuracy: 0.0769\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.3239 - accuracy: 0.5014 - val_loss: 8.2787 - val_accuracy: 0.1731\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.1775 - accuracy: 0.7183 - val_loss: 6.3153 - val_accuracy: 0.1731\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.9952 - accuracy: 0.8327 - val_loss: 8.7629 - val_accuracy: 0.1923\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2886 - accuracy: 0.9295 - val_loss: 116.4596 - val_accuracy: 0.0769\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3340 - accuracy: 0.9068 - val_loss: 56.1723 - val_accuracy: 0.0769\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3992 - accuracy: 0.8641 - val_loss: 20.7173 - val_accuracy: 0.1538\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1485 - accuracy: 0.9763 - val_loss: 4.5463 - val_accuracy: 0.4615\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3306 - accuracy: 0.9196 - val_loss: 12.5734 - val_accuracy: 0.2115\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.3681 - accuracy: 0.9264 - val_loss: 3.3595 - val_accuracy: 0.5385\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2765 - accuracy: 0.9407 - val_loss: 2.8917 - val_accuracy: 0.4423\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2313 - accuracy: 0.9435 - val_loss: 2.2935 - val_accuracy: 0.6154\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 2.0505 - val_accuracy: 0.6731\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1816 - accuracy: 0.9760 - val_loss: 1.5986 - val_accuracy: 0.6923\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0542 - accuracy: 0.9841 - val_loss: 1.4083 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.3957 - val_accuracy: 0.7308\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0495 - accuracy: 0.9638 - val_loss: 1.7341 - val_accuracy: 0.6731\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.5079 - val_accuracy: 0.7308\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.5313 - val_accuracy: 0.7308\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5503 - val_accuracy: 0.7308\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5574 - val_accuracy: 0.7308\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5608 - val_accuracy: 0.7308\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5624 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5502 - val_accuracy: 0.6923\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.5452 - val_accuracy: 0.7115\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5319 - val_accuracy: 0.7115\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5276 - val_accuracy: 0.7115\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5264 - val_accuracy: 0.7115\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5275 - val_accuracy: 0.7115\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5287 - val_accuracy: 0.7115\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5310 - val_accuracy: 0.7115\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5335 - val_accuracy: 0.7308\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5355 - val_accuracy: 0.7308\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5378 - val_accuracy: 0.7308\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5448 - val_accuracy: 0.7115\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5489 - val_accuracy: 0.7115\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 1.45; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.93 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 1.21 - Accuracy: 0.75%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 1.45 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.01, mtm = 0.9):\n",
      "> Accuracy: 0.69 (+- 0.06)\n",
      "> Loss: 1.2 (+- 0.21)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 4/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 15s 398ms/step - loss: 1.6271 - accuracy: 0.4300 - val_loss: 1.1666 - val_accuracy: 0.3077\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 1.4504 - accuracy: 0.4723 - val_loss: 1.0906 - val_accuracy: 0.4231\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.4579 - accuracy: 0.6258 - val_loss: 1.0496 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3688 - accuracy: 0.6245 - val_loss: 0.9035 - val_accuracy: 0.6154\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.1743 - accuracy: 0.8224 - val_loss: 0.8903 - val_accuracy: 0.6154\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.0265 - accuracy: 0.8493 - val_loss: 0.9760 - val_accuracy: 0.6154\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.0763 - accuracy: 0.7825 - val_loss: 0.8343 - val_accuracy: 0.6731\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.8139 - accuracy: 0.8719 - val_loss: 0.8826 - val_accuracy: 0.5962\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.8161 - accuracy: 0.8921 - val_loss: 0.7941 - val_accuracy: 0.6731\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.7425 - accuracy: 0.8910 - val_loss: 0.7906 - val_accuracy: 0.5769\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.6403 - accuracy: 0.9182 - val_loss: 0.7653 - val_accuracy: 0.6346\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.6248 - accuracy: 0.8812 - val_loss: 0.7345 - val_accuracy: 0.6923\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.5550 - accuracy: 0.9211 - val_loss: 0.7385 - val_accuracy: 0.6538\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.5299 - accuracy: 0.9200 - val_loss: 0.7716 - val_accuracy: 0.5769\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.4657 - accuracy: 0.9126 - val_loss: 0.6966 - val_accuracy: 0.7308\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.4280 - accuracy: 0.9432 - val_loss: 0.7032 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.3642 - accuracy: 0.9749 - val_loss: 0.6908 - val_accuracy: 0.6923\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3295 - accuracy: 0.9675 - val_loss: 0.7068 - val_accuracy: 0.6731\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.3539 - accuracy: 0.9630 - val_loss: 0.7154 - val_accuracy: 0.6538\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3188 - accuracy: 0.9620 - val_loss: 0.6951 - val_accuracy: 0.6923\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.2745 - accuracy: 0.9914 - val_loss: 0.6853 - val_accuracy: 0.6923\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2500 - accuracy: 0.9920 - val_loss: 0.6828 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2565 - accuracy: 0.9913 - val_loss: 0.6859 - val_accuracy: 0.6923\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2046 - accuracy: 0.9932 - val_loss: 0.7062 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2163 - accuracy: 0.9957 - val_loss: 0.6830 - val_accuracy: 0.6923\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1817 - accuracy: 0.9932 - val_loss: 0.6857 - val_accuracy: 0.6923\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1900 - accuracy: 0.9967 - val_loss: 0.6749 - val_accuracy: 0.6923\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2356 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.6731\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1535 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.6731\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1415 - accuracy: 0.9982 - val_loss: 0.7465 - val_accuracy: 0.6538\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1352 - accuracy: 1.0000 - val_loss: 0.7041 - val_accuracy: 0.6923\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1187 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.6731\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.6923\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.6923\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1101 - accuracy: 1.0000 - val_loss: 0.6939 - val_accuracy: 0.6923\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.6923\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1070 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.6923\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1003 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.6923\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1003 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.6923\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.6923\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 0.6923\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1107 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.6923\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.6923\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0836 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.6923\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.6923\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1077 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.6923\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1057 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 14s 380ms/step - loss: 1.8113 - accuracy: 0.3301 - val_loss: 1.1344 - val_accuracy: 0.3269\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.5204 - accuracy: 0.5784 - val_loss: 1.1025 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.3661 - accuracy: 0.7162 - val_loss: 1.0795 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.2800 - accuracy: 0.7497 - val_loss: 1.0883 - val_accuracy: 0.4038\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.1118 - accuracy: 0.7857 - val_loss: 1.0702 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.0449 - accuracy: 0.8177 - val_loss: 0.9933 - val_accuracy: 0.5192\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.8742 - accuracy: 0.8743 - val_loss: 0.9816 - val_accuracy: 0.5192\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.8165 - accuracy: 0.8601 - val_loss: 0.9889 - val_accuracy: 0.5000\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7871 - accuracy: 0.8682 - val_loss: 0.9547 - val_accuracy: 0.5385\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.7026 - accuracy: 0.9025 - val_loss: 0.8948 - val_accuracy: 0.5962\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.6529 - accuracy: 0.8731 - val_loss: 0.8900 - val_accuracy: 0.5769\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.5318 - accuracy: 0.9613 - val_loss: 0.8773 - val_accuracy: 0.5577\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5469 - accuracy: 0.9663 - val_loss: 0.8403 - val_accuracy: 0.6346\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4282 - accuracy: 0.9866 - val_loss: 0.8089 - val_accuracy: 0.6731\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4250 - accuracy: 0.9799 - val_loss: 0.7956 - val_accuracy: 0.6731\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.3861 - accuracy: 0.9593 - val_loss: 0.8073 - val_accuracy: 0.6538\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.3858 - accuracy: 0.9500 - val_loss: 0.7952 - val_accuracy: 0.6154\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.3285 - accuracy: 0.9709 - val_loss: 0.7866 - val_accuracy: 0.6731\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2953 - accuracy: 0.9917 - val_loss: 0.7798 - val_accuracy: 0.6346\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2849 - accuracy: 0.9946 - val_loss: 0.7668 - val_accuracy: 0.6731\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.2867 - accuracy: 0.9982 - val_loss: 0.7626 - val_accuracy: 0.6923\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2665 - accuracy: 0.9818 - val_loss: 0.7623 - val_accuracy: 0.6538\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.7617 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.2021 - accuracy: 1.0000 - val_loss: 0.7545 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1888 - accuracy: 0.9964 - val_loss: 0.7773 - val_accuracy: 0.5962\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1762 - accuracy: 0.9975 - val_loss: 0.7526 - val_accuracy: 0.6731\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1713 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.6923\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1451 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.7115\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1461 - accuracy: 0.9913 - val_loss: 0.7479 - val_accuracy: 0.6923\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 0.7469 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1411 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.6731\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1268 - accuracy: 1.0000 - val_loss: 0.7539 - val_accuracy: 0.6538\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.6731\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1229 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.6731\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0997 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.6538\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0858 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.6731\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.6731\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.7579 - val_accuracy: 0.6731\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1259 - accuracy: 1.0000 - val_loss: 0.7601 - val_accuracy: 0.6731\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.6731\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.6731\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.7573 - val_accuracy: 0.6731\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 0.7569 - val_accuracy: 0.6731\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.6731\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.6731\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.7584 - val_accuracy: 0.6731\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.7584 - val_accuracy: 0.6731\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.74; accuracy of 69.23%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 14s 400ms/step - loss: 2.0313 - accuracy: 0.2401 - val_loss: 0.9902 - val_accuracy: 0.5385\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.5106 - accuracy: 0.6079 - val_loss: 1.0530 - val_accuracy: 0.4231\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 1.5550 - accuracy: 0.4792 - val_loss: 0.9219 - val_accuracy: 0.5769\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3695 - accuracy: 0.7490 - val_loss: 0.9513 - val_accuracy: 0.6154\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.1508 - accuracy: 0.7311 - val_loss: 0.9130 - val_accuracy: 0.6346\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.0676 - accuracy: 0.7892 - val_loss: 0.8699 - val_accuracy: 0.5962\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.9518 - accuracy: 0.8142 - val_loss: 0.8750 - val_accuracy: 0.6346\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.8242 - accuracy: 0.8693 - val_loss: 0.8292 - val_accuracy: 0.6731\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7039 - accuracy: 0.8925 - val_loss: 0.8580 - val_accuracy: 0.6538\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.7052 - accuracy: 0.8656 - val_loss: 0.8057 - val_accuracy: 0.6923\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5837 - accuracy: 0.8914 - val_loss: 0.7807 - val_accuracy: 0.7115\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.5598 - accuracy: 0.9186 - val_loss: 0.7682 - val_accuracy: 0.7115\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5106 - accuracy: 0.9496 - val_loss: 0.7346 - val_accuracy: 0.7308\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4570 - accuracy: 0.9396 - val_loss: 0.7450 - val_accuracy: 0.7115\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.4471 - accuracy: 0.9417 - val_loss: 0.7249 - val_accuracy: 0.7115\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4493 - accuracy: 0.9388 - val_loss: 0.7212 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3770 - accuracy: 0.9503 - val_loss: 0.7152 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3347 - accuracy: 0.9708 - val_loss: 0.7071 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2848 - accuracy: 0.9914 - val_loss: 0.7028 - val_accuracy: 0.7115\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.2957 - accuracy: 0.9684 - val_loss: 0.7035 - val_accuracy: 0.7115\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2940 - accuracy: 0.9803 - val_loss: 0.7002 - val_accuracy: 0.7115\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2450 - accuracy: 0.9810 - val_loss: 0.6992 - val_accuracy: 0.7115\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2137 - accuracy: 0.9871 - val_loss: 0.7018 - val_accuracy: 0.7308\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2086 - accuracy: 0.9982 - val_loss: 0.6984 - val_accuracy: 0.7308\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2226 - accuracy: 0.9988 - val_loss: 0.7042 - val_accuracy: 0.7500\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1956 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.7308\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1613 - accuracy: 0.9913 - val_loss: 0.7017 - val_accuracy: 0.7308\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1408 - accuracy: 0.9957 - val_loss: 0.7066 - val_accuracy: 0.7500\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1406 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.7500\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1199 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.7500\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1404 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.7308\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1663 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1276 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.7500\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1132 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1117 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.7500\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1304 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.7500\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1065 - accuracy: 0.9988 - val_loss: 0.7015 - val_accuracy: 0.7500\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1429 - accuracy: 0.9828 - val_loss: 0.7008 - val_accuracy: 0.7500\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.7500\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.7500\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.7500\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1045 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.7500\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.77; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.74 - Accuracy: 0.69%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.77 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0):\n",
      "> Accuracy: 0.66 (+- 0.02)\n",
      "> Loss: 0.76 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 5/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 384ms/step - loss: 1.6502 - accuracy: 0.4203 - val_loss: 1.2003 - val_accuracy: 0.2885\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 2s 258ms/step - loss: 1.4319 - accuracy: 0.4713 - val_loss: 1.0889 - val_accuracy: 0.4231\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 1.2639 - accuracy: 0.6318 - val_loss: 0.8733 - val_accuracy: 0.6538\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.9922 - accuracy: 0.8298 - val_loss: 0.8845 - val_accuracy: 0.6154\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7940 - accuracy: 0.8770 - val_loss: 0.8409 - val_accuracy: 0.6923\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.6541 - accuracy: 0.9101 - val_loss: 0.7634 - val_accuracy: 0.6538\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5833 - accuracy: 0.8994 - val_loss: 0.7424 - val_accuracy: 0.7308\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4738 - accuracy: 0.9488 - val_loss: 0.7159 - val_accuracy: 0.7500\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4102 - accuracy: 0.9411 - val_loss: 0.7002 - val_accuracy: 0.7500\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3960 - accuracy: 0.9455 - val_loss: 0.6930 - val_accuracy: 0.7500\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2664 - accuracy: 0.9952 - val_loss: 0.7002 - val_accuracy: 0.6923\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2473 - accuracy: 0.9892 - val_loss: 0.6972 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2210 - accuracy: 0.9907 - val_loss: 0.7400 - val_accuracy: 0.5577\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1849 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.7308\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1693 - accuracy: 0.9828 - val_loss: 0.7183 - val_accuracy: 0.6154\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1680 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.6346\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1299 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.6346\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.6346\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1102 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.5962\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.6346\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.7392 - val_accuracy: 0.6346\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.7402 - val_accuracy: 0.6346\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.7279 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.6538\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.6346\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.7344 - val_accuracy: 0.6154\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.6154\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.6154\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.6154\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.6154\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.7293 - val_accuracy: 0.6538\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.6538\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.6538\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.7161 - val_accuracy: 0.6538\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.77; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 386ms/step - loss: 1.9230 - accuracy: 0.2642 - val_loss: 1.0369 - val_accuracy: 0.4615\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 1.4792 - accuracy: 0.6757 - val_loss: 1.2021 - val_accuracy: 0.4808\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.2286 - accuracy: 0.7065 - val_loss: 0.9253 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.0717 - accuracy: 0.8147 - val_loss: 0.9534 - val_accuracy: 0.5192\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.7220 - accuracy: 0.8949 - val_loss: 1.0049 - val_accuracy: 0.5385\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.6370 - accuracy: 0.9390 - val_loss: 0.8759 - val_accuracy: 0.6154\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4852 - accuracy: 0.9607 - val_loss: 0.8721 - val_accuracy: 0.5769\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4164 - accuracy: 0.9722 - val_loss: 0.8690 - val_accuracy: 0.6154\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3578 - accuracy: 0.9882 - val_loss: 0.8525 - val_accuracy: 0.6346\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3518 - accuracy: 0.9759 - val_loss: 0.8097 - val_accuracy: 0.6346\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2782 - accuracy: 0.9940 - val_loss: 0.8623 - val_accuracy: 0.5962\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.2603 - accuracy: 1.0000 - val_loss: 0.7836 - val_accuracy: 0.6923\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2395 - accuracy: 0.9828 - val_loss: 0.7688 - val_accuracy: 0.6731\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1650 - accuracy: 1.0000 - val_loss: 0.7602 - val_accuracy: 0.7115\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.1468 - accuracy: 1.0000 - val_loss: 0.8354 - val_accuracy: 0.6154\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1618 - accuracy: 1.0000 - val_loss: 0.8278 - val_accuracy: 0.5769\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1479 - accuracy: 0.9967 - val_loss: 0.7578 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.7489 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.6538\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.7685 - val_accuracy: 0.6731\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 0.6538\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.7712 - val_accuracy: 0.6538\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.7803 - val_accuracy: 0.6538\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.7785 - val_accuracy: 0.6538\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.7800 - val_accuracy: 0.6346\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.7829 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.6538\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.6731\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 0.6731\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.6731\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.7809 - val_accuracy: 0.6731\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.7814 - val_accuracy: 0.6923\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.7836 - val_accuracy: 0.6923\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.7852 - val_accuracy: 0.6923\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.6923\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.6731\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.6538\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.76; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 385ms/step - loss: 2.1224 - accuracy: 0.1938 - val_loss: 0.9557 - val_accuracy: 0.6346\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.4858 - accuracy: 0.6045 - val_loss: 0.9193 - val_accuracy: 0.5577\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.1398 - accuracy: 0.7613 - val_loss: 0.9121 - val_accuracy: 0.6346\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.9168 - accuracy: 0.8504 - val_loss: 0.9791 - val_accuracy: 0.5385\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7848 - accuracy: 0.8865 - val_loss: 0.7779 - val_accuracy: 0.7115\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7275 - accuracy: 0.8554 - val_loss: 0.7649 - val_accuracy: 0.6538\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5677 - accuracy: 0.8872 - val_loss: 0.7452 - val_accuracy: 0.7115\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.4900 - accuracy: 0.9359 - val_loss: 0.7241 - val_accuracy: 0.7115\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3987 - accuracy: 0.9132 - val_loss: 0.7132 - val_accuracy: 0.7500\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3819 - accuracy: 0.9424 - val_loss: 0.6952 - val_accuracy: 0.7115\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2914 - accuracy: 0.9759 - val_loss: 0.6964 - val_accuracy: 0.6923\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2705 - accuracy: 0.9888 - val_loss: 0.6928 - val_accuracy: 0.7308\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.1984 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.7885\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1837 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.6923\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1546 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.7308\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1399 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.7308\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1340 - accuracy: 0.9957 - val_loss: 0.6966 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1320 - accuracy: 0.9913 - val_loss: 0.7014 - val_accuracy: 0.7500\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.7017 - val_accuracy: 0.7500\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1030 - accuracy: 1.0000 - val_loss: 0.7077 - val_accuracy: 0.7308\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.7500\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.7088 - val_accuracy: 0.7500\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.7500\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.7169 - val_accuracy: 0.7500\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.7203 - val_accuracy: 0.7500\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.7500\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.7500\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.7500\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.7500\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.7500\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.7500\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.7283 - val_accuracy: 0.7500\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.7500\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.7500\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.78; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.77 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.76 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.78 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.5):\n",
      "> Accuracy: 0.66 (+- 0.02)\n",
      "> Loss: 0.77 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 6/9 ...\n",
      "Learning rate = 0.001\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 15s 412ms/step - loss: 1.8098 - accuracy: 0.3507 - val_loss: 1.3020 - val_accuracy: 0.1154\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.1971 - accuracy: 0.6239 - val_loss: 0.9293 - val_accuracy: 0.5769\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.6065 - accuracy: 0.8526 - val_loss: 0.8247 - val_accuracy: 0.6731\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2897 - accuracy: 0.9454 - val_loss: 0.7038 - val_accuracy: 0.6923\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1588 - accuracy: 0.9913 - val_loss: 0.7287 - val_accuracy: 0.6346\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.6923\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.0677 - accuracy: 0.9885 - val_loss: 0.6408 - val_accuracy: 0.6923\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.6607 - val_accuracy: 0.6923\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.6538\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.6731\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.6923\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.8363 - val_accuracy: 0.6538\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.6154\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.8400 - val_accuracy: 0.5962\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8506 - val_accuracy: 0.5769\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.5962\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9163 - val_accuracy: 0.5962\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.5962\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.5962\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.6154\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.8858 - val_accuracy: 0.6346\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.6346\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8825 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8833 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8792 - val_accuracy: 0.6731\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8782 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 16s 679ms/step - loss: 2.0321 - accuracy: 0.3244 - val_loss: 1.2447 - val_accuracy: 0.1923\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.3399 - accuracy: 0.5157 - val_loss: 1.0727 - val_accuracy: 0.5385\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.8094 - accuracy: 0.8116 - val_loss: 0.8473 - val_accuracy: 0.6346\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3600 - accuracy: 0.9519 - val_loss: 0.8220 - val_accuracy: 0.6731\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.1917 - accuracy: 0.9765 - val_loss: 0.8491 - val_accuracy: 0.6731\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1490 - accuracy: 0.9852 - val_loss: 0.7940 - val_accuracy: 0.5962\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.7551 - val_accuracy: 0.6923\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.7115\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.7725 - val_accuracy: 0.6923\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.8068 - val_accuracy: 0.6154\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.8219 - val_accuracy: 0.6346\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.6731\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.7910 - val_accuracy: 0.6923\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.7755 - val_accuracy: 0.6538\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7802 - val_accuracy: 0.6538\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7707 - val_accuracy: 0.6538\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7709 - val_accuracy: 0.6923\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.7758 - val_accuracy: 0.6731\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.6731\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.6731\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.6731\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.8092 - val_accuracy: 0.6731\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.8117 - val_accuracy: 0.6731\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8177 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8215 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8219 - val_accuracy: 0.6731\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8226 - val_accuracy: 0.6731\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.81; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 397ms/step - loss: 1.7670 - accuracy: 0.4142 - val_loss: 1.0387 - val_accuracy: 0.4423\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.2079 - accuracy: 0.7519 - val_loss: 1.2596 - val_accuracy: 0.2500\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.7526 - accuracy: 0.7692 - val_loss: 0.8324 - val_accuracy: 0.6154\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3923 - accuracy: 0.9309 - val_loss: 0.6853 - val_accuracy: 0.7308\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2019 - accuracy: 0.9846 - val_loss: 0.7431 - val_accuracy: 0.6923\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1402 - accuracy: 0.9718 - val_loss: 1.2322 - val_accuracy: 0.5962\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.7295 - val_accuracy: 0.7500\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.6923\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.6923\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.8825 - val_accuracy: 0.6923\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.8668 - val_accuracy: 0.7500\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.8941 - val_accuracy: 0.7500\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.9612 - val_accuracy: 0.7308\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.7500\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.7500\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9281 - val_accuracy: 0.7500\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.9358 - val_accuracy: 0.7500\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.7500\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.9540 - val_accuracy: 0.7500\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.7500\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.7500\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.9369 - val_accuracy: 0.7500\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9337 - val_accuracy: 0.7500\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.81; accuracy of 61.54%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.81 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.81 - Accuracy: 0.62%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.001, mtm = 0.9):\n",
      "> Accuracy: 0.67 (+- 0.05)\n",
      "> Loss: 0.79 (+- 0.03)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 7/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 14s 410ms/step - loss: 1.9325 - accuracy: 0.3360 - val_loss: 1.1078 - val_accuracy: 0.3654\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.8944 - accuracy: 0.3225 - val_loss: 1.1017 - val_accuracy: 0.3846\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 1.7757 - accuracy: 0.4150 - val_loss: 1.0936 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.5315 - accuracy: 0.4729 - val_loss: 1.0910 - val_accuracy: 0.3654\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.7561 - accuracy: 0.4502 - val_loss: 1.0833 - val_accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.6094 - accuracy: 0.4182 - val_loss: 1.0770 - val_accuracy: 0.3846\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.5812 - accuracy: 0.4390 - val_loss: 1.0737 - val_accuracy: 0.4231\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.6869 - accuracy: 0.4911 - val_loss: 1.0652 - val_accuracy: 0.4615\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 1.5146 - accuracy: 0.4560 - val_loss: 1.0607 - val_accuracy: 0.4423\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.5781 - accuracy: 0.4457 - val_loss: 1.0582 - val_accuracy: 0.4231\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.5545 - accuracy: 0.4783 - val_loss: 1.0525 - val_accuracy: 0.4423\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.5009 - accuracy: 0.5180 - val_loss: 1.0492 - val_accuracy: 0.5000\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.4383 - accuracy: 0.5832 - val_loss: 1.0458 - val_accuracy: 0.4808\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 1.5880 - accuracy: 0.5853 - val_loss: 1.0404 - val_accuracy: 0.4615\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.5952 - accuracy: 0.6221 - val_loss: 1.0331 - val_accuracy: 0.4808\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.4598 - accuracy: 0.6482 - val_loss: 1.0309 - val_accuracy: 0.4808\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 1.4875 - accuracy: 0.6029 - val_loss: 1.0245 - val_accuracy: 0.4808\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.4232 - accuracy: 0.6551 - val_loss: 1.0220 - val_accuracy: 0.4808\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.3502 - accuracy: 0.6469 - val_loss: 1.0215 - val_accuracy: 0.4808\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.4168 - accuracy: 0.6952 - val_loss: 1.0158 - val_accuracy: 0.4808\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.3887 - accuracy: 0.6861 - val_loss: 1.0111 - val_accuracy: 0.4808\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.3874 - accuracy: 0.7083 - val_loss: 1.0079 - val_accuracy: 0.5000\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.3315 - accuracy: 0.7294 - val_loss: 1.0052 - val_accuracy: 0.5192\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 1.3406 - accuracy: 0.6772 - val_loss: 1.0012 - val_accuracy: 0.5192\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.4278 - accuracy: 0.7426 - val_loss: 0.9951 - val_accuracy: 0.5192\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.3784 - accuracy: 0.7506 - val_loss: 0.9890 - val_accuracy: 0.5192\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.2624 - accuracy: 0.7342 - val_loss: 0.9866 - val_accuracy: 0.5192\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.2411 - accuracy: 0.7453 - val_loss: 0.9858 - val_accuracy: 0.5385\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3104 - accuracy: 0.7641 - val_loss: 0.9808 - val_accuracy: 0.5385\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.3310 - accuracy: 0.7518 - val_loss: 0.9770 - val_accuracy: 0.5385\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.1778 - accuracy: 0.7764 - val_loss: 0.9758 - val_accuracy: 0.5385\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.2695 - accuracy: 0.7641 - val_loss: 0.9699 - val_accuracy: 0.5385\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.2911 - accuracy: 0.7957 - val_loss: 0.9650 - val_accuracy: 0.5385\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.2222 - accuracy: 0.7802 - val_loss: 0.9611 - val_accuracy: 0.5385\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.1616 - accuracy: 0.7869 - val_loss: 0.9623 - val_accuracy: 0.5577\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.1944 - accuracy: 0.7848 - val_loss: 0.9567 - val_accuracy: 0.5577\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.2497 - accuracy: 0.8113 - val_loss: 0.9493 - val_accuracy: 0.5577\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.1946 - accuracy: 0.7609 - val_loss: 0.9446 - val_accuracy: 0.5577\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.2439 - accuracy: 0.7767 - val_loss: 0.9389 - val_accuracy: 0.5577\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.1360 - accuracy: 0.8493 - val_loss: 0.9369 - val_accuracy: 0.5962\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.1551 - accuracy: 0.8239 - val_loss: 0.9330 - val_accuracy: 0.5962\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0575 - accuracy: 0.7961 - val_loss: 0.9308 - val_accuracy: 0.5962\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0873 - accuracy: 0.8051 - val_loss: 0.9252 - val_accuracy: 0.6154\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.0731 - accuracy: 0.8153 - val_loss: 0.9223 - val_accuracy: 0.6154\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0212 - accuracy: 0.8169 - val_loss: 0.9208 - val_accuracy: 0.6346\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.0590 - accuracy: 0.8676 - val_loss: 0.9158 - val_accuracy: 0.6346\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.0803 - accuracy: 0.8239 - val_loss: 0.9113 - val_accuracy: 0.6346\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0367 - accuracy: 0.8323 - val_loss: 0.9070 - val_accuracy: 0.6346\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0123 - accuracy: 0.8602 - val_loss: 0.9024 - val_accuracy: 0.6346\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.0724 - accuracy: 0.8214 - val_loss: 0.8983 - val_accuracy: 0.6346\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.0365 - accuracy: 0.8261 - val_loss: 0.8947 - val_accuracy: 0.6346\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.1174 - accuracy: 0.8254 - val_loss: 0.8901 - val_accuracy: 0.6346\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.0254 - accuracy: 0.8784 - val_loss: 0.8859 - val_accuracy: 0.6346\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.0595 - accuracy: 0.8299 - val_loss: 0.8812 - val_accuracy: 0.6346\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.9924 - accuracy: 0.8622 - val_loss: 0.8793 - val_accuracy: 0.6346\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.9930 - accuracy: 0.8839 - val_loss: 0.8754 - val_accuracy: 0.6346\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.9653 - accuracy: 0.8722 - val_loss: 0.8717 - val_accuracy: 0.6346\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.0079 - accuracy: 0.8720 - val_loss: 0.8685 - val_accuracy: 0.6346\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.9513 - accuracy: 0.8669 - val_loss: 0.8658 - val_accuracy: 0.6346\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.9132 - accuracy: 0.8673 - val_loss: 0.8652 - val_accuracy: 0.6538\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.9162 - accuracy: 0.8504 - val_loss: 0.8604 - val_accuracy: 0.6538\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.8871 - accuracy: 0.8781 - val_loss: 0.8585 - val_accuracy: 0.6538\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.8880 - accuracy: 0.9018 - val_loss: 0.8580 - val_accuracy: 0.6538\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.8535 - accuracy: 0.9211 - val_loss: 0.8553 - val_accuracy: 0.6538\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0116 - accuracy: 0.8879 - val_loss: 0.8508 - val_accuracy: 0.6538\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.8577 - accuracy: 0.8819 - val_loss: 0.8461 - val_accuracy: 0.6538\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.8042 - accuracy: 0.8856 - val_loss: 0.8431 - val_accuracy: 0.6538\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.8888 - accuracy: 0.9098 - val_loss: 0.8397 - val_accuracy: 0.6538\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.8235 - accuracy: 0.8981 - val_loss: 0.8363 - val_accuracy: 0.6538\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.8481 - accuracy: 0.8586 - val_loss: 0.8328 - val_accuracy: 0.6538\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.9379 - accuracy: 0.8488 - val_loss: 0.8278 - val_accuracy: 0.6538\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.8221 - accuracy: 0.8945 - val_loss: 0.8259 - val_accuracy: 0.6538\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.8224 - accuracy: 0.8980 - val_loss: 0.8226 - val_accuracy: 0.6538\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.8095 - accuracy: 0.9003 - val_loss: 0.8209 - val_accuracy: 0.6538\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.8168 - accuracy: 0.8806 - val_loss: 0.8172 - val_accuracy: 0.6538\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.8071 - accuracy: 0.8879 - val_loss: 0.8145 - val_accuracy: 0.6538\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.7888 - accuracy: 0.8783 - val_loss: 0.8121 - val_accuracy: 0.6538\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.7895 - accuracy: 0.8985 - val_loss: 0.8106 - val_accuracy: 0.6538\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.7644 - accuracy: 0.8615 - val_loss: 0.8075 - val_accuracy: 0.6538\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.7740 - accuracy: 0.9150 - val_loss: 0.8032 - val_accuracy: 0.6538\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.7268 - accuracy: 0.9087 - val_loss: 0.8010 - val_accuracy: 0.6538\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.7560 - accuracy: 0.8614 - val_loss: 0.7982 - val_accuracy: 0.6538\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.7666 - accuracy: 0.9080 - val_loss: 0.7962 - val_accuracy: 0.6538\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7160 - accuracy: 0.9225 - val_loss: 0.7940 - val_accuracy: 0.6538\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7351 - accuracy: 0.8975 - val_loss: 0.7939 - val_accuracy: 0.6538\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6872 - accuracy: 0.9105 - val_loss: 0.7932 - val_accuracy: 0.6538\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7482 - accuracy: 0.8854 - val_loss: 0.7900 - val_accuracy: 0.6538\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6663 - accuracy: 0.9384 - val_loss: 0.7865 - val_accuracy: 0.6538\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.7268 - accuracy: 0.9147 - val_loss: 0.7822 - val_accuracy: 0.6538\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.7073 - accuracy: 0.9130 - val_loss: 0.7808 - val_accuracy: 0.6538\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.6721 - accuracy: 0.9287 - val_loss: 0.7796 - val_accuracy: 0.6538\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.7411 - accuracy: 0.9188 - val_loss: 0.7781 - val_accuracy: 0.6538\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.6683 - accuracy: 0.9437 - val_loss: 0.7776 - val_accuracy: 0.6538\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6844 - accuracy: 0.8957 - val_loss: 0.7748 - val_accuracy: 0.6538\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.6581 - accuracy: 0.9097 - val_loss: 0.7726 - val_accuracy: 0.6538\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.6342 - accuracy: 0.9269 - val_loss: 0.7698 - val_accuracy: 0.6731\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.6505 - accuracy: 0.9028 - val_loss: 0.7677 - val_accuracy: 0.6731\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.6560 - accuracy: 0.8936 - val_loss: 0.7656 - val_accuracy: 0.6731\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6415 - accuracy: 0.9536 - val_loss: 0.7637 - val_accuracy: 0.6731\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6244 - accuracy: 0.9406 - val_loss: 0.7612 - val_accuracy: 0.6731\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5814 - accuracy: 0.9318 - val_loss: 0.7594 - val_accuracy: 0.6731\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.6397 - accuracy: 0.9460 - val_loss: 0.7580 - val_accuracy: 0.6731\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6237 - accuracy: 0.8839 - val_loss: 0.7570 - val_accuracy: 0.6731\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.5862 - accuracy: 0.9062 - val_loss: 0.7549 - val_accuracy: 0.6731\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6076 - accuracy: 0.9004 - val_loss: 0.7542 - val_accuracy: 0.6731\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.5541 - accuracy: 0.9246 - val_loss: 0.7531 - val_accuracy: 0.6538\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5788 - accuracy: 0.9102 - val_loss: 0.7519 - val_accuracy: 0.6538\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5946 - accuracy: 0.9365 - val_loss: 0.7505 - val_accuracy: 0.6538\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5857 - accuracy: 0.9376 - val_loss: 0.7490 - val_accuracy: 0.6731\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5549 - accuracy: 0.9309 - val_loss: 0.7479 - val_accuracy: 0.6731\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5615 - accuracy: 0.9264 - val_loss: 0.7456 - val_accuracy: 0.6731\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4989 - accuracy: 0.9611 - val_loss: 0.7441 - val_accuracy: 0.6731\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5447 - accuracy: 0.9362 - val_loss: 0.7434 - val_accuracy: 0.6731\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5456 - accuracy: 0.9337 - val_loss: 0.7416 - val_accuracy: 0.6731\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5146 - accuracy: 0.9382 - val_loss: 0.7397 - val_accuracy: 0.6731\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5476 - accuracy: 0.9335 - val_loss: 0.7385 - val_accuracy: 0.6731\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5094 - accuracy: 0.9589 - val_loss: 0.7364 - val_accuracy: 0.6731\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.5128 - accuracy: 0.9433 - val_loss: 0.7346 - val_accuracy: 0.6731\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5372 - accuracy: 0.9186 - val_loss: 0.7333 - val_accuracy: 0.6731\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5224 - accuracy: 0.9164 - val_loss: 0.7315 - val_accuracy: 0.6731\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5057 - accuracy: 0.9351 - val_loss: 0.7303 - val_accuracy: 0.6923\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4910 - accuracy: 0.9492 - val_loss: 0.7287 - val_accuracy: 0.6923\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4827 - accuracy: 0.9401 - val_loss: 0.7269 - val_accuracy: 0.6731\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4744 - accuracy: 0.9409 - val_loss: 0.7243 - val_accuracy: 0.6731\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4921 - accuracy: 0.9276 - val_loss: 0.7239 - val_accuracy: 0.6731\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4838 - accuracy: 0.9520 - val_loss: 0.7229 - val_accuracy: 0.6731\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4875 - accuracy: 0.9170 - val_loss: 0.7214 - val_accuracy: 0.6731\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4638 - accuracy: 0.9679 - val_loss: 0.7200 - val_accuracy: 0.6731\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4937 - accuracy: 0.9273 - val_loss: 0.7183 - val_accuracy: 0.6731\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4614 - accuracy: 0.9264 - val_loss: 0.7183 - val_accuracy: 0.6731\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4543 - accuracy: 0.9651 - val_loss: 0.7179 - val_accuracy: 0.6731\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4640 - accuracy: 0.9409 - val_loss: 0.7172 - val_accuracy: 0.6923\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.4935 - accuracy: 0.8992 - val_loss: 0.7159 - val_accuracy: 0.6731\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4409 - accuracy: 0.9444 - val_loss: 0.7153 - val_accuracy: 0.6731\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4303 - accuracy: 0.9437 - val_loss: 0.7136 - val_accuracy: 0.6731\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4187 - accuracy: 0.9534 - val_loss: 0.7116 - val_accuracy: 0.6731\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4689 - accuracy: 0.9507 - val_loss: 0.7109 - val_accuracy: 0.6731\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4715 - accuracy: 0.9442 - val_loss: 0.7102 - val_accuracy: 0.6731\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4520 - accuracy: 0.9571 - val_loss: 0.7089 - val_accuracy: 0.6731\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.4860 - accuracy: 0.9282 - val_loss: 0.7071 - val_accuracy: 0.6731\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.4113 - accuracy: 0.9543 - val_loss: 0.7065 - val_accuracy: 0.6731\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4305 - accuracy: 0.9546 - val_loss: 0.7069 - val_accuracy: 0.6731\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4072 - accuracy: 0.9354 - val_loss: 0.7076 - val_accuracy: 0.6731\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4218 - accuracy: 0.9559 - val_loss: 0.7072 - val_accuracy: 0.6731\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4053 - accuracy: 0.9598 - val_loss: 0.7066 - val_accuracy: 0.6731\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.4040 - accuracy: 0.9737 - val_loss: 0.7040 - val_accuracy: 0.6731\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.4107 - accuracy: 0.9353 - val_loss: 0.7029 - val_accuracy: 0.6731\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.4078 - accuracy: 0.9688 - val_loss: 0.7020 - val_accuracy: 0.6731\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4128 - accuracy: 0.9628 - val_loss: 0.7012 - val_accuracy: 0.6731\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.4187 - accuracy: 0.9778 - val_loss: 0.7006 - val_accuracy: 0.6731\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4008 - accuracy: 0.9477 - val_loss: 0.6991 - val_accuracy: 0.6731\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3864 - accuracy: 0.9768 - val_loss: 0.6984 - val_accuracy: 0.6731\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.4011 - accuracy: 0.9504 - val_loss: 0.6977 - val_accuracy: 0.6731\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3872 - accuracy: 0.9467 - val_loss: 0.6969 - val_accuracy: 0.6731\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3793 - accuracy: 0.9584 - val_loss: 0.6965 - val_accuracy: 0.6731\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3651 - accuracy: 0.9489 - val_loss: 0.6954 - val_accuracy: 0.6731\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3823 - accuracy: 0.9982 - val_loss: 0.6957 - val_accuracy: 0.6731\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3385 - accuracy: 0.9717 - val_loss: 0.6950 - val_accuracy: 0.6731\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3657 - accuracy: 0.9591 - val_loss: 0.6938 - val_accuracy: 0.6731\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3794 - accuracy: 0.9749 - val_loss: 0.6923 - val_accuracy: 0.6731\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4060 - accuracy: 0.9606 - val_loss: 0.6919 - val_accuracy: 0.6731\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.3830 - accuracy: 0.9848 - val_loss: 0.6917 - val_accuracy: 0.6731\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3444 - accuracy: 0.9758 - val_loss: 0.6920 - val_accuracy: 0.6731\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3565 - accuracy: 0.9748 - val_loss: 0.6915 - val_accuracy: 0.6731\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.3838 - accuracy: 0.9590 - val_loss: 0.6905 - val_accuracy: 0.6731\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.3190 - accuracy: 0.9687 - val_loss: 0.6888 - val_accuracy: 0.6731\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3722 - accuracy: 0.9868 - val_loss: 0.6890 - val_accuracy: 0.6731\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3326 - accuracy: 0.9635 - val_loss: 0.6874 - val_accuracy: 0.6731\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.3745 - accuracy: 0.9289 - val_loss: 0.6878 - val_accuracy: 0.6731\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3254 - accuracy: 0.9694 - val_loss: 0.6871 - val_accuracy: 0.6731\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3298 - accuracy: 0.9761 - val_loss: 0.6863 - val_accuracy: 0.6731\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3119 - accuracy: 0.9895 - val_loss: 0.6876 - val_accuracy: 0.6731\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3142 - accuracy: 0.9827 - val_loss: 0.6872 - val_accuracy: 0.6731\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2971 - accuracy: 0.9892 - val_loss: 0.6861 - val_accuracy: 0.6731\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2943 - accuracy: 0.9949 - val_loss: 0.6851 - val_accuracy: 0.6731\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2990 - accuracy: 0.9895 - val_loss: 0.6843 - val_accuracy: 0.6731\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3161 - accuracy: 0.9822 - val_loss: 0.6835 - val_accuracy: 0.6731\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2914 - accuracy: 0.9971 - val_loss: 0.6842 - val_accuracy: 0.6731\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3111 - accuracy: 0.9507 - val_loss: 0.6822 - val_accuracy: 0.6731\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3113 - accuracy: 0.9761 - val_loss: 0.6828 - val_accuracy: 0.6731\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3083 - accuracy: 0.9921 - val_loss: 0.6823 - val_accuracy: 0.6731\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3386 - accuracy: 0.9752 - val_loss: 0.6835 - val_accuracy: 0.6731\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3034 - accuracy: 0.9735 - val_loss: 0.6825 - val_accuracy: 0.6731\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2725 - accuracy: 0.9786 - val_loss: 0.6816 - val_accuracy: 0.6731\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3003 - accuracy: 0.9568 - val_loss: 0.6806 - val_accuracy: 0.6731\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3042 - accuracy: 0.9644 - val_loss: 0.6803 - val_accuracy: 0.6731\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.2925 - accuracy: 0.9802 - val_loss: 0.6793 - val_accuracy: 0.6731\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2642 - accuracy: 0.9950 - val_loss: 0.6788 - val_accuracy: 0.6731\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3054 - accuracy: 0.9798 - val_loss: 0.6783 - val_accuracy: 0.6731\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3077 - accuracy: 0.9975 - val_loss: 0.6777 - val_accuracy: 0.6731\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3154 - accuracy: 0.9791 - val_loss: 0.6785 - val_accuracy: 0.6731\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2951 - accuracy: 0.9982 - val_loss: 0.6775 - val_accuracy: 0.6731\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3150 - accuracy: 0.9712 - val_loss: 0.6777 - val_accuracy: 0.6731\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2711 - accuracy: 0.9924 - val_loss: 0.6790 - val_accuracy: 0.6731\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3020 - accuracy: 0.9712 - val_loss: 0.6783 - val_accuracy: 0.6731\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2543 - accuracy: 0.9803 - val_loss: 0.6781 - val_accuracy: 0.6731\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2536 - accuracy: 0.9913 - val_loss: 0.6777 - val_accuracy: 0.6731\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.2647 - accuracy: 0.9971 - val_loss: 0.6775 - val_accuracy: 0.6731\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2789 - accuracy: 0.9913 - val_loss: 0.6778 - val_accuracy: 0.6731\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2677 - accuracy: 0.9878 - val_loss: 0.6772 - val_accuracy: 0.6731\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.6731\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2607 - accuracy: 0.9946 - val_loss: 0.6773 - val_accuracy: 0.6731\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2607 - accuracy: 0.9946 - val_loss: 0.6769 - val_accuracy: 0.6731\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2606 - accuracy: 0.9885 - val_loss: 0.6769 - val_accuracy: 0.6731\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2858 - accuracy: 0.9785 - val_loss: 0.6765 - val_accuracy: 0.6731\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2462 - accuracy: 0.9885 - val_loss: 0.6763 - val_accuracy: 0.6731\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2561 - accuracy: 0.9885 - val_loss: 0.6762 - val_accuracy: 0.6731\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2261 - accuracy: 0.9885 - val_loss: 0.6759 - val_accuracy: 0.6731\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2551 - accuracy: 0.9763 - val_loss: 0.6756 - val_accuracy: 0.6731\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2787 - accuracy: 0.9967 - val_loss: 0.6758 - val_accuracy: 0.6731\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2539 - accuracy: 0.9904 - val_loss: 0.6753 - val_accuracy: 0.6731\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2941 - accuracy: 0.9885 - val_loss: 0.6754 - val_accuracy: 0.6731\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2229 - accuracy: 0.9975 - val_loss: 0.6749 - val_accuracy: 0.6731\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2375 - accuracy: 0.9975 - val_loss: 0.6750 - val_accuracy: 0.6731\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2536 - accuracy: 0.9932 - val_loss: 0.6747 - val_accuracy: 0.6731\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2429 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.6731\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2426 - accuracy: 0.9982 - val_loss: 0.6744 - val_accuracy: 0.6731\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2586 - accuracy: 0.9975 - val_loss: 0.6743 - val_accuracy: 0.6731\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2415 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.6731\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2466 - accuracy: 0.9913 - val_loss: 0.6740 - val_accuracy: 0.6731\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2388 - accuracy: 1.0000 - val_loss: 0.6736 - val_accuracy: 0.6731\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2386 - accuracy: 0.9914 - val_loss: 0.6736 - val_accuracy: 0.6923\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2264 - accuracy: 0.9967 - val_loss: 0.6738 - val_accuracy: 0.6923\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.2561 - accuracy: 0.9975 - val_loss: 0.6736 - val_accuracy: 0.6923\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2049 - accuracy: 0.9975 - val_loss: 0.6735 - val_accuracy: 0.6923\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2169 - accuracy: 0.9932 - val_loss: 0.6733 - val_accuracy: 0.6923\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2141 - accuracy: 0.9957 - val_loss: 0.6731 - val_accuracy: 0.6923\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2331 - accuracy: 0.9899 - val_loss: 0.6731 - val_accuracy: 0.6923\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2605 - accuracy: 0.9913 - val_loss: 0.6730 - val_accuracy: 0.6923\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2279 - accuracy: 0.9885 - val_loss: 0.6734 - val_accuracy: 0.6923\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2533 - accuracy: 0.9885 - val_loss: 0.6730 - val_accuracy: 0.6923\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2351 - accuracy: 0.9940 - val_loss: 0.6727 - val_accuracy: 0.6923\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2356 - accuracy: 0.9885 - val_loss: 0.6725 - val_accuracy: 0.6923\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.6923\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2741 - accuracy: 0.9631 - val_loss: 0.6723 - val_accuracy: 0.6923\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2179 - accuracy: 0.9988 - val_loss: 0.6724 - val_accuracy: 0.6923\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2041 - accuracy: 0.9975 - val_loss: 0.6725 - val_accuracy: 0.6923\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2150 - accuracy: 0.9741 - val_loss: 0.6724 - val_accuracy: 0.6923\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2329 - accuracy: 0.9878 - val_loss: 0.6725 - val_accuracy: 0.6923\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2634 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.6923\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.6722 - val_accuracy: 0.6923\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2218 - accuracy: 0.9967 - val_loss: 0.6721 - val_accuracy: 0.6923\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 0.2193 - accuracy: 0.9885 - val_loss: 0.6720 - val_accuracy: 0.6923\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.6923\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.6923\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2183 - accuracy: 0.9957 - val_loss: 0.6716 - val_accuracy: 0.6923\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2289 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.6923\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2001 - accuracy: 0.9975 - val_loss: 0.6717 - val_accuracy: 0.6923\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2144 - accuracy: 0.9867 - val_loss: 0.6718 - val_accuracy: 0.6923\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2525 - accuracy: 0.9656 - val_loss: 0.6715 - val_accuracy: 0.6923\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2518 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.6923\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2057 - accuracy: 0.9913 - val_loss: 0.6716 - val_accuracy: 0.6923\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2383 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.6923\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2134 - accuracy: 0.9982 - val_loss: 0.6715 - val_accuracy: 0.6923\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2163 - accuracy: 0.9975 - val_loss: 0.6715 - val_accuracy: 0.6923\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2168 - accuracy: 0.9834 - val_loss: 0.6715 - val_accuracy: 0.6923\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2105 - accuracy: 0.9913 - val_loss: 0.6714 - val_accuracy: 0.6923\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2074 - accuracy: 0.9957 - val_loss: 0.6713 - val_accuracy: 0.6923\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1991 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.6923\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2032 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.6923\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2015 - accuracy: 0.9967 - val_loss: 0.6711 - val_accuracy: 0.6923\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2079 - accuracy: 0.9942 - val_loss: 0.6710 - val_accuracy: 0.6923\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2334 - accuracy: 0.9928 - val_loss: 0.6710 - val_accuracy: 0.6923\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2231 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.6923\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2256 - accuracy: 0.9828 - val_loss: 0.6710 - val_accuracy: 0.6923\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2177 - accuracy: 0.9901 - val_loss: 0.6709 - val_accuracy: 0.6923\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2082 - accuracy: 0.9946 - val_loss: 0.6709 - val_accuracy: 0.6923\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2598 - accuracy: 0.9687 - val_loss: 0.6709 - val_accuracy: 0.6923\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2222 - accuracy: 0.9957 - val_loss: 0.6708 - val_accuracy: 0.6923\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2229 - accuracy: 0.9828 - val_loss: 0.6708 - val_accuracy: 0.6923\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2047 - accuracy: 1.0000 - val_loss: 0.6709 - val_accuracy: 0.6923\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2212 - accuracy: 0.9988 - val_loss: 0.6708 - val_accuracy: 0.6923\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2401 - accuracy: 0.9928 - val_loss: 0.6708 - val_accuracy: 0.6923\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.6709 - val_accuracy: 0.6923\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2077 - accuracy: 0.9870 - val_loss: 0.6711 - val_accuracy: 0.6923\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2067 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.6923\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2186 - accuracy: 0.9957 - val_loss: 0.6711 - val_accuracy: 0.6923\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2050 - accuracy: 0.9967 - val_loss: 0.6710 - val_accuracy: 0.6923\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2086 - accuracy: 0.9885 - val_loss: 0.6710 - val_accuracy: 0.6923\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.6923\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2305 - accuracy: 0.9913 - val_loss: 0.6711 - val_accuracy: 0.6923\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2358 - accuracy: 0.9828 - val_loss: 0.6712 - val_accuracy: 0.6923\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1849 - accuracy: 0.9957 - val_loss: 0.6711 - val_accuracy: 0.6923\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2327 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.6923\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2187 - accuracy: 0.9852 - val_loss: 0.6712 - val_accuracy: 0.6923\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2283 - accuracy: 0.9946 - val_loss: 0.6712 - val_accuracy: 0.6923\n",
      "Epoch 287/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.6923\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1906 - accuracy: 0.9913 - val_loss: 0.6712 - val_accuracy: 0.6923\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.6923\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2166 - accuracy: 0.9795 - val_loss: 0.6711 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 63.46%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 12s 390ms/step - loss: 1.8965 - accuracy: 0.3709 - val_loss: 1.1959 - val_accuracy: 0.2500\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.7996 - accuracy: 0.3059 - val_loss: 1.1949 - val_accuracy: 0.1923\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 1.8923 - accuracy: 0.3534 - val_loss: 1.1920 - val_accuracy: 0.2115\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.6017 - accuracy: 0.4243 - val_loss: 1.1939 - val_accuracy: 0.2115\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.7648 - accuracy: 0.4018 - val_loss: 1.1886 - val_accuracy: 0.1923\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.5594 - accuracy: 0.4047 - val_loss: 1.1870 - val_accuracy: 0.2115\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.7599 - accuracy: 0.3708 - val_loss: 1.1793 - val_accuracy: 0.1923\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.5930 - accuracy: 0.4270 - val_loss: 1.1768 - val_accuracy: 0.2115\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.6318 - accuracy: 0.4238 - val_loss: 1.1695 - val_accuracy: 0.1923\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.5554 - accuracy: 0.4981 - val_loss: 1.1607 - val_accuracy: 0.1923\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.4631 - accuracy: 0.5205 - val_loss: 1.1594 - val_accuracy: 0.2115\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.5814 - accuracy: 0.5419 - val_loss: 1.1498 - val_accuracy: 0.2308\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.5447 - accuracy: 0.5164 - val_loss: 1.1430 - val_accuracy: 0.2308\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.4561 - accuracy: 0.5503 - val_loss: 1.1352 - val_accuracy: 0.2885\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.6332 - accuracy: 0.6266 - val_loss: 1.1232 - val_accuracy: 0.3462\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.4104 - accuracy: 0.6210 - val_loss: 1.1198 - val_accuracy: 0.3462\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.4704 - accuracy: 0.6521 - val_loss: 1.1123 - val_accuracy: 0.3846\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 1.3727 - accuracy: 0.6979 - val_loss: 1.1077 - val_accuracy: 0.3846\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.3588 - accuracy: 0.6436 - val_loss: 1.1034 - val_accuracy: 0.3654\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3777 - accuracy: 0.6873 - val_loss: 1.0970 - val_accuracy: 0.3846\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.4295 - accuracy: 0.7139 - val_loss: 1.0898 - val_accuracy: 0.4038\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.3460 - accuracy: 0.6970 - val_loss: 1.0854 - val_accuracy: 0.4038\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.3520 - accuracy: 0.7182 - val_loss: 1.0803 - val_accuracy: 0.4038\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.2581 - accuracy: 0.7439 - val_loss: 1.0761 - val_accuracy: 0.4231\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.3317 - accuracy: 0.7047 - val_loss: 1.0731 - val_accuracy: 0.4231\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.3574 - accuracy: 0.7324 - val_loss: 1.0659 - val_accuracy: 0.4423\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3262 - accuracy: 0.7013 - val_loss: 1.0601 - val_accuracy: 0.4615\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.2924 - accuracy: 0.7478 - val_loss: 1.0542 - val_accuracy: 0.4615\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.2643 - accuracy: 0.7425 - val_loss: 1.0480 - val_accuracy: 0.4808\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.3254 - accuracy: 0.7887 - val_loss: 1.0395 - val_accuracy: 0.4808\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.2284 - accuracy: 0.8385 - val_loss: 1.0362 - val_accuracy: 0.4808\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.1875 - accuracy: 0.8164 - val_loss: 1.0326 - val_accuracy: 0.4808\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 1.1890 - accuracy: 0.7089 - val_loss: 1.0342 - val_accuracy: 0.4808\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.2048 - accuracy: 0.8127 - val_loss: 1.0265 - val_accuracy: 0.5000\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.1113 - accuracy: 0.7959 - val_loss: 1.0214 - val_accuracy: 0.5000\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.2213 - accuracy: 0.7899 - val_loss: 1.0144 - val_accuracy: 0.5192\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0954 - accuracy: 0.7926 - val_loss: 1.0157 - val_accuracy: 0.5000\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.1974 - accuracy: 0.7926 - val_loss: 1.0089 - val_accuracy: 0.5192\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.0628 - accuracy: 0.8004 - val_loss: 1.0087 - val_accuracy: 0.5192\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.1145 - accuracy: 0.8117 - val_loss: 1.0062 - val_accuracy: 0.5385\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.0122 - accuracy: 0.8193 - val_loss: 1.0041 - val_accuracy: 0.5385\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.0856 - accuracy: 0.8280 - val_loss: 0.9977 - val_accuracy: 0.5385\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.0629 - accuracy: 0.8314 - val_loss: 0.9940 - val_accuracy: 0.5385\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.0735 - accuracy: 0.8323 - val_loss: 0.9881 - val_accuracy: 0.5385\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.0419 - accuracy: 0.8155 - val_loss: 0.9827 - val_accuracy: 0.5385\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 1.1358 - accuracy: 0.8294 - val_loss: 0.9789 - val_accuracy: 0.5385\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.0104 - accuracy: 0.8293 - val_loss: 0.9768 - val_accuracy: 0.5385\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.0009 - accuracy: 0.7992 - val_loss: 0.9749 - val_accuracy: 0.5385\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.0035 - accuracy: 0.8370 - val_loss: 0.9729 - val_accuracy: 0.5385\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.9894 - accuracy: 0.8442 - val_loss: 0.9729 - val_accuracy: 0.5385\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.9901 - accuracy: 0.7929 - val_loss: 0.9668 - val_accuracy: 0.5385\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0238 - accuracy: 0.8458 - val_loss: 0.9599 - val_accuracy: 0.5385\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.0202 - accuracy: 0.8375 - val_loss: 0.9538 - val_accuracy: 0.5577\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.9535 - accuracy: 0.8838 - val_loss: 0.9490 - val_accuracy: 0.5577\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.9116 - accuracy: 0.8583 - val_loss: 0.9495 - val_accuracy: 0.5385\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.9600 - accuracy: 0.8900 - val_loss: 0.9434 - val_accuracy: 0.5769\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.9531 - accuracy: 0.8503 - val_loss: 0.9380 - val_accuracy: 0.5769\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.8555 - accuracy: 0.8687 - val_loss: 0.9364 - val_accuracy: 0.5577\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.8929 - accuracy: 0.8437 - val_loss: 0.9359 - val_accuracy: 0.5577\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.8738 - accuracy: 0.8818 - val_loss: 0.9319 - val_accuracy: 0.5769\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.9326 - accuracy: 0.8818 - val_loss: 0.9284 - val_accuracy: 0.5769\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.9390 - accuracy: 0.8817 - val_loss: 0.9252 - val_accuracy: 0.5769\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.8561 - accuracy: 0.9014 - val_loss: 0.9248 - val_accuracy: 0.5769\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.8859 - accuracy: 0.8676 - val_loss: 0.9221 - val_accuracy: 0.5769\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.8347 - accuracy: 0.9056 - val_loss: 0.9209 - val_accuracy: 0.5769\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.8745 - accuracy: 0.8637 - val_loss: 0.9172 - val_accuracy: 0.5577\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.8372 - accuracy: 0.8865 - val_loss: 0.9148 - val_accuracy: 0.5769\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.8584 - accuracy: 0.8564 - val_loss: 0.9111 - val_accuracy: 0.5769\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.8667 - accuracy: 0.9161 - val_loss: 0.9068 - val_accuracy: 0.5769\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.8463 - accuracy: 0.8540 - val_loss: 0.9033 - val_accuracy: 0.5962\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.8021 - accuracy: 0.8670 - val_loss: 0.9046 - val_accuracy: 0.5962\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.8169 - accuracy: 0.8858 - val_loss: 0.9021 - val_accuracy: 0.5962\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.7866 - accuracy: 0.8841 - val_loss: 0.8992 - val_accuracy: 0.5962\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7662 - accuracy: 0.9053 - val_loss: 0.9003 - val_accuracy: 0.5962\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.7887 - accuracy: 0.8701 - val_loss: 0.9002 - val_accuracy: 0.5962\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.6995 - accuracy: 0.9166 - val_loss: 0.8964 - val_accuracy: 0.5962\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.7678 - accuracy: 0.8893 - val_loss: 0.8916 - val_accuracy: 0.5962\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7207 - accuracy: 0.8851 - val_loss: 0.8921 - val_accuracy: 0.5962\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7291 - accuracy: 0.9033 - val_loss: 0.8898 - val_accuracy: 0.5962\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.7108 - accuracy: 0.9256 - val_loss: 0.8872 - val_accuracy: 0.5962\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7292 - accuracy: 0.9054 - val_loss: 0.8847 - val_accuracy: 0.5962\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.7141 - accuracy: 0.8823 - val_loss: 0.8808 - val_accuracy: 0.5962\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.7477 - accuracy: 0.9017 - val_loss: 0.8768 - val_accuracy: 0.6154\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.6818 - accuracy: 0.9263 - val_loss: 0.8760 - val_accuracy: 0.6154\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6598 - accuracy: 0.9392 - val_loss: 0.8747 - val_accuracy: 0.6154\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.6753 - accuracy: 0.9415 - val_loss: 0.8727 - val_accuracy: 0.6154\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.6501 - accuracy: 0.9349 - val_loss: 0.8694 - val_accuracy: 0.6154\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6769 - accuracy: 0.8662 - val_loss: 0.8683 - val_accuracy: 0.6154\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6708 - accuracy: 0.9310 - val_loss: 0.8650 - val_accuracy: 0.6154\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6525 - accuracy: 0.9335 - val_loss: 0.8617 - val_accuracy: 0.6154\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.7663 - accuracy: 0.8964 - val_loss: 0.8625 - val_accuracy: 0.6154\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.6699 - accuracy: 0.9207 - val_loss: 0.8610 - val_accuracy: 0.6154\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.6586 - accuracy: 0.8992 - val_loss: 0.8587 - val_accuracy: 0.6154\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.6365 - accuracy: 0.9442 - val_loss: 0.8558 - val_accuracy: 0.6154\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5913 - accuracy: 0.9445 - val_loss: 0.8540 - val_accuracy: 0.6154\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.6065 - accuracy: 0.9203 - val_loss: 0.8522 - val_accuracy: 0.6154\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.6393 - accuracy: 0.8983 - val_loss: 0.8503 - val_accuracy: 0.6154\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.6168 - accuracy: 0.9296 - val_loss: 0.8470 - val_accuracy: 0.6154\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5656 - accuracy: 0.9545 - val_loss: 0.8463 - val_accuracy: 0.6154\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5488 - accuracy: 0.9689 - val_loss: 0.8455 - val_accuracy: 0.6154\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.6099 - accuracy: 0.9090 - val_loss: 0.8435 - val_accuracy: 0.6154\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.6217 - accuracy: 0.9147 - val_loss: 0.8408 - val_accuracy: 0.6346\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.6038 - accuracy: 0.9178 - val_loss: 0.8385 - val_accuracy: 0.6346\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.6041 - accuracy: 0.9040 - val_loss: 0.8365 - val_accuracy: 0.6346\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.5331 - accuracy: 0.9504 - val_loss: 0.8359 - val_accuracy: 0.6346\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.5899 - accuracy: 0.9365 - val_loss: 0.8340 - val_accuracy: 0.6346\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.5309 - accuracy: 0.9145 - val_loss: 0.8331 - val_accuracy: 0.6346\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.5729 - accuracy: 0.9258 - val_loss: 0.8298 - val_accuracy: 0.6346\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5683 - accuracy: 0.9358 - val_loss: 0.8285 - val_accuracy: 0.6346\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.5239 - accuracy: 0.9310 - val_loss: 0.8266 - val_accuracy: 0.6346\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4948 - accuracy: 0.9611 - val_loss: 0.8246 - val_accuracy: 0.6538\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5453 - accuracy: 0.9466 - val_loss: 0.8250 - val_accuracy: 0.6538\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.5356 - accuracy: 0.9358 - val_loss: 0.8222 - val_accuracy: 0.6538\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.5194 - accuracy: 0.9360 - val_loss: 0.8223 - val_accuracy: 0.6538\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.5123 - accuracy: 0.9335 - val_loss: 0.8211 - val_accuracy: 0.6538\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4543 - accuracy: 0.9501 - val_loss: 0.8210 - val_accuracy: 0.6731\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.4876 - accuracy: 0.9495 - val_loss: 0.8184 - val_accuracy: 0.6731\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4671 - accuracy: 0.9730 - val_loss: 0.8174 - val_accuracy: 0.6731\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4764 - accuracy: 0.9393 - val_loss: 0.8155 - val_accuracy: 0.6731\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5017 - accuracy: 0.9270 - val_loss: 0.8157 - val_accuracy: 0.6731\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4950 - accuracy: 0.9579 - val_loss: 0.8164 - val_accuracy: 0.6731\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.5153 - accuracy: 0.9500 - val_loss: 0.8165 - val_accuracy: 0.6538\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4928 - accuracy: 0.9694 - val_loss: 0.8134 - val_accuracy: 0.6731\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4885 - accuracy: 0.9500 - val_loss: 0.8132 - val_accuracy: 0.6538\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4824 - accuracy: 0.9616 - val_loss: 0.8121 - val_accuracy: 0.6538\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4790 - accuracy: 0.9290 - val_loss: 0.8132 - val_accuracy: 0.6731\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4665 - accuracy: 0.9629 - val_loss: 0.8123 - val_accuracy: 0.6731\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4407 - accuracy: 0.9898 - val_loss: 0.8101 - val_accuracy: 0.6731\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.4856 - accuracy: 0.9719 - val_loss: 0.8100 - val_accuracy: 0.6731\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4321 - accuracy: 0.9728 - val_loss: 0.8101 - val_accuracy: 0.6731\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4054 - accuracy: 0.9509 - val_loss: 0.8076 - val_accuracy: 0.6731\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4370 - accuracy: 0.9385 - val_loss: 0.8064 - val_accuracy: 0.6731\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4067 - accuracy: 0.9598 - val_loss: 0.8036 - val_accuracy: 0.6731\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.4124 - accuracy: 0.9803 - val_loss: 0.8026 - val_accuracy: 0.6731\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.4361 - accuracy: 0.9516 - val_loss: 0.8011 - val_accuracy: 0.6731\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4253 - accuracy: 0.9536 - val_loss: 0.7998 - val_accuracy: 0.6731\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.4551 - accuracy: 0.9302 - val_loss: 0.7980 - val_accuracy: 0.6923\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3984 - accuracy: 0.9565 - val_loss: 0.7967 - val_accuracy: 0.6923\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4159 - accuracy: 0.9401 - val_loss: 0.7972 - val_accuracy: 0.6923\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4297 - accuracy: 0.9383 - val_loss: 0.7994 - val_accuracy: 0.6731\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4112 - accuracy: 0.9489 - val_loss: 0.7967 - val_accuracy: 0.6731\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4121 - accuracy: 0.9618 - val_loss: 0.7963 - val_accuracy: 0.6923\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.3791 - accuracy: 0.9741 - val_loss: 0.7951 - val_accuracy: 0.6923\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 3s 303ms/step - loss: 0.3788 - accuracy: 0.9931 - val_loss: 0.7921 - val_accuracy: 0.7115\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4090 - accuracy: 0.9774 - val_loss: 0.7900 - val_accuracy: 0.7115\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4141 - accuracy: 0.9737 - val_loss: 0.7899 - val_accuracy: 0.7115\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3783 - accuracy: 0.9712 - val_loss: 0.7909 - val_accuracy: 0.7115\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3868 - accuracy: 0.9497 - val_loss: 0.7904 - val_accuracy: 0.7115\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4059 - accuracy: 0.9916 - val_loss: 0.7894 - val_accuracy: 0.7115\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.4030 - accuracy: 0.9729 - val_loss: 0.7878 - val_accuracy: 0.7115\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3643 - accuracy: 0.9655 - val_loss: 0.7866 - val_accuracy: 0.7115\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3814 - accuracy: 0.9678 - val_loss: 0.7866 - val_accuracy: 0.7115\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3914 - accuracy: 0.9620 - val_loss: 0.7862 - val_accuracy: 0.7115\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3564 - accuracy: 0.9913 - val_loss: 0.7851 - val_accuracy: 0.7115\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3791 - accuracy: 0.9712 - val_loss: 0.7850 - val_accuracy: 0.7115\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3786 - accuracy: 0.9633 - val_loss: 0.7837 - val_accuracy: 0.7115\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3893 - accuracy: 0.9727 - val_loss: 0.7831 - val_accuracy: 0.7115\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.3568 - accuracy: 0.9717 - val_loss: 0.7824 - val_accuracy: 0.7115\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.3527 - accuracy: 0.9443 - val_loss: 0.7809 - val_accuracy: 0.7115\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.3606 - accuracy: 0.9579 - val_loss: 0.7809 - val_accuracy: 0.7115\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3437 - accuracy: 0.9767 - val_loss: 0.7802 - val_accuracy: 0.7115\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3290 - accuracy: 0.9838 - val_loss: 0.7805 - val_accuracy: 0.7115\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3412 - accuracy: 0.9783 - val_loss: 0.7792 - val_accuracy: 0.7115\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3307 - accuracy: 0.9895 - val_loss: 0.7786 - val_accuracy: 0.7115\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3108 - accuracy: 0.9847 - val_loss: 0.7774 - val_accuracy: 0.7115\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3343 - accuracy: 0.9860 - val_loss: 0.7764 - val_accuracy: 0.7308\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3233 - accuracy: 0.9671 - val_loss: 0.7762 - val_accuracy: 0.7308\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3276 - accuracy: 0.9761 - val_loss: 0.7748 - val_accuracy: 0.7308\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3006 - accuracy: 0.9663 - val_loss: 0.7735 - val_accuracy: 0.7308\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.3189 - accuracy: 0.9654 - val_loss: 0.7741 - val_accuracy: 0.7308\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3343 - accuracy: 0.9826 - val_loss: 0.7749 - val_accuracy: 0.7308\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2956 - accuracy: 0.9817 - val_loss: 0.7753 - val_accuracy: 0.7308\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3073 - accuracy: 0.9836 - val_loss: 0.7738 - val_accuracy: 0.7308\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.3367 - accuracy: 0.9774 - val_loss: 0.7744 - val_accuracy: 0.7308\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3184 - accuracy: 0.9889 - val_loss: 0.7737 - val_accuracy: 0.7308\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.3133 - accuracy: 0.9810 - val_loss: 0.7736 - val_accuracy: 0.7308\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2916 - accuracy: 0.9901 - val_loss: 0.7731 - val_accuracy: 0.7115\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2630 - accuracy: 0.9895 - val_loss: 0.7731 - val_accuracy: 0.7115\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.3789 - accuracy: 0.9281 - val_loss: 0.7726 - val_accuracy: 0.7115\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3092 - accuracy: 1.0000 - val_loss: 0.7731 - val_accuracy: 0.7115\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.2953 - accuracy: 1.0000 - val_loss: 0.7724 - val_accuracy: 0.7308\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2781 - accuracy: 1.0000 - val_loss: 0.7723 - val_accuracy: 0.7115\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2866 - accuracy: 0.9860 - val_loss: 0.7719 - val_accuracy: 0.7115\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3017 - accuracy: 0.9920 - val_loss: 0.7721 - val_accuracy: 0.7115\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3331 - accuracy: 0.9656 - val_loss: 0.7719 - val_accuracy: 0.7115\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2897 - accuracy: 0.9975 - val_loss: 0.7713 - val_accuracy: 0.7115\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2873 - accuracy: 0.9864 - val_loss: 0.7712 - val_accuracy: 0.7115\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2866 - accuracy: 0.9845 - val_loss: 0.7716 - val_accuracy: 0.7115\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2863 - accuracy: 0.9852 - val_loss: 0.7711 - val_accuracy: 0.7115\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.2953 - accuracy: 0.9831 - val_loss: 0.7736 - val_accuracy: 0.7308\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2766 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.7115\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2816 - accuracy: 0.9848 - val_loss: 0.7726 - val_accuracy: 0.7115\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3035 - accuracy: 0.9899 - val_loss: 0.7729 - val_accuracy: 0.7115\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2894 - accuracy: 0.9880 - val_loss: 0.7723 - val_accuracy: 0.7115\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2877 - accuracy: 0.9855 - val_loss: 0.7721 - val_accuracy: 0.7115\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2587 - accuracy: 0.9964 - val_loss: 0.7719 - val_accuracy: 0.7115\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2663 - accuracy: 1.0000 - val_loss: 0.7718 - val_accuracy: 0.7115\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2866 - accuracy: 0.9785 - val_loss: 0.7718 - val_accuracy: 0.7115\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 0.2670 - accuracy: 0.9988 - val_loss: 0.7715 - val_accuracy: 0.7115\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2738 - accuracy: 0.9957 - val_loss: 0.7715 - val_accuracy: 0.7115\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3153 - accuracy: 0.9715 - val_loss: 0.7713 - val_accuracy: 0.7115\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2763 - accuracy: 0.9816 - val_loss: 0.7714 - val_accuracy: 0.7308\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2728 - accuracy: 0.9654 - val_loss: 0.7715 - val_accuracy: 0.7115\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2921 - accuracy: 0.9946 - val_loss: 0.7713 - val_accuracy: 0.7115\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2602 - accuracy: 0.9975 - val_loss: 0.7712 - val_accuracy: 0.7115\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2883 - accuracy: 0.9988 - val_loss: 0.7712 - val_accuracy: 0.7115\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2711 - accuracy: 0.9957 - val_loss: 0.7713 - val_accuracy: 0.7115\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2762 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.7115\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2671 - accuracy: 1.0000 - val_loss: 0.7714 - val_accuracy: 0.7115\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.75; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 390ms/step - loss: 1.8984 - accuracy: 0.3340 - val_loss: 1.0899 - val_accuracy: 0.4231\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.8320 - accuracy: 0.3670 - val_loss: 1.0863 - val_accuracy: 0.3654\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.7914 - accuracy: 0.3891 - val_loss: 1.0804 - val_accuracy: 0.3654\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.6835 - accuracy: 0.3846 - val_loss: 1.0800 - val_accuracy: 0.3846\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.7351 - accuracy: 0.4247 - val_loss: 1.0750 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.8614 - accuracy: 0.4210 - val_loss: 1.0688 - val_accuracy: 0.4423\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.6430 - accuracy: 0.4229 - val_loss: 1.0665 - val_accuracy: 0.4231\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.5747 - accuracy: 0.4322 - val_loss: 1.0627 - val_accuracy: 0.4615\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.6216 - accuracy: 0.5021 - val_loss: 1.0646 - val_accuracy: 0.4808\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.7467 - accuracy: 0.4917 - val_loss: 1.0582 - val_accuracy: 0.4808\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.6787 - accuracy: 0.4961 - val_loss: 1.0536 - val_accuracy: 0.5192\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.5317 - accuracy: 0.5757 - val_loss: 1.0532 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.7079 - accuracy: 0.5618 - val_loss: 1.0501 - val_accuracy: 0.5192\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.6204 - accuracy: 0.6218 - val_loss: 1.0455 - val_accuracy: 0.5385\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.4133 - accuracy: 0.5924 - val_loss: 1.0476 - val_accuracy: 0.5192\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.4160 - accuracy: 0.6190 - val_loss: 1.0492 - val_accuracy: 0.5192\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.4648 - accuracy: 0.6101 - val_loss: 1.0483 - val_accuracy: 0.5192\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.3963 - accuracy: 0.6485 - val_loss: 1.0467 - val_accuracy: 0.5192\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.4512 - accuracy: 0.6220 - val_loss: 1.0418 - val_accuracy: 0.5192\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.4616 - accuracy: 0.6663 - val_loss: 1.0378 - val_accuracy: 0.5192\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.3589 - accuracy: 0.7040 - val_loss: 1.0342 - val_accuracy: 0.5192\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3218 - accuracy: 0.6972 - val_loss: 1.0311 - val_accuracy: 0.5385\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.3245 - accuracy: 0.7038 - val_loss: 1.0308 - val_accuracy: 0.5385\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.5014 - accuracy: 0.6819 - val_loss: 1.0262 - val_accuracy: 0.5192\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 1.2990 - accuracy: 0.7063 - val_loss: 1.0235 - val_accuracy: 0.5192\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.2147 - accuracy: 0.7473 - val_loss: 1.0206 - val_accuracy: 0.5192\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.2469 - accuracy: 0.7010 - val_loss: 1.0183 - val_accuracy: 0.5385\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.3188 - accuracy: 0.6999 - val_loss: 1.0112 - val_accuracy: 0.5577\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.3109 - accuracy: 0.7493 - val_loss: 1.0081 - val_accuracy: 0.5577\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3061 - accuracy: 0.7303 - val_loss: 1.0046 - val_accuracy: 0.5385\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.2583 - accuracy: 0.7108 - val_loss: 0.9988 - val_accuracy: 0.5577\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.2602 - accuracy: 0.7450 - val_loss: 0.9931 - val_accuracy: 0.5577\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.1882 - accuracy: 0.8272 - val_loss: 0.9883 - val_accuracy: 0.5577\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.2022 - accuracy: 0.7580 - val_loss: 0.9828 - val_accuracy: 0.5385\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.2605 - accuracy: 0.7683 - val_loss: 0.9790 - val_accuracy: 0.5385\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.2264 - accuracy: 0.7789 - val_loss: 0.9738 - val_accuracy: 0.5385\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.2208 - accuracy: 0.8232 - val_loss: 0.9729 - val_accuracy: 0.5577\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.1847 - accuracy: 0.8071 - val_loss: 0.9695 - val_accuracy: 0.5385\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 1.0746 - accuracy: 0.8035 - val_loss: 0.9662 - val_accuracy: 0.5385\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.0815 - accuracy: 0.7911 - val_loss: 0.9645 - val_accuracy: 0.5385\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0919 - accuracy: 0.7431 - val_loss: 0.9614 - val_accuracy: 0.5385\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.0363 - accuracy: 0.7891 - val_loss: 0.9579 - val_accuracy: 0.5192\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.0800 - accuracy: 0.7913 - val_loss: 0.9545 - val_accuracy: 0.5192\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.0149 - accuracy: 0.8379 - val_loss: 0.9498 - val_accuracy: 0.5192\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.0600 - accuracy: 0.8103 - val_loss: 0.9466 - val_accuracy: 0.5192\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.0510 - accuracy: 0.8203 - val_loss: 0.9413 - val_accuracy: 0.5385\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.0559 - accuracy: 0.8193 - val_loss: 0.9372 - val_accuracy: 0.5385\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.0024 - accuracy: 0.8111 - val_loss: 0.9322 - val_accuracy: 0.5577\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.0276 - accuracy: 0.8378 - val_loss: 0.9279 - val_accuracy: 0.5577\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.0216 - accuracy: 0.8355 - val_loss: 0.9262 - val_accuracy: 0.5769\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0291 - accuracy: 0.8110 - val_loss: 0.9212 - val_accuracy: 0.5769\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 1.0024 - accuracy: 0.8374 - val_loss: 0.9182 - val_accuracy: 0.5769\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.9294 - accuracy: 0.8389 - val_loss: 0.9140 - val_accuracy: 0.5769\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.8434 - accuracy: 0.8481 - val_loss: 0.9150 - val_accuracy: 0.5962\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.9343 - accuracy: 0.8725 - val_loss: 0.9099 - val_accuracy: 0.5962\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.9175 - accuracy: 0.8603 - val_loss: 0.9041 - val_accuracy: 0.5962\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.9156 - accuracy: 0.8901 - val_loss: 0.8985 - val_accuracy: 0.5962\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0330 - accuracy: 0.8389 - val_loss: 0.8949 - val_accuracy: 0.5962\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.9011 - accuracy: 0.8534 - val_loss: 0.8913 - val_accuracy: 0.5962\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.8741 - accuracy: 0.8119 - val_loss: 0.8888 - val_accuracy: 0.5962\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.9394 - accuracy: 0.9000 - val_loss: 0.8857 - val_accuracy: 0.6154\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.8564 - accuracy: 0.8678 - val_loss: 0.8827 - val_accuracy: 0.6154\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.9140 - accuracy: 0.8538 - val_loss: 0.8811 - val_accuracy: 0.6154\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.8338 - accuracy: 0.8887 - val_loss: 0.8775 - val_accuracy: 0.6154\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.9029 - accuracy: 0.8790 - val_loss: 0.8718 - val_accuracy: 0.6154\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.8438 - accuracy: 0.8925 - val_loss: 0.8703 - val_accuracy: 0.6154\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.8480 - accuracy: 0.8487 - val_loss: 0.8676 - val_accuracy: 0.6154\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.8563 - accuracy: 0.8504 - val_loss: 0.8643 - val_accuracy: 0.6346\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.8595 - accuracy: 0.8671 - val_loss: 0.8628 - val_accuracy: 0.6346\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.8085 - accuracy: 0.8510 - val_loss: 0.8601 - val_accuracy: 0.6346\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.7837 - accuracy: 0.9070 - val_loss: 0.8559 - val_accuracy: 0.6346\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.7732 - accuracy: 0.8999 - val_loss: 0.8534 - val_accuracy: 0.6346\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.8165 - accuracy: 0.9015 - val_loss: 0.8512 - val_accuracy: 0.6346\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7906 - accuracy: 0.8678 - val_loss: 0.8479 - val_accuracy: 0.6346\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.8097 - accuracy: 0.9010 - val_loss: 0.8454 - val_accuracy: 0.6346\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.7572 - accuracy: 0.8801 - val_loss: 0.8433 - val_accuracy: 0.6538\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.7699 - accuracy: 0.8913 - val_loss: 0.8402 - val_accuracy: 0.6538\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.7415 - accuracy: 0.8818 - val_loss: 0.8380 - val_accuracy: 0.6538\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7534 - accuracy: 0.8953 - val_loss: 0.8358 - val_accuracy: 0.6538\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.7647 - accuracy: 0.8617 - val_loss: 0.8332 - val_accuracy: 0.6538\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6866 - accuracy: 0.9122 - val_loss: 0.8322 - val_accuracy: 0.6538\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7159 - accuracy: 0.9122 - val_loss: 0.8294 - val_accuracy: 0.6731\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6969 - accuracy: 0.9065 - val_loss: 0.8269 - val_accuracy: 0.6731\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7050 - accuracy: 0.9119 - val_loss: 0.8241 - val_accuracy: 0.6731\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7056 - accuracy: 0.9315 - val_loss: 0.8218 - val_accuracy: 0.6731\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6648 - accuracy: 0.8802 - val_loss: 0.8188 - val_accuracy: 0.6731\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6704 - accuracy: 0.8942 - val_loss: 0.8181 - val_accuracy: 0.6731\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.6651 - accuracy: 0.9057 - val_loss: 0.8149 - val_accuracy: 0.6731\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.7509 - accuracy: 0.9121 - val_loss: 0.8143 - val_accuracy: 0.6731\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.7039 - accuracy: 0.8772 - val_loss: 0.8100 - val_accuracy: 0.6731\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6429 - accuracy: 0.9249 - val_loss: 0.8067 - val_accuracy: 0.6731\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.6653 - accuracy: 0.9579 - val_loss: 0.8052 - val_accuracy: 0.6731\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.6190 - accuracy: 0.9219 - val_loss: 0.8037 - val_accuracy: 0.6731\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.5952 - accuracy: 0.8957 - val_loss: 0.8010 - val_accuracy: 0.6731\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6161 - accuracy: 0.8956 - val_loss: 0.7991 - val_accuracy: 0.6731\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.6431 - accuracy: 0.8786 - val_loss: 0.7978 - val_accuracy: 0.6731\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.6473 - accuracy: 0.8709 - val_loss: 0.7956 - val_accuracy: 0.6731\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6273 - accuracy: 0.8805 - val_loss: 0.7949 - val_accuracy: 0.6731\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5869 - accuracy: 0.9379 - val_loss: 0.7940 - val_accuracy: 0.6731\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.6155 - accuracy: 0.8895 - val_loss: 0.7917 - val_accuracy: 0.6731\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6232 - accuracy: 0.9093 - val_loss: 0.7899 - val_accuracy: 0.6923\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5623 - accuracy: 0.9368 - val_loss: 0.7869 - val_accuracy: 0.6731\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5871 - accuracy: 0.9443 - val_loss: 0.7848 - val_accuracy: 0.6731\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.5533 - accuracy: 0.9300 - val_loss: 0.7834 - val_accuracy: 0.6731\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5479 - accuracy: 0.9278 - val_loss: 0.7820 - val_accuracy: 0.6731\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5524 - accuracy: 0.9465 - val_loss: 0.7814 - val_accuracy: 0.6731\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5535 - accuracy: 0.8968 - val_loss: 0.7797 - val_accuracy: 0.6731\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5657 - accuracy: 0.9347 - val_loss: 0.7786 - val_accuracy: 0.6731\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.5869 - accuracy: 0.9606 - val_loss: 0.7763 - val_accuracy: 0.6731\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.5363 - accuracy: 0.9457 - val_loss: 0.7754 - val_accuracy: 0.6731\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5257 - accuracy: 0.9232 - val_loss: 0.7738 - val_accuracy: 0.6731\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5388 - accuracy: 0.9374 - val_loss: 0.7732 - val_accuracy: 0.6731\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5593 - accuracy: 0.9047 - val_loss: 0.7720 - val_accuracy: 0.6731\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5105 - accuracy: 0.9700 - val_loss: 0.7705 - val_accuracy: 0.6731\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5245 - accuracy: 0.9353 - val_loss: 0.7709 - val_accuracy: 0.6731\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5348 - accuracy: 0.9342 - val_loss: 0.7691 - val_accuracy: 0.6731\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.5369 - accuracy: 0.9253 - val_loss: 0.7686 - val_accuracy: 0.6731\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.5018 - accuracy: 0.9281 - val_loss: 0.7671 - val_accuracy: 0.6731\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4738 - accuracy: 0.9434 - val_loss: 0.7655 - val_accuracy: 0.6731\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.5005 - accuracy: 0.9562 - val_loss: 0.7648 - val_accuracy: 0.6731\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4580 - accuracy: 0.9402 - val_loss: 0.7622 - val_accuracy: 0.6731\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 2s 264ms/step - loss: 0.4642 - accuracy: 0.9649 - val_loss: 0.7611 - val_accuracy: 0.6731\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.4798 - accuracy: 0.9606 - val_loss: 0.7593 - val_accuracy: 0.6731\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4830 - accuracy: 0.9536 - val_loss: 0.7573 - val_accuracy: 0.6731\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4536 - accuracy: 0.9612 - val_loss: 0.7557 - val_accuracy: 0.6731\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4688 - accuracy: 0.9485 - val_loss: 0.7543 - val_accuracy: 0.6923\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4886 - accuracy: 0.9219 - val_loss: 0.7526 - val_accuracy: 0.6923\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.5150 - accuracy: 0.9390 - val_loss: 0.7507 - val_accuracy: 0.6923\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4348 - accuracy: 0.9582 - val_loss: 0.7498 - val_accuracy: 0.6923\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4632 - accuracy: 0.9428 - val_loss: 0.7488 - val_accuracy: 0.6731\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4769 - accuracy: 0.9669 - val_loss: 0.7477 - val_accuracy: 0.6923\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4808 - accuracy: 0.9257 - val_loss: 0.7471 - val_accuracy: 0.6923\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4552 - accuracy: 0.9503 - val_loss: 0.7455 - val_accuracy: 0.6923\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4151 - accuracy: 0.9440 - val_loss: 0.7440 - val_accuracy: 0.6923\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.4631 - accuracy: 0.9621 - val_loss: 0.7438 - val_accuracy: 0.6923\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4079 - accuracy: 0.9627 - val_loss: 0.7433 - val_accuracy: 0.6923\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4165 - accuracy: 0.9541 - val_loss: 0.7424 - val_accuracy: 0.6923\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4126 - accuracy: 0.9531 - val_loss: 0.7408 - val_accuracy: 0.6923\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4359 - accuracy: 0.9510 - val_loss: 0.7401 - val_accuracy: 0.6923\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.4511 - accuracy: 0.9562 - val_loss: 0.7387 - val_accuracy: 0.6923\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.4876 - accuracy: 0.9302 - val_loss: 0.7388 - val_accuracy: 0.6923\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.4204 - accuracy: 0.9327 - val_loss: 0.7381 - val_accuracy: 0.6923\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.4240 - accuracy: 0.9605 - val_loss: 0.7367 - val_accuracy: 0.6923\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3965 - accuracy: 0.9334 - val_loss: 0.7360 - val_accuracy: 0.6923\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3995 - accuracy: 0.9576 - val_loss: 0.7345 - val_accuracy: 0.6923\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3824 - accuracy: 0.9509 - val_loss: 0.7340 - val_accuracy: 0.6923\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.3951 - accuracy: 0.9606 - val_loss: 0.7326 - val_accuracy: 0.6923\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.3866 - accuracy: 0.9488 - val_loss: 0.7326 - val_accuracy: 0.6923\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4089 - accuracy: 0.9443 - val_loss: 0.7321 - val_accuracy: 0.6923\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3909 - accuracy: 0.9503 - val_loss: 0.7318 - val_accuracy: 0.6923\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4031 - accuracy: 0.9622 - val_loss: 0.7310 - val_accuracy: 0.7115\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3622 - accuracy: 0.9529 - val_loss: 0.7301 - val_accuracy: 0.6923\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3588 - accuracy: 0.9749 - val_loss: 0.7291 - val_accuracy: 0.6923\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3517 - accuracy: 0.9664 - val_loss: 0.7279 - val_accuracy: 0.7115\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3567 - accuracy: 0.9667 - val_loss: 0.7274 - val_accuracy: 0.7115\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3205 - accuracy: 0.9499 - val_loss: 0.7274 - val_accuracy: 0.7115\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3417 - accuracy: 0.9630 - val_loss: 0.7274 - val_accuracy: 0.7115\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3667 - accuracy: 0.9479 - val_loss: 0.7264 - val_accuracy: 0.7115\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3618 - accuracy: 0.9621 - val_loss: 0.7254 - val_accuracy: 0.7115\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.3176 - accuracy: 0.9745 - val_loss: 0.7241 - val_accuracy: 0.7115\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3554 - accuracy: 0.9729 - val_loss: 0.7242 - val_accuracy: 0.7115\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3572 - accuracy: 0.9690 - val_loss: 0.7230 - val_accuracy: 0.7115\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3300 - accuracy: 0.9581 - val_loss: 0.7232 - val_accuracy: 0.7115\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3387 - accuracy: 0.9365 - val_loss: 0.7227 - val_accuracy: 0.7115\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3342 - accuracy: 0.9615 - val_loss: 0.7218 - val_accuracy: 0.7115\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.3382 - accuracy: 0.9777 - val_loss: 0.7222 - val_accuracy: 0.7115\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3321 - accuracy: 0.9731 - val_loss: 0.7215 - val_accuracy: 0.7115\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3345 - accuracy: 0.9758 - val_loss: 0.7207 - val_accuracy: 0.7115\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3504 - accuracy: 0.9662 - val_loss: 0.7203 - val_accuracy: 0.7115\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3355 - accuracy: 0.9729 - val_loss: 0.7192 - val_accuracy: 0.7115\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3200 - accuracy: 0.9821 - val_loss: 0.7188 - val_accuracy: 0.7115\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3026 - accuracy: 0.9799 - val_loss: 0.7187 - val_accuracy: 0.7115\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2863 - accuracy: 0.9845 - val_loss: 0.7187 - val_accuracy: 0.7308\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2980 - accuracy: 0.9822 - val_loss: 0.7177 - val_accuracy: 0.7308\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3368 - accuracy: 0.9535 - val_loss: 0.7171 - val_accuracy: 0.7308\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.3154 - accuracy: 0.9798 - val_loss: 0.7171 - val_accuracy: 0.7115\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3057 - accuracy: 0.9654 - val_loss: 0.7159 - val_accuracy: 0.7115\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3351 - accuracy: 0.9386 - val_loss: 0.7154 - val_accuracy: 0.7115\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3051 - accuracy: 0.9742 - val_loss: 0.7150 - val_accuracy: 0.7115\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2959 - accuracy: 0.9903 - val_loss: 0.7154 - val_accuracy: 0.7500\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2873 - accuracy: 0.9935 - val_loss: 0.7149 - val_accuracy: 0.7500\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3040 - accuracy: 0.9679 - val_loss: 0.7147 - val_accuracy: 0.7500\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2840 - accuracy: 0.9988 - val_loss: 0.7139 - val_accuracy: 0.7500\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2809 - accuracy: 0.9967 - val_loss: 0.7132 - val_accuracy: 0.7500\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2733 - accuracy: 0.9880 - val_loss: 0.7131 - val_accuracy: 0.7500\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2836 - accuracy: 0.9842 - val_loss: 0.7125 - val_accuracy: 0.7500\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2620 - accuracy: 0.9949 - val_loss: 0.7122 - val_accuracy: 0.7500\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2665 - accuracy: 0.9756 - val_loss: 0.7118 - val_accuracy: 0.7500\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2765 - accuracy: 0.9579 - val_loss: 0.7110 - val_accuracy: 0.7500\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2376 - accuracy: 0.9913 - val_loss: 0.7102 - val_accuracy: 0.7500\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3394 - accuracy: 0.9760 - val_loss: 0.7098 - val_accuracy: 0.7500\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2559 - accuracy: 0.9805 - val_loss: 0.7098 - val_accuracy: 0.7500\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2590 - accuracy: 0.9862 - val_loss: 0.7091 - val_accuracy: 0.7500\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2774 - accuracy: 0.9602 - val_loss: 0.7087 - val_accuracy: 0.7500\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2758 - accuracy: 0.9859 - val_loss: 0.7090 - val_accuracy: 0.7500\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.2620 - accuracy: 0.9828 - val_loss: 0.7086 - val_accuracy: 0.7500\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2843 - accuracy: 0.9888 - val_loss: 0.7089 - val_accuracy: 0.7308\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2597 - accuracy: 0.9855 - val_loss: 0.7082 - val_accuracy: 0.7500\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2214 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.7500\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2750 - accuracy: 0.9933 - val_loss: 0.7078 - val_accuracy: 0.7308\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2665 - accuracy: 0.9861 - val_loss: 0.7075 - val_accuracy: 0.7308\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2516 - accuracy: 0.9982 - val_loss: 0.7069 - val_accuracy: 0.7308\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2977 - accuracy: 0.9605 - val_loss: 0.7073 - val_accuracy: 0.7308\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2497 - accuracy: 0.9739 - val_loss: 0.7072 - val_accuracy: 0.7308\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2358 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.7308\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2470 - accuracy: 0.9810 - val_loss: 0.7068 - val_accuracy: 0.7308\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2465 - accuracy: 0.9971 - val_loss: 0.7071 - val_accuracy: 0.7308\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2360 - accuracy: 0.9955 - val_loss: 0.7072 - val_accuracy: 0.7308\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2873 - accuracy: 0.9736 - val_loss: 0.7065 - val_accuracy: 0.7308\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.7308\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2351 - accuracy: 0.9889 - val_loss: 0.7059 - val_accuracy: 0.7308\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.2099 - accuracy: 0.9932 - val_loss: 0.7059 - val_accuracy: 0.7308\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2453 - accuracy: 1.0000 - val_loss: 0.7056 - val_accuracy: 0.7308\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2071 - accuracy: 0.9932 - val_loss: 0.7056 - val_accuracy: 0.7308\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.2475 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.7308\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2176 - accuracy: 0.9816 - val_loss: 0.7055 - val_accuracy: 0.7308\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2187 - accuracy: 0.9975 - val_loss: 0.7050 - val_accuracy: 0.7308\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2215 - accuracy: 0.9988 - val_loss: 0.7046 - val_accuracy: 0.7308\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2254 - accuracy: 0.9907 - val_loss: 0.7040 - val_accuracy: 0.7308\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2214 - accuracy: 0.9864 - val_loss: 0.7039 - val_accuracy: 0.7308\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.2132 - accuracy: 0.9932 - val_loss: 0.7038 - val_accuracy: 0.7308\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2121 - accuracy: 0.9855 - val_loss: 0.7037 - val_accuracy: 0.7308\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2372 - accuracy: 0.9769 - val_loss: 0.7031 - val_accuracy: 0.7308\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2197 - accuracy: 0.9913 - val_loss: 0.7029 - val_accuracy: 0.7308\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2113 - accuracy: 0.9842 - val_loss: 0.7024 - val_accuracy: 0.7308\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.7308\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1947 - accuracy: 0.9988 - val_loss: 0.7025 - val_accuracy: 0.7308\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2010 - accuracy: 0.9889 - val_loss: 0.7022 - val_accuracy: 0.7308\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.7308\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.1865 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.7500\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.2021 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.7308\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.1808 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.7500\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2137 - accuracy: 0.9946 - val_loss: 0.7026 - val_accuracy: 0.7500\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2077 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.7500\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1924 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.7500\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1735 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.7500\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1900 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.7500\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1972 - accuracy: 0.9957 - val_loss: 0.7024 - val_accuracy: 0.7500\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1842 - accuracy: 1.0000 - val_loss: 0.7024 - val_accuracy: 0.7500\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2466 - accuracy: 0.9921 - val_loss: 0.7026 - val_accuracy: 0.7500\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1984 - accuracy: 0.9932 - val_loss: 0.7026 - val_accuracy: 0.7500\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1900 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.7500\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1863 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.7500\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2059 - accuracy: 0.9946 - val_loss: 0.7025 - val_accuracy: 0.7500\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2095 - accuracy: 0.9786 - val_loss: 0.7024 - val_accuracy: 0.7500\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.2345 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.7500\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1878 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.7500\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1957 - accuracy: 0.9885 - val_loss: 0.7023 - val_accuracy: 0.7500\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2011 - accuracy: 0.9842 - val_loss: 0.7023 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.78; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.63%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.75 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.78 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0):\n",
      "> Accuracy: 0.67 (+- 0.03)\n",
      "> Loss: 0.76 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 8/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.5\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 385ms/step - loss: 2.1356 - accuracy: 0.3499 - val_loss: 1.1110 - val_accuracy: 0.3462\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 1.7859 - accuracy: 0.3982 - val_loss: 1.0890 - val_accuracy: 0.4231\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 1.8091 - accuracy: 0.3575 - val_loss: 1.0803 - val_accuracy: 0.4038\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.6011 - accuracy: 0.4446 - val_loss: 1.0692 - val_accuracy: 0.4231\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.5306 - accuracy: 0.5289 - val_loss: 1.0619 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.4446 - accuracy: 0.5897 - val_loss: 1.0542 - val_accuracy: 0.4808\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 1.4587 - accuracy: 0.5379 - val_loss: 1.0488 - val_accuracy: 0.4808\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 1.4839 - accuracy: 0.6095 - val_loss: 1.0370 - val_accuracy: 0.5000\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.4231 - accuracy: 0.6049 - val_loss: 1.0226 - val_accuracy: 0.4808\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 1.5274 - accuracy: 0.6469 - val_loss: 1.0154 - val_accuracy: 0.5385\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.4244 - accuracy: 0.6829 - val_loss: 1.0057 - val_accuracy: 0.5192\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.3628 - accuracy: 0.6919 - val_loss: 1.0000 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 1.3561 - accuracy: 0.7176 - val_loss: 0.9863 - val_accuracy: 0.5192\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 1.2239 - accuracy: 0.7421 - val_loss: 0.9755 - val_accuracy: 0.5000\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 1.3225 - accuracy: 0.7508 - val_loss: 0.9713 - val_accuracy: 0.5385\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 1.2067 - accuracy: 0.7297 - val_loss: 0.9656 - val_accuracy: 0.5577\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 1.3000 - accuracy: 0.8292 - val_loss: 0.9537 - val_accuracy: 0.5577\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.2230 - accuracy: 0.7240 - val_loss: 0.9425 - val_accuracy: 0.5192\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.2103 - accuracy: 0.8164 - val_loss: 0.9366 - val_accuracy: 0.5192\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.1139 - accuracy: 0.7932 - val_loss: 0.9283 - val_accuracy: 0.5385\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 1.1020 - accuracy: 0.8103 - val_loss: 0.9190 - val_accuracy: 0.5192\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.1447 - accuracy: 0.7905 - val_loss: 0.9149 - val_accuracy: 0.5192\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 1.0593 - accuracy: 0.8084 - val_loss: 0.9169 - val_accuracy: 0.5577\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 1.0336 - accuracy: 0.7968 - val_loss: 0.9033 - val_accuracy: 0.6154\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.1101 - accuracy: 0.7959 - val_loss: 0.8970 - val_accuracy: 0.6346\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 1.0238 - accuracy: 0.8217 - val_loss: 0.8831 - val_accuracy: 0.6154\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 1.0009 - accuracy: 0.8495 - val_loss: 0.8798 - val_accuracy: 0.6154\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.9859 - accuracy: 0.8187 - val_loss: 0.8721 - val_accuracy: 0.6154\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.9602 - accuracy: 0.8226 - val_loss: 0.8651 - val_accuracy: 0.6154\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.9751 - accuracy: 0.8556 - val_loss: 0.8607 - val_accuracy: 0.6154\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.8742 - accuracy: 0.8813 - val_loss: 0.8528 - val_accuracy: 0.6154\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.9238 - accuracy: 0.8646 - val_loss: 0.8512 - val_accuracy: 0.6154\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.8930 - accuracy: 0.8699 - val_loss: 0.8446 - val_accuracy: 0.6538\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 0.9146 - accuracy: 0.8934 - val_loss: 0.8388 - val_accuracy: 0.6538\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.8366 - accuracy: 0.8389 - val_loss: 0.8345 - val_accuracy: 0.6538\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.8044 - accuracy: 0.8951 - val_loss: 0.8241 - val_accuracy: 0.6538\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7566 - accuracy: 0.9039 - val_loss: 0.8185 - val_accuracy: 0.6538\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.7560 - accuracy: 0.8536 - val_loss: 0.8130 - val_accuracy: 0.6538\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.7552 - accuracy: 0.8897 - val_loss: 0.8101 - val_accuracy: 0.6538\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.8086 - accuracy: 0.9334 - val_loss: 0.8042 - val_accuracy: 0.6538\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.7558 - accuracy: 0.8842 - val_loss: 0.7972 - val_accuracy: 0.6538\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.7122 - accuracy: 0.8956 - val_loss: 0.7922 - val_accuracy: 0.6538\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.7495 - accuracy: 0.8740 - val_loss: 0.7858 - val_accuracy: 0.6538\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7142 - accuracy: 0.9089 - val_loss: 0.7837 - val_accuracy: 0.6538\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6321 - accuracy: 0.9326 - val_loss: 0.7806 - val_accuracy: 0.6538\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.6734 - accuracy: 0.9073 - val_loss: 0.7771 - val_accuracy: 0.6538\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6741 - accuracy: 0.9265 - val_loss: 0.7709 - val_accuracy: 0.6538\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.6758 - accuracy: 0.9159 - val_loss: 0.7703 - val_accuracy: 0.6538\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.6624 - accuracy: 0.8895 - val_loss: 0.7657 - val_accuracy: 0.6538\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.6503 - accuracy: 0.8660 - val_loss: 0.7602 - val_accuracy: 0.6538\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6078 - accuracy: 0.9323 - val_loss: 0.7551 - val_accuracy: 0.6731\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.6180 - accuracy: 0.8749 - val_loss: 0.7547 - val_accuracy: 0.6731\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.5947 - accuracy: 0.8913 - val_loss: 0.7530 - val_accuracy: 0.6538\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.5924 - accuracy: 0.9263 - val_loss: 0.7512 - val_accuracy: 0.6731\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5447 - accuracy: 0.9449 - val_loss: 0.7447 - val_accuracy: 0.6731\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.5421 - accuracy: 0.9310 - val_loss: 0.7414 - val_accuracy: 0.6731\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.5866 - accuracy: 0.9174 - val_loss: 0.7397 - val_accuracy: 0.6731\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5497 - accuracy: 0.9536 - val_loss: 0.7356 - val_accuracy: 0.6731\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.5271 - accuracy: 0.9340 - val_loss: 0.7315 - val_accuracy: 0.6731\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.5648 - accuracy: 0.9388 - val_loss: 0.7273 - val_accuracy: 0.6731\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.5786 - accuracy: 0.9417 - val_loss: 0.7274 - val_accuracy: 0.6731\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.5560 - accuracy: 0.9525 - val_loss: 0.7261 - val_accuracy: 0.6923\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.5074 - accuracy: 0.9314 - val_loss: 0.7199 - val_accuracy: 0.6731\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5066 - accuracy: 0.9329 - val_loss: 0.7192 - val_accuracy: 0.6731\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4538 - accuracy: 0.9461 - val_loss: 0.7171 - val_accuracy: 0.6923\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.4670 - accuracy: 0.9405 - val_loss: 0.7163 - val_accuracy: 0.6923\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.4559 - accuracy: 0.9565 - val_loss: 0.7129 - val_accuracy: 0.6923\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4427 - accuracy: 0.9592 - val_loss: 0.7105 - val_accuracy: 0.6923\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.4369 - accuracy: 0.9508 - val_loss: 0.7091 - val_accuracy: 0.6923\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4396 - accuracy: 0.9593 - val_loss: 0.7076 - val_accuracy: 0.6923\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.4295 - accuracy: 0.9471 - val_loss: 0.7045 - val_accuracy: 0.6923\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4182 - accuracy: 0.9616 - val_loss: 0.7026 - val_accuracy: 0.6731\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4330 - accuracy: 0.9167 - val_loss: 0.7033 - val_accuracy: 0.6923\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4279 - accuracy: 0.9613 - val_loss: 0.7003 - val_accuracy: 0.6731\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.3992 - accuracy: 0.9769 - val_loss: 0.7004 - val_accuracy: 0.6923\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.4352 - accuracy: 0.9489 - val_loss: 0.6985 - val_accuracy: 0.6923\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3615 - accuracy: 0.9666 - val_loss: 0.6960 - val_accuracy: 0.6923\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3647 - accuracy: 0.9612 - val_loss: 0.6946 - val_accuracy: 0.6923\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3533 - accuracy: 0.9766 - val_loss: 0.6943 - val_accuracy: 0.6731\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3363 - accuracy: 0.9923 - val_loss: 0.6907 - val_accuracy: 0.6731\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4003 - accuracy: 0.9687 - val_loss: 0.6901 - val_accuracy: 0.6731\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 3s 372ms/step - loss: 0.3391 - accuracy: 0.9633 - val_loss: 0.6883 - val_accuracy: 0.6731\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3383 - accuracy: 0.9783 - val_loss: 0.6876 - val_accuracy: 0.6923\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3744 - accuracy: 0.9687 - val_loss: 0.6855 - val_accuracy: 0.6731\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 0.3264 - accuracy: 0.9849 - val_loss: 0.6841 - val_accuracy: 0.6731\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.3088 - accuracy: 0.9888 - val_loss: 0.6828 - val_accuracy: 0.6731\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3062 - accuracy: 0.9781 - val_loss: 0.6807 - val_accuracy: 0.6731\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3186 - accuracy: 0.9867 - val_loss: 0.6808 - val_accuracy: 0.6731\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 0.2884 - accuracy: 0.9975 - val_loss: 0.6807 - val_accuracy: 0.6731\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2960 - accuracy: 0.9812 - val_loss: 0.6822 - val_accuracy: 0.6923\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3084 - accuracy: 0.9741 - val_loss: 0.6800 - val_accuracy: 0.6731\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.3015 - accuracy: 0.9988 - val_loss: 0.6780 - val_accuracy: 0.6731\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 0.3047 - accuracy: 0.9728 - val_loss: 0.6813 - val_accuracy: 0.6731\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2938 - accuracy: 0.9885 - val_loss: 0.6780 - val_accuracy: 0.6731\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2773 - accuracy: 0.9982 - val_loss: 0.6768 - val_accuracy: 0.6731\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2760 - accuracy: 0.9741 - val_loss: 0.6766 - val_accuracy: 0.6731\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2611 - accuracy: 0.9846 - val_loss: 0.6745 - val_accuracy: 0.6731\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2700 - accuracy: 0.9796 - val_loss: 0.6761 - val_accuracy: 0.7115\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2508 - accuracy: 0.9934 - val_loss: 0.6733 - val_accuracy: 0.6731\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2787 - accuracy: 0.9712 - val_loss: 0.6748 - val_accuracy: 0.7115\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.2585 - accuracy: 0.9892 - val_loss: 0.6740 - val_accuracy: 0.7115\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.2520 - accuracy: 0.9828 - val_loss: 0.6723 - val_accuracy: 0.6923\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.2840 - accuracy: 0.9848 - val_loss: 0.6713 - val_accuracy: 0.6923\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2510 - accuracy: 0.9852 - val_loss: 0.6737 - val_accuracy: 0.7115\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2473 - accuracy: 0.9828 - val_loss: 0.6721 - val_accuracy: 0.6923\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.2439 - accuracy: 0.9913 - val_loss: 0.6720 - val_accuracy: 0.6923\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2777 - accuracy: 0.9702 - val_loss: 0.6699 - val_accuracy: 0.6923\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2424 - accuracy: 0.9897 - val_loss: 0.6697 - val_accuracy: 0.6923\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.6923\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2198 - accuracy: 0.9982 - val_loss: 0.6722 - val_accuracy: 0.6923\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2522 - accuracy: 0.9967 - val_loss: 0.6712 - val_accuracy: 0.6923\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2059 - accuracy: 1.0000 - val_loss: 0.6706 - val_accuracy: 0.6923\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2250 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.6923\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2172 - accuracy: 0.9892 - val_loss: 0.6701 - val_accuracy: 0.6923\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2009 - accuracy: 0.9975 - val_loss: 0.6693 - val_accuracy: 0.6923\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2027 - accuracy: 0.9752 - val_loss: 0.6666 - val_accuracy: 0.6923\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1677 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.6923\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2049 - accuracy: 0.9920 - val_loss: 0.6671 - val_accuracy: 0.6923\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2108 - accuracy: 0.9828 - val_loss: 0.6688 - val_accuracy: 0.6923\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.1994 - accuracy: 0.9933 - val_loss: 0.6673 - val_accuracy: 0.6923\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.6923\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.1819 - accuracy: 0.9988 - val_loss: 0.6659 - val_accuracy: 0.6923\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1901 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.6923\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.1816 - accuracy: 0.9939 - val_loss: 0.6672 - val_accuracy: 0.6923\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1772 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.6923\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1791 - accuracy: 0.9967 - val_loss: 0.6678 - val_accuracy: 0.6923\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1902 - accuracy: 0.9932 - val_loss: 0.6675 - val_accuracy: 0.6923\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1905 - accuracy: 0.9988 - val_loss: 0.6677 - val_accuracy: 0.6923\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1739 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.6923\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1620 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.6923\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.1651 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.6923\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1646 - accuracy: 1.0000 - val_loss: 0.6671 - val_accuracy: 0.6923\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.1569 - accuracy: 0.9913 - val_loss: 0.6671 - val_accuracy: 0.6923\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.1774 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.6923\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.1714 - accuracy: 0.9932 - val_loss: 0.6667 - val_accuracy: 0.6923\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.6923\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1808 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.6923\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1688 - accuracy: 0.9975 - val_loss: 0.6667 - val_accuracy: 0.6923\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1756 - accuracy: 0.9975 - val_loss: 0.6667 - val_accuracy: 0.6923\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1749 - accuracy: 1.0000 - val_loss: 0.6667 - val_accuracy: 0.6923\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1530 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.6923\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.1704 - accuracy: 0.9946 - val_loss: 0.6666 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 14s 383ms/step - loss: 1.8451 - accuracy: 0.3935 - val_loss: 1.2083 - val_accuracy: 0.1538\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 1.8097 - accuracy: 0.3359 - val_loss: 1.2000 - val_accuracy: 0.1731\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.7237 - accuracy: 0.3961 - val_loss: 1.1952 - val_accuracy: 0.1923\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.5598 - accuracy: 0.4800 - val_loss: 1.1887 - val_accuracy: 0.1923\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 1.5632 - accuracy: 0.5210 - val_loss: 1.1967 - val_accuracy: 0.1923\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.5577 - accuracy: 0.4749 - val_loss: 1.1803 - val_accuracy: 0.2500\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.4109 - accuracy: 0.5744 - val_loss: 1.1693 - val_accuracy: 0.2500\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.5021 - accuracy: 0.5572 - val_loss: 1.1649 - val_accuracy: 0.2500\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.3994 - accuracy: 0.6558 - val_loss: 1.1484 - val_accuracy: 0.2500\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.4407 - accuracy: 0.6585 - val_loss: 1.1243 - val_accuracy: 0.3462\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.4472 - accuracy: 0.6798 - val_loss: 1.1274 - val_accuracy: 0.3462\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.3632 - accuracy: 0.7188 - val_loss: 1.1033 - val_accuracy: 0.3462\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.2773 - accuracy: 0.7448 - val_loss: 1.0894 - val_accuracy: 0.3846\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.2769 - accuracy: 0.7250 - val_loss: 1.0928 - val_accuracy: 0.4231\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.3241 - accuracy: 0.8053 - val_loss: 1.0745 - val_accuracy: 0.4231\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 1.2348 - accuracy: 0.7927 - val_loss: 1.0534 - val_accuracy: 0.4423\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.2545 - accuracy: 0.8061 - val_loss: 1.0480 - val_accuracy: 0.4423\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.1127 - accuracy: 0.7996 - val_loss: 1.0394 - val_accuracy: 0.4615\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.1374 - accuracy: 0.8016 - val_loss: 1.0346 - val_accuracy: 0.4615\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.1155 - accuracy: 0.7515 - val_loss: 1.0263 - val_accuracy: 0.5000\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.1377 - accuracy: 0.8081 - val_loss: 1.0193 - val_accuracy: 0.5192\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.1268 - accuracy: 0.8340 - val_loss: 1.0008 - val_accuracy: 0.5385\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.0282 - accuracy: 0.7623 - val_loss: 0.9939 - val_accuracy: 0.5385\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.0633 - accuracy: 0.8725 - val_loss: 0.9816 - val_accuracy: 0.5385\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.9241 - accuracy: 0.8666 - val_loss: 0.9717 - val_accuracy: 0.5577\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.9603 - accuracy: 0.8809 - val_loss: 0.9738 - val_accuracy: 0.5385\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.9687 - accuracy: 0.8215 - val_loss: 0.9750 - val_accuracy: 0.5577\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 1.0090 - accuracy: 0.8597 - val_loss: 0.9587 - val_accuracy: 0.5385\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.9098 - accuracy: 0.8784 - val_loss: 0.9520 - val_accuracy: 0.5577\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.9014 - accuracy: 0.8894 - val_loss: 0.9376 - val_accuracy: 0.5577\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.9352 - accuracy: 0.8630 - val_loss: 0.9372 - val_accuracy: 0.5385\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.8862 - accuracy: 0.8839 - val_loss: 0.9264 - val_accuracy: 0.5577\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.8044 - accuracy: 0.9032 - val_loss: 0.9182 - val_accuracy: 0.5577\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.8854 - accuracy: 0.9161 - val_loss: 0.9144 - val_accuracy: 0.5769\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7765 - accuracy: 0.8873 - val_loss: 0.9050 - val_accuracy: 0.5769\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.8145 - accuracy: 0.9276 - val_loss: 0.9095 - val_accuracy: 0.5769\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.8419 - accuracy: 0.8873 - val_loss: 0.8944 - val_accuracy: 0.5769\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.7684 - accuracy: 0.8925 - val_loss: 0.8862 - val_accuracy: 0.5769\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.7805 - accuracy: 0.9062 - val_loss: 0.8847 - val_accuracy: 0.5962\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.7371 - accuracy: 0.9031 - val_loss: 0.8783 - val_accuracy: 0.5962\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7201 - accuracy: 0.9268 - val_loss: 0.8736 - val_accuracy: 0.5962\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.6618 - accuracy: 0.9481 - val_loss: 0.8726 - val_accuracy: 0.6154\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.6731 - accuracy: 0.9134 - val_loss: 0.8682 - val_accuracy: 0.6154\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.6771 - accuracy: 0.9012 - val_loss: 0.8690 - val_accuracy: 0.6154\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.7133 - accuracy: 0.8936 - val_loss: 0.8612 - val_accuracy: 0.6154\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.6838 - accuracy: 0.8927 - val_loss: 0.8556 - val_accuracy: 0.6346\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.6544 - accuracy: 0.9076 - val_loss: 0.8452 - val_accuracy: 0.6346\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5913 - accuracy: 0.9226 - val_loss: 0.8451 - val_accuracy: 0.6346\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.6677 - accuracy: 0.8837 - val_loss: 0.8382 - val_accuracy: 0.6346\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.6010 - accuracy: 0.9477 - val_loss: 0.8410 - val_accuracy: 0.6154\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6366 - accuracy: 0.8910 - val_loss: 0.8383 - val_accuracy: 0.6346\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.5982 - accuracy: 0.9063 - val_loss: 0.8347 - val_accuracy: 0.6346\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5460 - accuracy: 0.9281 - val_loss: 0.8327 - val_accuracy: 0.6346\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.5287 - accuracy: 0.9501 - val_loss: 0.8293 - val_accuracy: 0.6346\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5427 - accuracy: 0.8936 - val_loss: 0.8227 - val_accuracy: 0.6346\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.5614 - accuracy: 0.9484 - val_loss: 0.8190 - val_accuracy: 0.6538\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5385 - accuracy: 0.9266 - val_loss: 0.8146 - val_accuracy: 0.6923\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.5107 - accuracy: 0.9837 - val_loss: 0.8127 - val_accuracy: 0.6923\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5103 - accuracy: 0.9367 - val_loss: 0.8083 - val_accuracy: 0.6923\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.4868 - accuracy: 0.9317 - val_loss: 0.8095 - val_accuracy: 0.6923\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4900 - accuracy: 0.9424 - val_loss: 0.8096 - val_accuracy: 0.6731\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 0.5082 - accuracy: 0.9100 - val_loss: 0.8058 - val_accuracy: 0.7115\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.4642 - accuracy: 0.9462 - val_loss: 0.8029 - val_accuracy: 0.7115\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4698 - accuracy: 0.9738 - val_loss: 0.8096 - val_accuracy: 0.6538\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4900 - accuracy: 0.9620 - val_loss: 0.8018 - val_accuracy: 0.6731\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4402 - accuracy: 0.9497 - val_loss: 0.8002 - val_accuracy: 0.6731\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4487 - accuracy: 0.9518 - val_loss: 0.7952 - val_accuracy: 0.7115\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.4290 - accuracy: 0.9593 - val_loss: 0.7961 - val_accuracy: 0.7115\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4130 - accuracy: 0.9503 - val_loss: 0.7954 - val_accuracy: 0.7115\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4163 - accuracy: 0.9650 - val_loss: 0.7931 - val_accuracy: 0.7115\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.4169 - accuracy: 0.9721 - val_loss: 0.7889 - val_accuracy: 0.7115\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.3806 - accuracy: 0.9740 - val_loss: 0.7877 - val_accuracy: 0.7115\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3829 - accuracy: 0.9915 - val_loss: 0.7887 - val_accuracy: 0.7115\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.3884 - accuracy: 0.9601 - val_loss: 0.7863 - val_accuracy: 0.7115\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4056 - accuracy: 0.9428 - val_loss: 0.7843 - val_accuracy: 0.7115\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3497 - accuracy: 0.9849 - val_loss: 0.7825 - val_accuracy: 0.7115\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3507 - accuracy: 0.9971 - val_loss: 0.7811 - val_accuracy: 0.7115\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3763 - accuracy: 0.9777 - val_loss: 0.7807 - val_accuracy: 0.7115\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3652 - accuracy: 0.9680 - val_loss: 0.7768 - val_accuracy: 0.6731\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3420 - accuracy: 0.9781 - val_loss: 0.7749 - val_accuracy: 0.6923\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3524 - accuracy: 0.9819 - val_loss: 0.7751 - val_accuracy: 0.6731\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3305 - accuracy: 0.9920 - val_loss: 0.7735 - val_accuracy: 0.6731\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3282 - accuracy: 0.9946 - val_loss: 0.7725 - val_accuracy: 0.7115\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3245 - accuracy: 0.9661 - val_loss: 0.7740 - val_accuracy: 0.6731\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.7727 - val_accuracy: 0.6731\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3314 - accuracy: 0.9762 - val_loss: 0.7701 - val_accuracy: 0.7308\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3116 - accuracy: 0.9831 - val_loss: 0.7690 - val_accuracy: 0.7308\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3055 - accuracy: 0.9632 - val_loss: 0.7685 - val_accuracy: 0.6923\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.3152 - accuracy: 0.9967 - val_loss: 0.7680 - val_accuracy: 0.7115\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3084 - accuracy: 0.9964 - val_loss: 0.7665 - val_accuracy: 0.6923\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2959 - accuracy: 0.9841 - val_loss: 0.7651 - val_accuracy: 0.6923\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.3277 - accuracy: 0.9988 - val_loss: 0.7676 - val_accuracy: 0.6923\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2729 - accuracy: 0.9844 - val_loss: 0.7665 - val_accuracy: 0.6923\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2968 - accuracy: 0.9828 - val_loss: 0.7668 - val_accuracy: 0.6923\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2707 - accuracy: 0.9924 - val_loss: 0.7671 - val_accuracy: 0.6923\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2686 - accuracy: 0.9946 - val_loss: 0.7666 - val_accuracy: 0.6923\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2430 - accuracy: 0.9975 - val_loss: 0.7649 - val_accuracy: 0.6923\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2751 - accuracy: 0.9988 - val_loss: 0.7647 - val_accuracy: 0.6923\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2642 - accuracy: 0.9946 - val_loss: 0.7641 - val_accuracy: 0.6923\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2500 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.6923\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.2437 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.6923\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2366 - accuracy: 0.9913 - val_loss: 0.7652 - val_accuracy: 0.6923\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2542 - accuracy: 0.9932 - val_loss: 0.7643 - val_accuracy: 0.6923\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2590 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.6923\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2425 - accuracy: 0.9826 - val_loss: 0.7626 - val_accuracy: 0.6923\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2664 - accuracy: 0.9727 - val_loss: 0.7626 - val_accuracy: 0.6923\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2673 - accuracy: 1.0000 - val_loss: 0.7624 - val_accuracy: 0.6923\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 0.2346 - accuracy: 0.9828 - val_loss: 0.7624 - val_accuracy: 0.6923\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2390 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.6923\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2335 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.6923\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.7629 - val_accuracy: 0.6923\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2248 - accuracy: 0.9982 - val_loss: 0.7617 - val_accuracy: 0.6923\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2609 - accuracy: 1.0000 - val_loss: 0.7619 - val_accuracy: 0.6923\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2301 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.6923\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2716 - accuracy: 0.9885 - val_loss: 0.7603 - val_accuracy: 0.6923\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2050 - accuracy: 0.9988 - val_loss: 0.7605 - val_accuracy: 0.6923\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2312 - accuracy: 0.9922 - val_loss: 0.7609 - val_accuracy: 0.6923\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2234 - accuracy: 0.9967 - val_loss: 0.7599 - val_accuracy: 0.6923\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2354 - accuracy: 0.9975 - val_loss: 0.7595 - val_accuracy: 0.6923\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1972 - accuracy: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.6923\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.7591 - val_accuracy: 0.6923\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.6923\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2043 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.6923\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2119 - accuracy: 0.9988 - val_loss: 0.7581 - val_accuracy: 0.6923\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.2142 - accuracy: 0.9988 - val_loss: 0.7578 - val_accuracy: 0.6923\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2225 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.6923\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.6923\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.6923\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2948 - accuracy: 0.9739 - val_loss: 0.7616 - val_accuracy: 0.6923\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2306 - accuracy: 1.0000 - val_loss: 0.7611 - val_accuracy: 0.6923\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.6923\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2026 - accuracy: 0.9913 - val_loss: 0.7611 - val_accuracy: 0.6923\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2162 - accuracy: 0.9988 - val_loss: 0.7613 - val_accuracy: 0.6923\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2115 - accuracy: 0.9946 - val_loss: 0.7612 - val_accuracy: 0.6923\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2036 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.6923\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.6923\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.6923\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.1933 - accuracy: 0.9988 - val_loss: 0.7610 - val_accuracy: 0.6923\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1952 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.6923\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1915 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.6923\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2044 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.6923\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.6923\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1871 - accuracy: 1.0000 - val_loss: 0.7603 - val_accuracy: 0.6923\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2070 - accuracy: 1.0000 - val_loss: 0.7602 - val_accuracy: 0.6923\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1954 - accuracy: 1.0000 - val_loss: 0.7603 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.74; accuracy of 69.23%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 397ms/step - loss: 1.9036 - accuracy: 0.3136 - val_loss: 1.0852 - val_accuracy: 0.3462\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.6226 - accuracy: 0.3618 - val_loss: 1.0891 - val_accuracy: 0.4038\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.8370 - accuracy: 0.3410 - val_loss: 1.0771 - val_accuracy: 0.3846\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.5170 - accuracy: 0.4701 - val_loss: 1.0628 - val_accuracy: 0.4423\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.5677 - accuracy: 0.4940 - val_loss: 1.0610 - val_accuracy: 0.4423\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.6466 - accuracy: 0.4486 - val_loss: 1.0502 - val_accuracy: 0.4423\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.6158 - accuracy: 0.5444 - val_loss: 1.0329 - val_accuracy: 0.4615\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.4951 - accuracy: 0.6141 - val_loss: 1.0249 - val_accuracy: 0.5385\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.3949 - accuracy: 0.6544 - val_loss: 1.0372 - val_accuracy: 0.5192\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.4495 - accuracy: 0.6202 - val_loss: 1.0248 - val_accuracy: 0.5192\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.4279 - accuracy: 0.7150 - val_loss: 1.0167 - val_accuracy: 0.5385\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.3376 - accuracy: 0.7268 - val_loss: 1.0092 - val_accuracy: 0.5192\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.2525 - accuracy: 0.7206 - val_loss: 1.0099 - val_accuracy: 0.5000\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.3373 - accuracy: 0.7530 - val_loss: 0.9987 - val_accuracy: 0.5385\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.2124 - accuracy: 0.8161 - val_loss: 0.9849 - val_accuracy: 0.5385\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.2495 - accuracy: 0.7890 - val_loss: 0.9804 - val_accuracy: 0.5385\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.2087 - accuracy: 0.7724 - val_loss: 0.9695 - val_accuracy: 0.5192\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.1856 - accuracy: 0.7843 - val_loss: 0.9682 - val_accuracy: 0.5385\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 1.1088 - accuracy: 0.8009 - val_loss: 0.9631 - val_accuracy: 0.5769\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.1221 - accuracy: 0.8075 - val_loss: 0.9502 - val_accuracy: 0.5769\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 1.0335 - accuracy: 0.8357 - val_loss: 0.9529 - val_accuracy: 0.5962\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.0962 - accuracy: 0.7796 - val_loss: 0.9451 - val_accuracy: 0.5769\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.0868 - accuracy: 0.8195 - val_loss: 0.9363 - val_accuracy: 0.5769\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.0070 - accuracy: 0.8359 - val_loss: 0.9312 - val_accuracy: 0.5769\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.9871 - accuracy: 0.8448 - val_loss: 0.9241 - val_accuracy: 0.5769\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.9443 - accuracy: 0.8486 - val_loss: 0.9171 - val_accuracy: 0.5769\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.9564 - accuracy: 0.8165 - val_loss: 0.9106 - val_accuracy: 0.6154\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.9531 - accuracy: 0.8205 - val_loss: 0.9022 - val_accuracy: 0.6346\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 1.0268 - accuracy: 0.8407 - val_loss: 0.8931 - val_accuracy: 0.6346\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.8848 - accuracy: 0.9054 - val_loss: 0.8868 - val_accuracy: 0.6346\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.8593 - accuracy: 0.8723 - val_loss: 0.8831 - val_accuracy: 0.6538\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.8173 - accuracy: 0.8872 - val_loss: 0.8740 - val_accuracy: 0.6538\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.8656 - accuracy: 0.8587 - val_loss: 0.8685 - val_accuracy: 0.6538\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.7853 - accuracy: 0.9077 - val_loss: 0.8640 - val_accuracy: 0.6346\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.8340 - accuracy: 0.8475 - val_loss: 0.8594 - val_accuracy: 0.6346\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.7987 - accuracy: 0.8779 - val_loss: 0.8526 - val_accuracy: 0.6346\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.7482 - accuracy: 0.9302 - val_loss: 0.8465 - val_accuracy: 0.6346\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.7870 - accuracy: 0.8642 - val_loss: 0.8407 - val_accuracy: 0.6538\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7739 - accuracy: 0.8938 - val_loss: 0.8411 - val_accuracy: 0.6346\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.7859 - accuracy: 0.8659 - val_loss: 0.8356 - val_accuracy: 0.6538\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.7427 - accuracy: 0.8957 - val_loss: 0.8256 - val_accuracy: 0.6731\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7177 - accuracy: 0.9139 - val_loss: 0.8233 - val_accuracy: 0.6731\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.6775 - accuracy: 0.9345 - val_loss: 0.8212 - val_accuracy: 0.6731\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7233 - accuracy: 0.8452 - val_loss: 0.8170 - val_accuracy: 0.6731\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6286 - accuracy: 0.9282 - val_loss: 0.8131 - val_accuracy: 0.6731\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6526 - accuracy: 0.9062 - val_loss: 0.8086 - val_accuracy: 0.6731\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.6222 - accuracy: 0.9096 - val_loss: 0.7991 - val_accuracy: 0.6923\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.6443 - accuracy: 0.9120 - val_loss: 0.7957 - val_accuracy: 0.6731\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.6349 - accuracy: 0.8920 - val_loss: 0.7943 - val_accuracy: 0.6731\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.6531 - accuracy: 0.8911 - val_loss: 0.7901 - val_accuracy: 0.6731\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5620 - accuracy: 0.9210 - val_loss: 0.7860 - val_accuracy: 0.6731\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.6731 - accuracy: 0.8796 - val_loss: 0.7840 - val_accuracy: 0.6731\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.6494 - accuracy: 0.8871 - val_loss: 0.7788 - val_accuracy: 0.6731\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.5494 - accuracy: 0.9185 - val_loss: 0.7742 - val_accuracy: 0.6731\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.5588 - accuracy: 0.9028 - val_loss: 0.7723 - val_accuracy: 0.6731\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5681 - accuracy: 0.8911 - val_loss: 0.7710 - val_accuracy: 0.6731\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.5530 - accuracy: 0.9184 - val_loss: 0.7669 - val_accuracy: 0.6731\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5202 - accuracy: 0.9460 - val_loss: 0.7635 - val_accuracy: 0.6731\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4966 - accuracy: 0.9377 - val_loss: 0.7591 - val_accuracy: 0.6731\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.5032 - accuracy: 0.9335 - val_loss: 0.7553 - val_accuracy: 0.6731\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5495 - accuracy: 0.9481 - val_loss: 0.7580 - val_accuracy: 0.6731\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.5202 - accuracy: 0.9185 - val_loss: 0.7540 - val_accuracy: 0.6731\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.4731 - accuracy: 0.9480 - val_loss: 0.7539 - val_accuracy: 0.6731\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4388 - accuracy: 0.9289 - val_loss: 0.7517 - val_accuracy: 0.6731\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4805 - accuracy: 0.9324 - val_loss: 0.7493 - val_accuracy: 0.6731\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4190 - accuracy: 0.9619 - val_loss: 0.7483 - val_accuracy: 0.6731\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4180 - accuracy: 0.9688 - val_loss: 0.7450 - val_accuracy: 0.6923\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.4164 - accuracy: 0.9677 - val_loss: 0.7429 - val_accuracy: 0.6923\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4142 - accuracy: 0.9684 - val_loss: 0.7408 - val_accuracy: 0.6923\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4400 - accuracy: 0.9432 - val_loss: 0.7381 - val_accuracy: 0.6923\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4136 - accuracy: 0.9282 - val_loss: 0.7359 - val_accuracy: 0.6923\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4032 - accuracy: 0.9709 - val_loss: 0.7344 - val_accuracy: 0.7115\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4021 - accuracy: 0.9831 - val_loss: 0.7345 - val_accuracy: 0.7115\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.4231 - accuracy: 0.9167 - val_loss: 0.7337 - val_accuracy: 0.7308\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3875 - accuracy: 0.9896 - val_loss: 0.7299 - val_accuracy: 0.7115\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3701 - accuracy: 0.9517 - val_loss: 0.7287 - val_accuracy: 0.7115\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3580 - accuracy: 0.9628 - val_loss: 0.7264 - val_accuracy: 0.7115\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3632 - accuracy: 0.9579 - val_loss: 0.7276 - val_accuracy: 0.7308\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3608 - accuracy: 0.9650 - val_loss: 0.7263 - val_accuracy: 0.7115\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3557 - accuracy: 0.9496 - val_loss: 0.7241 - val_accuracy: 0.7115\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.3668 - accuracy: 0.9648 - val_loss: 0.7233 - val_accuracy: 0.7115\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3334 - accuracy: 0.9733 - val_loss: 0.7214 - val_accuracy: 0.7115\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3305 - accuracy: 0.9772 - val_loss: 0.7197 - val_accuracy: 0.7115\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.3053 - accuracy: 0.9808 - val_loss: 0.7190 - val_accuracy: 0.7115\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3103 - accuracy: 0.9529 - val_loss: 0.7184 - val_accuracy: 0.7115\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.3365 - accuracy: 0.9714 - val_loss: 0.7178 - val_accuracy: 0.7308\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3950 - accuracy: 0.9659 - val_loss: 0.7183 - val_accuracy: 0.7308\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3112 - accuracy: 0.9882 - val_loss: 0.7159 - val_accuracy: 0.7308\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3521 - accuracy: 0.9343 - val_loss: 0.7151 - val_accuracy: 0.7308\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.3156 - accuracy: 0.9815 - val_loss: 0.7147 - val_accuracy: 0.7308\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2678 - accuracy: 0.9806 - val_loss: 0.7131 - val_accuracy: 0.7308\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2828 - accuracy: 0.9793 - val_loss: 0.7122 - val_accuracy: 0.7308\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2855 - accuracy: 0.9932 - val_loss: 0.7114 - val_accuracy: 0.7308\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3028 - accuracy: 0.9940 - val_loss: 0.7108 - val_accuracy: 0.7115\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2661 - accuracy: 0.9751 - val_loss: 0.7091 - val_accuracy: 0.7308\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2791 - accuracy: 0.9878 - val_loss: 0.7081 - val_accuracy: 0.7308\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2692 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.7308\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2601 - accuracy: 0.9787 - val_loss: 0.7074 - val_accuracy: 0.7308\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2665 - accuracy: 0.9932 - val_loss: 0.7069 - val_accuracy: 0.7308\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2339 - accuracy: 0.9938 - val_loss: 0.7058 - val_accuracy: 0.7308\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2273 - accuracy: 0.9964 - val_loss: 0.7046 - val_accuracy: 0.7308\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2293 - accuracy: 0.9982 - val_loss: 0.7034 - val_accuracy: 0.7308\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.2125 - accuracy: 0.9885 - val_loss: 0.7026 - val_accuracy: 0.7308\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2901 - accuracy: 0.9483 - val_loss: 0.7036 - val_accuracy: 0.7308\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.7308\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2347 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.7308\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2903 - accuracy: 0.9465 - val_loss: 0.7027 - val_accuracy: 0.7308\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.7308\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.7308\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2462 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.7308\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2260 - accuracy: 0.9822 - val_loss: 0.7026 - val_accuracy: 0.7308\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.1870 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.7308\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2319 - accuracy: 0.9967 - val_loss: 0.7017 - val_accuracy: 0.7308\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.7308\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2138 - accuracy: 0.9977 - val_loss: 0.7013 - val_accuracy: 0.7308\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1888 - accuracy: 0.9988 - val_loss: 0.7020 - val_accuracy: 0.7500\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.2179 - accuracy: 0.9967 - val_loss: 0.7016 - val_accuracy: 0.7500\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2261 - accuracy: 0.9828 - val_loss: 0.7021 - val_accuracy: 0.7500\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1900 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.7500\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1986 - accuracy: 0.9949 - val_loss: 0.7010 - val_accuracy: 0.7500\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.7500\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2456 - accuracy: 0.9982 - val_loss: 0.7021 - val_accuracy: 0.7500\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1882 - accuracy: 0.9988 - val_loss: 0.7018 - val_accuracy: 0.7500\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1985 - accuracy: 1.0000 - val_loss: 0.7015 - val_accuracy: 0.7500\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1890 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.7500\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.2291 - accuracy: 0.9895 - val_loss: 0.7004 - val_accuracy: 0.7500\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2093 - accuracy: 0.9932 - val_loss: 0.7006 - val_accuracy: 0.7500\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1827 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.7500\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.2073 - accuracy: 0.9913 - val_loss: 0.7004 - val_accuracy: 0.7500\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2018 - accuracy: 0.9946 - val_loss: 0.7004 - val_accuracy: 0.7500\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1983 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.7500\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2057 - accuracy: 1.0000 - val_loss: 0.7011 - val_accuracy: 0.7500\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1940 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1727 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1824 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1835 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.7500\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1765 - accuracy: 0.9957 - val_loss: 0.7010 - val_accuracy: 0.7500\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1799 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1768 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.7500\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1861 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.7500\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.1551 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.7500\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1755 - accuracy: 0.9932 - val_loss: 0.7006 - val_accuracy: 0.7500\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1892 - accuracy: 0.9982 - val_loss: 0.7005 - val_accuracy: 0.7500\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1768 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.7500\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1787 - accuracy: 0.9859 - val_loss: 0.7004 - val_accuracy: 0.7500\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.2018 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.7500\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1875 - accuracy: 0.9885 - val_loss: 0.7005 - val_accuracy: 0.7500\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1496 - accuracy: 0.9975 - val_loss: 0.7005 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.78; accuracy of 65.38%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.74 - Accuracy: 0.69%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.78 - Accuracy: 0.65%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.5):\n",
      "> Accuracy: 0.67 (+- 0.02)\n",
      "> Loss: 0.76 (+- 0.02)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for combination 9/9 ...\n",
      "Learning rate = 0.0001\n",
      "Momentum = 0.9\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[21, 60, 9, 48, 31, 16, 47, 51, 143, 69, 116, 83, 38, 67, 41, 11, 85, 144, 63, 156, 115, 126, 119, 153, 102, 113, 147, 106, 159, 7, 187, 185, 196, 186, 201, 206, 179, 175, 111, 164, 160, 182, 71, 138, 66, 50, 1, 205, 45, 53, 62, 105]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 15s 398ms/step - loss: 2.0972 - accuracy: 0.2380 - val_loss: 1.1263 - val_accuracy: 0.3077\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.5742 - accuracy: 0.4551 - val_loss: 1.0802 - val_accuracy: 0.4615\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.5118 - accuracy: 0.5698 - val_loss: 1.0606 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 1.5033 - accuracy: 0.6459 - val_loss: 0.9940 - val_accuracy: 0.5577\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.2518 - accuracy: 0.7580 - val_loss: 0.9093 - val_accuracy: 0.6346\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 1.1349 - accuracy: 0.7728 - val_loss: 0.9149 - val_accuracy: 0.5962\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.9687 - accuracy: 0.8609 - val_loss: 0.8766 - val_accuracy: 0.6731\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.8935 - accuracy: 0.8632 - val_loss: 0.8536 - val_accuracy: 0.6731\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.9347 - accuracy: 0.8037 - val_loss: 0.8380 - val_accuracy: 0.6923\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.7802 - accuracy: 0.9144 - val_loss: 0.7670 - val_accuracy: 0.7115\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.7154 - accuracy: 0.9290 - val_loss: 0.7950 - val_accuracy: 0.6346\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6870 - accuracy: 0.8749 - val_loss: 0.7720 - val_accuracy: 0.6731\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.5646 - accuracy: 0.9171 - val_loss: 0.7236 - val_accuracy: 0.7115\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.5587 - accuracy: 0.9435 - val_loss: 0.7291 - val_accuracy: 0.7115\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.4829 - accuracy: 0.9162 - val_loss: 0.7057 - val_accuracy: 0.7115\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4404 - accuracy: 0.9397 - val_loss: 0.7021 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4014 - accuracy: 0.9483 - val_loss: 0.6878 - val_accuracy: 0.6923\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.4444 - accuracy: 0.9293 - val_loss: 0.6926 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3532 - accuracy: 0.9741 - val_loss: 0.6993 - val_accuracy: 0.6923\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3522 - accuracy: 0.9720 - val_loss: 0.6838 - val_accuracy: 0.7115\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2993 - accuracy: 0.9690 - val_loss: 0.6833 - val_accuracy: 0.7115\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2950 - accuracy: 0.9834 - val_loss: 0.6744 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2608 - accuracy: 0.9712 - val_loss: 0.7012 - val_accuracy: 0.6538\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2753 - accuracy: 0.9946 - val_loss: 0.6923 - val_accuracy: 0.6923\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2195 - accuracy: 0.9977 - val_loss: 0.6636 - val_accuracy: 0.6923\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2138 - accuracy: 0.9946 - val_loss: 0.6752 - val_accuracy: 0.6923\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1793 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.6731\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1990 - accuracy: 0.9975 - val_loss: 0.6778 - val_accuracy: 0.6923\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1607 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.6923\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1382 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1325 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.6731\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1402 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.6923\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1356 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.6923\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1160 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.6923\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1418 - accuracy: 0.9932 - val_loss: 0.6781 - val_accuracy: 0.6923\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.6923\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1317 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.6923\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.6923\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.6923\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 0.6755 - val_accuracy: 0.6923\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.6923\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.6731 - val_accuracy: 0.6731\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.6923\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 0.6719 - val_accuracy: 0.6923\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: loss of 0.76; accuracy of 67.31%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[85, 63, 129, 31, 156, 158, 48, 139, 121, 13, 108, 140, 65, 95, 150, 128, 103, 26, 56, 10, 86, 153, 96, 75, 18, 151, 98, 41, 185, 0, 57, 187, 183, 101, 173, 130, 53, 200, 171, 189, 66, 43, 142, 12, 133, 105, 94, 62, 176, 191, 197, 190]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 397ms/step - loss: 1.9761 - accuracy: 0.3412 - val_loss: 1.2861 - val_accuracy: 0.1346\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.6432 - accuracy: 0.3717 - val_loss: 1.2297 - val_accuracy: 0.2885\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 1.6400 - accuracy: 0.5975 - val_loss: 1.1451 - val_accuracy: 0.2500\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.4104 - accuracy: 0.7489 - val_loss: 1.1041 - val_accuracy: 0.3654\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.2355 - accuracy: 0.7790 - val_loss: 1.0706 - val_accuracy: 0.4231\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.1236 - accuracy: 0.8266 - val_loss: 1.0552 - val_accuracy: 0.4423\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.9827 - accuracy: 0.8878 - val_loss: 0.9992 - val_accuracy: 0.5000\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.8616 - accuracy: 0.9001 - val_loss: 0.9972 - val_accuracy: 0.5192\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.8166 - accuracy: 0.8811 - val_loss: 0.9830 - val_accuracy: 0.5385\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.7442 - accuracy: 0.9023 - val_loss: 0.9309 - val_accuracy: 0.5385\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.6547 - accuracy: 0.9249 - val_loss: 0.8951 - val_accuracy: 0.5769\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6282 - accuracy: 0.9144 - val_loss: 0.8752 - val_accuracy: 0.5962\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.5590 - accuracy: 0.9215 - val_loss: 0.8594 - val_accuracy: 0.6154\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.5327 - accuracy: 0.9236 - val_loss: 0.8475 - val_accuracy: 0.5577\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4441 - accuracy: 0.9396 - val_loss: 0.8313 - val_accuracy: 0.5962\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3958 - accuracy: 0.9776 - val_loss: 0.8061 - val_accuracy: 0.6538\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4081 - accuracy: 0.9816 - val_loss: 0.8103 - val_accuracy: 0.5962\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3360 - accuracy: 0.9788 - val_loss: 0.7908 - val_accuracy: 0.6538\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3324 - accuracy: 0.9803 - val_loss: 0.7842 - val_accuracy: 0.6538\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3013 - accuracy: 0.9837 - val_loss: 0.7813 - val_accuracy: 0.6731\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2739 - accuracy: 0.9810 - val_loss: 0.7741 - val_accuracy: 0.6538\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.2710 - accuracy: 0.9872 - val_loss: 0.7695 - val_accuracy: 0.6923\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2797 - accuracy: 0.9729 - val_loss: 0.7688 - val_accuracy: 0.6923\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.2313 - accuracy: 0.9933 - val_loss: 0.7687 - val_accuracy: 0.6731\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.6731\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2095 - accuracy: 0.9967 - val_loss: 0.7516 - val_accuracy: 0.6923\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1913 - accuracy: 1.0000 - val_loss: 0.7617 - val_accuracy: 0.6538\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1864 - accuracy: 1.0000 - val_loss: 0.7623 - val_accuracy: 0.6923\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1395 - accuracy: 1.0000 - val_loss: 0.7612 - val_accuracy: 0.6923\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1473 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.6923\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1418 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.6923\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1218 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.7115\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1232 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.6923\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.7575 - val_accuracy: 0.6731\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1143 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.6923\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1148 - accuracy: 1.0000 - val_loss: 0.7551 - val_accuracy: 0.6923\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1144 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.6923\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1167 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.6923\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.6923\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.0968 - accuracy: 1.0000 - val_loss: 0.7547 - val_accuracy: 0.6923\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.6923\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0892 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.6923\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.6923\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.6923\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.6923\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1132 - accuracy: 1.0000 - val_loss: 0.7554 - val_accuracy: 0.6923\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: loss of 0.74; accuracy of 73.08%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3/3 ...\n",
      "------------------------------------------------------------------------\n",
      "[25, 60, 84, 152, 17, 120, 20, 136, 2, 51, 103, 21, 148, 131, 143, 37, 89, 83, 33, 151, 104, 29, 11, 86, 32, 106, 16, 41, 185, 187, 7, 5, 62, 181, 3, 182, 161, 4, 192, 127, 194, 45, 179, 24, 70, 195, 193, 97, 155, 164, 40, 101]\n",
      "Epoch 1/300\n",
      "10/10 [==============================] - 13s 398ms/step - loss: 1.8874 - accuracy: 0.3234 - val_loss: 1.0834 - val_accuracy: 0.3462\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 1.5816 - accuracy: 0.4271 - val_loss: 1.0770 - val_accuracy: 0.4231\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 1.4789 - accuracy: 0.5184 - val_loss: 1.0413 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.2977 - accuracy: 0.6636 - val_loss: 0.9604 - val_accuracy: 0.5385\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 1.1967 - accuracy: 0.7962 - val_loss: 0.9335 - val_accuracy: 0.6346\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 1.1674 - accuracy: 0.7541 - val_loss: 0.9073 - val_accuracy: 0.6346\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.0268 - accuracy: 0.8451 - val_loss: 0.8768 - val_accuracy: 0.6538\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.9463 - accuracy: 0.8237 - val_loss: 0.8418 - val_accuracy: 0.6538\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.8667 - accuracy: 0.8882 - val_loss: 0.8219 - val_accuracy: 0.6731\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.7283 - accuracy: 0.9210 - val_loss: 0.8059 - val_accuracy: 0.6923\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6369 - accuracy: 0.9205 - val_loss: 0.7753 - val_accuracy: 0.6731\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.6176 - accuracy: 0.9109 - val_loss: 0.7771 - val_accuracy: 0.7115\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5309 - accuracy: 0.9195 - val_loss: 0.7514 - val_accuracy: 0.7308\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.5022 - accuracy: 0.9427 - val_loss: 0.7354 - val_accuracy: 0.7308\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.4534 - accuracy: 0.9359 - val_loss: 0.7292 - val_accuracy: 0.7308\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4265 - accuracy: 0.9458 - val_loss: 0.7242 - val_accuracy: 0.7115\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.4085 - accuracy: 0.9545 - val_loss: 0.7153 - val_accuracy: 0.7115\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3489 - accuracy: 0.9775 - val_loss: 0.7073 - val_accuracy: 0.7115\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3484 - accuracy: 0.9501 - val_loss: 0.7083 - val_accuracy: 0.7115\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2903 - accuracy: 0.9765 - val_loss: 0.7038 - val_accuracy: 0.7115\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2698 - accuracy: 0.9967 - val_loss: 0.7071 - val_accuracy: 0.7115\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.2793 - accuracy: 0.9904 - val_loss: 0.7044 - val_accuracy: 0.7115\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2769 - accuracy: 0.9828 - val_loss: 0.6993 - val_accuracy: 0.6923\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.2461 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.7115\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.2046 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.7115\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1990 - accuracy: 0.9935 - val_loss: 0.6953 - val_accuracy: 0.7115\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.1813 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.7115\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1873 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.7500\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1650 - accuracy: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.7115\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1347 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.7308\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.1528 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.7500\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.1248 - accuracy: 1.0000 - val_loss: 0.7039 - val_accuracy: 0.7500\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.7308\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.7308\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1057 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.7500\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.7500\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.7092 - val_accuracy: 0.7500\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.7500\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1058 - accuracy: 0.9957 - val_loss: 0.7096 - val_accuracy: 0.7500\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.7095 - val_accuracy: 0.7500\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.7500\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.7500\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.7500\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.0915 - accuracy: 1.0000 - val_loss: 0.7108 - val_accuracy: 0.7500\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.7500\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.1133 - accuracy: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.7500\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.7500\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.7500\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.7500\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: loss of 0.76; accuracy of 71.15%\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.76 - Accuracy: 0.67%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.74 - Accuracy: 0.73%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.76 - Accuracy: 0.71%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds (LR = 0.0001, mtm = 0.9):\n",
      "> Accuracy: 0.71 (+- 0.02)\n",
      "> Loss: 0.75 (+- 0.01)\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_rate = [0.01, 0.001, 0.0001]\n",
    "momentum = [0, 0.5, 0.9]\n",
    "\n",
    "tot_comb = len(learn_rate) * len(momentum)\n",
    "glob_param = np.empty([tot_comb, 2])\n",
    "\n",
    "history_list = []\n",
    "scores_glob_array = np.empty([tot_comb, n_folds, 2])\n",
    "\n",
    "import itertools\n",
    "\n",
    "for idx, x in enumerate(itertools.product(learn_rate, momentum)):\n",
    "    learn_rate = x[0]\n",
    "    momentum = x[1]\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for combination {idx + 1}/{tot_comb} ...')\n",
    "    print(f'Learning rate = {learn_rate}')\n",
    "    print(f'Momentum = {momentum}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    history_array = np.array([])\n",
    "    scores_array = np.empty([n_folds, 2])\n",
    "\n",
    "    glob_param[idx, 0] = learn_rate\n",
    "    glob_param[idx, 1] = momentum\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold + 1}/{n_folds} ...')\n",
    "        print('------------------------------------------------------------------------')\n",
    "\n",
    "        # Generate the fold sample for train-test\n",
    "        X_train, Y_train, X_test, Y_test = part_traintest(X_traintest, Y_traintest, rand_seed + fold, frac_test)\n",
    "\n",
    "        # Define the model architecture\n",
    "        model_1rama = DenseNet201_1Rama(vista, input_dim, rand_seed, learn_rate, momentum)\n",
    "\n",
    "        # Fit data to model\n",
    "        history = model_1rama.fit(X_train, Y_train,\n",
    "                                  batch_size = batch_size,\n",
    "                                  epochs = no_epochs,\n",
    "                                  validation_data = (X_test, Y_test),\n",
    "                                  class_weight = class_weight,\n",
    "                                  verbose = 1,\n",
    "                                  callbacks = [early_stopping, reduce_lr])\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        scores_array[fold, :] = model_1rama.evaluate(X_val, Y_val, verbose = 0)\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Score for fold {fold + 1}: {model_1rama.metrics_names[0]} of {round(scores_array[fold, 0], 2)}; {model_1rama.metrics_names[1]} of {round(scores_array[fold, 1]*100, 2)}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('')\n",
    "\n",
    "        # Append history callback into array\n",
    "        history_array = np.append(history_array, [history])\n",
    "\n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, scores_array.shape[0]):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i + 1} - Loss: {round(scores_array[i, 0], 2)} - Accuracy: {round(scores_array[i, 1], 2)}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Average scores for all folds (LR = {learn_rate}, mtm = {momentum}):')\n",
    "    print(f'> Accuracy: {round(np.mean(scores_array[:, 1]), 2)} (+- {round(np.std(scores_array[:, 1]), 2)})')\n",
    "    print(f'> Loss: {round(np.mean(scores_array[:, 0]), 2)} (+- {round(np.std(scores_array[:, 0]), 2)})')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "    idx_best_hist = np.argmax(scores_array[:, 1])\n",
    "    history_list.append(history_array[idx_best_hist])\n",
    "\n",
    "    scores_glob_array[idx, :, :] = scores_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    \"\"\"\n",
    "    Function that plots the metrics from the training process\n",
    "        - history is the output from the training process\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize = (15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc = 'upper right')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"\n",
    "    Credit to:\n",
    "    https://gist.github.com/zachguo/10296432\n",
    "    \n",
    "    Function that makes a pretty print for confusion matrixes\n",
    "        - cm is the array of histories generated during the training process\n",
    "        - labels is number of epochs fixed for the training process\n",
    "        - hide_zeroes is a boolean that allows the user to hide the zeroes in the matrix\n",
    "        - hide_diagonal is a boolean that allows the user to hide the diagonal in the matrix\n",
    "        - hide_threshold is a number that allows the user to hide results in the matrix below that value\n",
    "    \"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados promedios del entrenamiento DenseNet-CC:\n",
      "- LR=0.01 / mom=0.0:\tAcc=0.67 (+- 0.1) - Loss=0.84 (+- 0.09)\n",
      "- LR=0.01 / mom=0.5:\tAcc=0.59 (+- 0.08) - Loss=0.88 (+- 0.05)\n",
      "- LR=0.01 / mom=0.9:\tAcc=0.69 (+- 0.06) - Loss=1.2 (+- 0.21)\n",
      "- LR=0.001 / mom=0.0:\tAcc=0.66 (+- 0.02) - Loss=0.76 (+- 0.01)\n",
      "- LR=0.001 / mom=0.5:\tAcc=0.66 (+- 0.02) - Loss=0.77 (+- 0.01)\n",
      "- LR=0.001 / mom=0.9:\tAcc=0.67 (+- 0.05) - Loss=0.79 (+- 0.03)\n",
      "- LR=0.0001 / mom=0.0:\tAcc=0.67 (+- 0.03) - Loss=0.76 (+- 0.01)\n",
      "- LR=0.0001 / mom=0.5:\tAcc=0.67 (+- 0.02) - Loss=0.76 (+- 0.02)\n",
      "- LR=0.0001 / mom=0.9:\tAcc=0.71 (+- 0.02) - Loss=0.75 (+- 0.01)\n",
      "\n",
      "El mejor resultado para la DenseNet-CC se obtiene para LR = 0.0001 y momentum = 0.9.\n"
     ]
    }
   ],
   "source": [
    "print(f'Resultados promedios del entrenamiento DenseNet-{vista}:')\n",
    "for i in range(len(glob_param)):\n",
    "    print(f'- LR={glob_param[i, 0]} / mom={glob_param[i, 1]}:\\tAcc={round(np.mean(scores_glob_array[i, :, 1]), 2)} (+- {round(np.std(scores_glob_array[i, :, 1]), 2)}) - Loss={round(np.mean(scores_glob_array[i, :, 0]), 2)} (+- {round(np.std(scores_glob_array[i, :, 0]), 2)})')\n",
    "\n",
    "idx_best = np.argmax(np.mean(scores_glob_array, 1)[:, 1])\n",
    "history_best = history_list[idx_best]\n",
    "model_best = history_best.model\n",
    "print(f'\\nEl mejor resultado para la DenseNet-{vista} se obtiene para LR = {glob_param[idx_best, 0]} y momentum = {glob_param[idx_best, 1]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    benigno seguimiento     maligno \n",
      "        benigno        23.0         0.0         5.0 \n",
      "    seguimiento         3.0         1.0         0.0 \n",
      "        maligno         6.0         0.0        14.0 \n"
     ]
    }
   ],
   "source": [
    "conf_matrix = metrics.confusion_matrix(Y_val.argmax(axis = 1), model_best.predict(X_val).argmax(axis = 1))\n",
    "print_cm(conf_matrix, list(dict_valores.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     benigno       0.72      0.82      0.77        28\n",
      " seguimiento       1.00      0.25      0.40         4\n",
      "     maligno       0.74      0.70      0.72        20\n",
      "\n",
      "    accuracy                           0.73        52\n",
      "   macro avg       0.82      0.59      0.63        52\n",
      "weighted avg       0.75      0.73      0.72        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classif_report = metrics.classification_report(Y_val.argmax(axis = 1), model_best.predict(X_val).argmax(axis = 1),\n",
    "                                               target_names = list(dict_valores.keys()))\n",
    "print(classif_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_best_DN201_CC/assets\n"
     ]
    }
   ],
   "source": [
    "file_path = './model_best_DN201_' + vista\n",
    "K.models.save_model(model_best, file_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
